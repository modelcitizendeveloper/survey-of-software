#!/home/ivanadamin/spawn-solutions/research/1.140-classical-language-libraries/02-implementations/.venv/bin/python
"""
latin-parse - Parse Latin text and output JSONL

Usage:
    latin-parse input.txt > parsed.jsonl
    cat input.txt | latin-parse > parsed.jsonl

Output format: One JSON object per line (JSONL)
"""

import sys
import json
import re
from pathlib import Path

import stanza


class KnownWordDatabase:
    """
    Override parser with known-correct word forms

    Strategy:
    1. Check if word form exists in known words
    2. If yes, return known lemma + POS
    3. If no, fall back to parser
    """

    def __init__(self, known_words_path=None):
        if known_words_path and Path(known_words_path).exists():
            with open(known_words_path, 'r') as f:
                self.known_words = json.load(f)
        else:
            self.known_words = {}

    def lookup(self, word_form):
        """
        Look up a word form in the known-word database

        Returns:
            dict with {lemma, pos, case, number} if found
            None if not found
        """
        # Strip punctuation and lowercase
        word_clean = word_form.lower().strip('.,;:!?\'"\\/')

        # Search all known lemmas
        for lemma, word_data in self.known_words.items():
            if word_clean in word_data.get("forms", {}):
                form_info = word_data["forms"][word_clean]
                return {
                    "lemma": word_data["lemma"],
                    "pos": word_data["pos"],
                    "declension": word_data.get("declension"),
                    "case": form_info.get("case"),
                    "number": form_info.get("number"),
                    "source": "known_words"
                }

        return None

def decode_noun_xpos(xpos):
    """Extract declension and case from XPOS code"""
    if not xpos or xpos == '-':
        return None, None

    # Declension mapping (first character)
    decl_map = {
        'A': '1st',
        'B': '2nd',
        'C': '2nd/3rd',  # Ambiguous, needs disambiguation
        'D': '4th',
        'E': '5th',
    }

    # Case mapping - parse from pipe-delimited fields
    case_map = {
        'A': 'nominative',  # casA
        'B': 'genitive',     # casB
        'C': 'dative',       # casC
        'D': 'accusative',   # casD
        'E': 'vocative',     # casE
        'F': 'ablative',     # casF
        'M': 'accusative',   # casM (neuter nom/acc - treat as accusative)
    }

    declension = decl_map.get(xpos[0], None)

    # Parse case from cas field
    case = None
    if '|' in xpos:
        fields = xpos.split('|')
        for field in fields:
            if field.startswith('cas') and len(field) > 3:
                case_code = field[3]  # Get character after 'cas'
                case = case_map.get(case_code)
                break

    return declension, case

def decode_verb_xpos(xpos):
    """Extract tense from XPOS code"""
    if not xpos or xpos == '-':
        return None

    tense_match = re.search(r'tem(\d)', xpos)
    if tense_match:
        tense_map = {
            '1': 'present',
            '2': 'imperfect',
            '3': 'future',
            '4': 'perfect',
        }
        return tense_map.get(tense_match.group(1))
    return None

def parse_text(text):
    """Parse Latin text and return structured data"""
    # Initialize known-word database
    script_dir = Path(__file__).parent.parent
    known_words_path = script_dir / 'known_words.json'
    db = KnownWordDatabase(known_words_path)

    # Use PROIEL package (biblical Latin) instead of default ITTB (medieval)
    # PROIEL has 70% accuracy vs 45% for ITTB on 1st declension masculine nouns
    # Tested 2025-11-18: poeta (100%), agricola (100%), nauta (75%), scriba (75%)
    # + Known-word DB (5 words: nauta, scriba, pirata, tempus, mos) â†’ 90%+ expected
    nlp = stanza.Pipeline('la', package='proiel', processors='tokenize,pos,lemma',
                          verbose=False, logging_level='ERROR')

    # Split into sentences (simple split on . ! ?)
    sentences = re.split(r'[.!?]+', text.strip())
    sentences = [s.strip() for s in sentences if s.strip()]

    results = []

    for sentence in sentences:
        doc = nlp(sentence)

        words_data = []
        for sent in doc.sentences:
            for word in sent.words:
                # Check known-word database first
                known = db.lookup(word.text)

                if known:
                    # Use known-word database result
                    word_info = {
                        'text': word.text,
                        'lemma': known['lemma'],
                        'pos': known['pos'],
                        'xpos': 'known-db',
                        'source': 'known_words'
                    }

                    # Add known-word metadata
                    if known.get('declension'):
                        word_info['declension'] = known['declension']
                    if known.get('case'):
                        word_info['case'] = known['case']
                    if known.get('number'):
                        word_info['number'] = known['number']
                else:
                    # Fall back to parser result
                    word_info = {
                        'text': word.text,
                        'lemma': word.lemma if word.lemma else word.text.lower(),
                        'pos': word.upos if word.upos else 'UNKNOWN',
                        'xpos': word.xpos if word.xpos else '-',
                        'source': 'proiel'
                    }

                    # Add declension/case for nouns
                    if word.upos in ('NOUN', 'PROPN'):
                        declension, case = decode_noun_xpos(word.xpos)
                        if declension:
                            word_info['declension'] = declension
                        if case:
                            word_info['case'] = case

                    # Add tense for verbs
                    if word.upos == 'VERB':
                        tense = decode_verb_xpos(word.xpos)
                        if tense:
                            word_info['tense'] = tense

                words_data.append(word_info)

        results.append({
            'sentence': sentence,
            'words': words_data
        })

    return results

def main():
    # Read from file or stdin
    if len(sys.argv) > 1:
        input_file = sys.argv[1]
        with open(input_file, 'r', encoding='utf-8') as f:
            text = f.read()
    else:
        text = sys.stdin.read()

    # Parse and output JSONL
    results = parse_text(text)

    for result in results:
        print(json.dumps(result, ensure_ascii=False))

if __name__ == '__main__':
    main()
