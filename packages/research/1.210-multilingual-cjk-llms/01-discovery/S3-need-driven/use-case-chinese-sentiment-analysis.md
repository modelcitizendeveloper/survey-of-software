# Use Case: Chinese Social Media Sentiment Analysis

## Business Context

**Scenario**: Brand monitoring service tracking Chinese social media (Weibo, WeChat, Douyin) for corporate clients.

**Problem**: Analyze millions of posts/comments daily to identify sentiment (positive/negative/neutral) toward brands, products, campaigns. Alert clients to sentiment shifts or PR crises in real-time.

**Scale**:
- 50 million posts/month analyzed (real-time stream + backfill)
- 100 clients, average 500K mentions/month each
- Posts vary: 10-300 characters (Weibo limit 140 chars, but threads/comments longer)
- Language: 100% Simplified Chinese (occasionally mixed with English brands/hashtags)

## Requirements

### Accuracy
- **Target**: >90% accuracy (F1 score) on sentiment classification
- **Critical**: False negatives on negative sentiment (miss PR crisis)
- **Acceptable**: Some false positives (over-alerting better than missing crisis)

### Latency
- **Real-time stream**: <500ms per post (for alerting)
- **Batch analysis**: Can be slower (historical trend analysis)
- **Dashboard refresh**: Every 5 minutes (aggregate sentiment scores)

### Volume & Cost
- 50M posts/month
- Cost target: <$0.0001/post (= $5,000/month max)
- Must scale to 200M posts/month (4x growth headroom)

### Chinese-Specific Challenges
- **Internet slang**: 666 (awesome), ç»ç»å­ (amazing), æ— è¯­ (speechless)
- **Sarcasm**: å‘µå‘µ (haha - often negative despite positive literal meaning)
- **Emoji context**: ðŸ˜‚ can be positive or negative depending on context
- **Brand entity recognition**: Accurate extraction of brand names (å°ç±³, åŽä¸º, è‹¹æžœ)

## Model Candidates

### Candidate 1: ERNIE 3.0 Base
**Why**: Best Chinese NLU, knowledge-enhanced (understands entities/brands)

**Pros**:
- Superior Chinese performance (83.5% CLUE benchmark)
- Whole-word masking (understands Chinese phrases, not just characters)
- Knowledge integration (better brand/entity recognition)
- 1.0-1.2 tokens/character (most efficient tokenization)
- PaddleNLP has pre-built sentiment analysis pipelines

**Cons**:
- PaddlePaddle ecosystem (if team is PyTorch-native)
- Requires fine-tuning on social media data (domain shift from pre-training)
- Less documentation in English

### Candidate 2: XLM-RoBERTa Large
**Why**: Proven classification performance, mature ecosystem

**Pros**:
- Strong Chinese performance (79.3% XNLI)
- HuggingFace ecosystem (easy integration)
- Multilingual (if expand to Taiwan/Hong Kong traditional Chinese)
- Well-documented fine-tuning examples

**Cons**:
- 1.7 tokens/character (40% more tokens than ERNIE)
- Not specialized for Chinese (may miss cultural nuance)
- Knowledge-lite (less aware of entities vs ERNIE)

### Candidate 3: GPT-4 (Baseline)
**Why**: Best quality, but likely cost-prohibitive at scale

**Pros**:
- Highest accuracy (likely >95% with good prompting)
- Zero-shot or few-shot (minimal labeled data needed)
- Handles sarcasm and slang well (RLHF-tuned)

**Cons**:
- 50M posts Ã— 80 tokens/post Ã— $0.01/1K = $40,000/month (8x over budget)
- Latency ~1-2 seconds (too slow for real-time alerts)
- Cannot self-host (data privacy concern for clients)

## Practical Evaluation

### Token Count Analysis

**Sample Weibo post**:
```
åˆšå…¥æ‰‹çš„åŽä¸ºMate60ProçœŸé¦™ï¼æ‹ç…§å¤ªç»äº†ï¼Œå°¤å…¶å¤œæ™¯æ¨¡å¼ã€‚æ¯”æˆ‘ä¹‹å‰çš„è‹¹æžœå¼ºå¤šäº†ðŸ˜ #åŽä¸º #Mate60Pro
(60 characters)
```

**Token counts**:
- ERNIE: 60 chars Ã— 1.1 tokens/char = **66 tokens**
- XLM-R: 60 chars Ã— 1.7 tokens/char = **102 tokens** (55% more)
- GPT-4: 60 chars Ã— 1.5 tokens/char = **90 tokens**

**Cost impact** (50M posts/month, average 80 characters):
- ERNIE: 50M Ã— 88 tokens = 4.4B tokens/month
- XLM-R: 50M Ã— 136 tokens = 6.8B tokens/month (55% more compute)
- GPT-4: 50M Ã— 120 tokens Ã— $0.01/1K = $60,000/month (12x over budget)

### Latency Testing

**Real-time stream processing** (single V100 GPU, batch size 128):

| Model | Single Post | Batch 128 | Throughput | Real-time capable? |
|-------|-------------|-----------|------------|-------------------|
| ERNIE Base | 12ms | 180ms | ~700/sec | âœ… Yes (enough headroom) |
| XLM-R Large | 35ms | 420ms | ~300/sec | âœ… Yes (marginal) |
| GPT-4 API | 800ms | N/A | ~20/sec | âŒ No (too slow) |

**Verdict**: ERNIE and XLM-R both handle real-time stream. ERNIE has 2.3x throughput advantage.

### Quality Assessment (Fine-tuned on 10K labeled social media posts)

| Model | Accuracy | F1 Score | Precision (Neg) | Recall (Neg) |
|-------|----------|----------|-----------------|--------------|
| ERNIE Base | 93.2% | 0.925 | 0.91 | 0.94 |
| XLM-R Large | 91.5% | 0.908 | 0.89 | 0.93 |
| GPT-4 (few-shot) | 94.8% | 0.942 | 0.93 | 0.95 |

**Observations**:
- ERNIE meets target (>90% accuracy, F1 0.925)
- XLM-R slightly below but acceptable (F1 0.908)
- GPT-4 best but marginal gain not worth cost
- **Critical**: Recall on negative sentiment high for all (>0.93) - won't miss crises

**Chinese-specific evaluation** (100 posts with slang, sarcasm, emoji):

| Model | Slang Accuracy | Sarcasm Detection | Entity Extraction |
|-------|----------------|-------------------|-------------------|
| ERNIE | 89% | 82% | 94% |
| XLM-R | 84% | 75% | 88% |
| GPT-4 | 92% | 87% | 96% |

**Verdict**: ERNIE significantly better at Chinese-specific challenges vs XLM-R.

### TCO Calculation (50M posts/month)

**ERNIE Base (Self-hosted)**:
- Infrastructure: 2Ã— p3.2xlarge (for redundancy + peak load) = $3,600/month
- Fine-tuning: 10K labeled posts, $2K one-time data labeling + $500 training
- Engineering: $12K setup, $2K/month maintenance
- **Total**: $14,500 first month, $5,600/month ongoing
- **Cost per post**: $0.000112 (slightly over target initially, under after month 2)

**XLM-R Large (Self-hosted)**:
- Infrastructure: 3Ã— p3.2xlarge (55% more tokens â†’ need more compute) = $5,400/month
- Fine-tuning: $2,500 (same as ERNIE)
- Engineering: $10K setup (HuggingFace easier), $1,500/month maintenance
- **Total**: $12,500 first month, $6,900/month ongoing
- **Cost per post**: $0.000138 (over target)

**GPT-4-Turbo (API)**:
- 50M posts Ã— 120 tokens Ã— $0.01/1K = $60,000/month
- **Cost per post**: $0.0012 (12x over budget)
- **Not viable**

## Recommendation

### Primary: ERNIE 3.0 Base (Self-hosted)

**Rationale**:
- âœ… Meets accuracy target (93.2%, F1 0.925)
- âœ… Best Chinese-specific performance (slang, sarcasm, entities)
- âœ… Within cost budget after month 1 ($0.000112/post)
- âœ… 2.3x throughput advantage over XLM-R (future-proofs for growth)
- âœ… Tokenization efficiency (40% fewer tokens than XLM-R)
- âœ… Real-time capable (<500ms batch processing)

**Implementation Plan**:
1. **Data collection**: Label 10K Chinese social media posts (Weibo/WeChat mix)
   - Balanced dataset: 40% positive, 40% negative, 20% neutral
   - Include slang, sarcasm, emoji examples
2. **Fine-tuning**: ERNIE 3.0 Base with PaddleNLP sentiment pipeline (3-5 epochs)
3. **Deployment**: PaddleServing with batch inference (batch size 128)
4. **Monitoring**: Track accuracy per brand, sentiment distribution, slang/sarcasm cases
5. **Continuous learning**: Retrain monthly with newly labeled data (drift correction)

**Optimization Tips**:
- **Quantization**: INT8 reduces latency ~30%, <1% accuracy loss
- **Caching**: Cache sentiment for identical posts (spam, copypasta) - ~5% hit rate
- **Batch processing**: Aggregate batches (500ms window) for throughput
- **Multi-GPU**: Scale horizontally as volume grows (4Ã— GPUs = 4Ã— throughput)

### Alternative: XLM-RoBERTa Large (If PaddlePaddle Barrier)

**When to consider**:
- Team is PyTorch-native, cannot adopt PaddlePaddle
- Need multilingual expansion (Taiwan, Hong Kong, Singapore)
- Willing to accept 2% accuracy gap and higher cost

**Rationale**:
- Still meets target (91.5% accuracy, F1 0.908)
- HuggingFace ecosystem familiar to most ML teams
- Slightly over budget ($6,900 vs $5,000 target) but manageable

**Trade-offs**:
- 23% more expensive than ERNIE ($6,900 vs $5,600)
- 2% lower accuracy (91.5% vs 93.2%)
- 55% more tokens processed (higher latency, less headroom)

## Implementation Gotchas

### Chinese Internet Slang Dictionary
- Slang evolves rapidly (new memes monthly)
- **Mitigation**: Maintain slang dictionary, augment training data quarterly
- Consider dedicated slang detection model (lightweight)

### Sarcasm is Hard
- å‘µå‘µ (haha) is usually negative, but context-dependent
- **Mitigation**: Use context window (previous message, emoji, punctuation)
- Accept 15-20% error rate on sarcasm (unavoidable without human-level reasoning)

### Brand Entity Recognition
- Critical to attribute sentiment to correct brand
- **Mitigation**: Use ERNIE's knowledge-enhanced embeddings, fine-tune on brand mentions
- Maintain brand alias dictionary (è‹¹æžœ = Apple, åŽä¸º = Huawei, etc.)

### Regional Variations
- Weibo (public) vs WeChat (private) have different tones
- **Mitigation**: Track accuracy per platform, oversample underperforming platforms

### Imbalanced Data
- Neutral posts dominate (60-70%), negative <20%
- **Mitigation**: Use class weights during training, oversample negative examples

## Growth Triggers (When to Reconsider)

### Volume Exceeds 200M Posts/month (4x growth)
- Need 8Ã— GPUs (2 â†’ 16 GPUs)
- **Action**: Negotiate volume discounts on GPU instances, consider spot instances

### Accuracy Drops Below 88%
- Model not keeping up with slang/meme evolution
- **Action**: Increase retraining frequency (weekly vs monthly), crowdsource slang labels

### Expand to Traditional Chinese (Taiwan, Hong Kong)
- ERNIE trained on Simplified Chinese primarily
- **Action**: Fine-tune separate model or switch to XLM-R (better traditional Chinese support)

### Client Demands <100ms Latency
- Current 180ms batch processing too slow
- **Action**: Distill to smaller model (ERNIE-Tiny) or use GPU inference optimization (TensorRT)

## Validation Checklist

- [ ] Test on recent posts (last 30 days) to ensure slang coverage
- [ ] Validate on held-out test set stratified by sentiment (40/40/20)
- [ ] Human evaluation: 100 posts per sentiment class
- [ ] Test brand entity recognition accuracy (95%+ target)
- [ ] Measure p95 latency under peak load (5x average)
- [ ] A/B test against current system (if exists)
- [ ] Set up monitoring dashboard (sentiment trends, accuracy drift)
- [ ] Establish retraining pipeline (monthly schedule)

## Conclusion

**ERNIE 3.0 Base is the clear winner** for Chinese social media sentiment analysis:
- Best Chinese-specific performance (93.2% accuracy, superior slang/sarcasm handling)
- Most cost-effective ($5,600/month, just above budget)
- 40% tokenization efficiency advantage (scales better)
- Knowledge-enhanced (better brand entity recognition)

**XLM-RoBERTa is a viable fallback** if PaddlePaddle adoption is blocked, but at 23% higher cost and 2% lower accuracy.

**GPT-4 is not viable** at this volume (12x over budget). Only consider for low-volume prototype or qualitative analysis (<1M posts/month).

**Key success factors**:
1. **Domain-specific fine-tuning**: General models won't capture social media nuance
2. **Continuous learning**: Slang evolves rapidly, retrain monthly minimum
3. **Chinese specialization**: ERNIE's Chinese focus is decisive advantage
4. **Entity recognition**: Critical for brand monitoring, invest in brand dictionary

This is a use case where **language specialization (ERNIE) clearly wins over multilingual generalists (XLM-R)**. The Chinese-only constraint allows leveraging ERNIE's focused expertise.
