# S3 Approach: Need-Driven Discovery

## What S3 Discovers

S3 answers: **WHO needs Chinese tokenization + WHY?**

Focus: Use cases, personas, requirements → library matching.

## Methodology

### Start with Needs, Not Tools
1. **Identify persona**: Who is building what?
2. **Extract requirements**: What constraints matter?
3. **Map to libraries**: Which tools fit the scenario?
4. **Validate**: Does this solve the actual problem?

### Use Case Format

Each use case answers:
- **Who**: User persona and context
- **Why**: Business/technical requirements
- **Constraints**: Speed, accuracy, cost, complexity
- **Solution**: Recommended library + rationale
- **Alternatives**: Other options if requirements change

## Use Cases Covered

1. **E-commerce Search**: Building product search engines
2. **NLP Research**: Academic research requiring accuracy
3. **Chatbot Development**: Real-time conversational AI
4. **Content Moderation**: Social media filtering at scale
5. **Multilingual Products**: Apps supporting Chinese + other languages

## S3 Does NOT Cover

- Library internals → See S2
- Quick comparisons → See S1
- Strategic planning → See S4

## Reading Time

~20 minutes for complete S3 pass
