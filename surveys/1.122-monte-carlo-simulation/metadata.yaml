published: true
experiment_number: "1.122"
experiment_sequence: 28
experiment_date: "2025-10-19"
experiment_completed: "2025-10-19"
experiment_status: complete
discovery_method: detailed_toc
tier: 1
category: "Simulation & Modeling Libraries"
migrated_from: null
notes: "Monte Carlo simulation libraries - NumPy, scipy.stats, SALib, uncertainties, PyMC, chaospy, OpenTURNS. Second experiment in 1.120-129 simulation category. Application-neutral generic research following 'Hardware Store for Software' philosophy."

summary: |
  Comprehensive analysis of 7 Monte Carlo simulation libraries for Python: NumPy (RNG foundation), scipy.stats (distributions + quasi-MC), SALib (sensitivity analysis specialist), uncertainties (automatic error propagation), PyMC (Bayesian inference ONLY - NOT for forward MC), chaospy (polynomial chaos - HIGH RISK: declining project), OpenTURNS (industrial UQ suite). Research covers 6 generic use case patterns (sensitivity analysis, confidence intervals, risk quantification, uncertainty propagation, model calibration, distribution characterization) applicable across all domains (finance, engineering, healthcare, manufacturing, etc.). Key discovery: NumPy + scipy.stats universal foundation (Tier 1 - 10+ year horizon), SALib niche leader with succession risk (Tier 3 - 3-5 year horizon), chaospy HIGH RISK (declining academic project - avoid/migrate).

key_findings:
  universal_foundation:
    libraries: "NumPy (numpy.random.default_rng) + scipy.stats"
    confidence: "10/10 - All 4 methodologies agreed"
    viability: "15+ year horizon, NumFOCUS backing, critical infrastructure"
    use_cases: "All 6 generic patterns, universal across domains"

  sensitivity_analysis_specialist:
    library: "SALib"
    confidence: "S1/S2/S3: HIGH (9/10), S4: MEDIUM (6/10) - succession risk"
    viability: "3-5 year horizon, academic volunteer project, NO institutional backing"
    methods: "Sobol, Morris, FAST, PAWN, DGSM - comprehensive coverage"
    risk_mitigation: "Use abstraction layer, monitor quarterly, maintain fork capability"

  bayesian_inference_only:
    library: "PyMC"
    confidence: "9/10 for Bayesian parameter inference, 2/10 for forward Monte Carlo"
    critical_insight: "PyMC designed for INVERSE problems (parameter estimation), 10-100× slower for forward simulation"
    viability: "7-10 year horizon, NumFOCUS backing, commercial support available"
    use_case: "Model calibration with uncertainty (Pattern 5 only)"

  high_risk_library:
    library: "chaospy"
    confidence: "S1/S2/S3: 7-8/10 technical, S4: 2/10 strategic"
    risk: "Declining academic project, abandonment risk, may break with Python 3.14+"
    recommendation: "AVOID or MIGRATE to OpenTURNS/scipy.stats within 6-12 months"
    technical_merit: "Polynomial chaos expansion excellent, but strategic risk unacceptable"

  industrial_uq:
    library: "OpenTURNS"
    confidence: "9/10 strategic, 7/10 usability (steep learning curve)"
    viability: "10+ year horizon, industrial consortium (EDF, Airbus, Phimeca), regulatory acceptance"
    use_cases: "Enterprise/regulatory contexts requiring copulas, reliability analysis, Kriging"
    trade_off: "API friction vs institutional backing - acceptable for compliance needs"

libraries_analyzed:
  - name: NumPy (numpy.random)
    version: "1.26+"
    repository: "https://github.com/numpy/numpy"
    license: BSD-3-Clause
    maturity_tier: "Tier 1 (Universal Safe Bet)"
    primary_use: "Random number generation foundation"
    viability: "15+ years"

  - name: scipy.stats
    version: "1.11+"
    repository: "https://github.com/scipy/scipy"
    license: BSD-3-Clause
    maturity_tier: "Tier 1 (Universal Safe Bet)"
    primary_use: "Distributions + quasi-MC + bootstrap"
    viability: "10+ years"

  - name: SALib
    version: "1.4+"
    repository: "https://github.com/SALib/SALib"
    license: MIT
    maturity_tier: "Tier 3 (Niche Leader with Risk)"
    primary_use: "Sensitivity analysis (Sobol, Morris, FAST)"
    viability: "3-5 years (succession risk)"

  - name: uncertainties
    version: "3.1+"
    repository: "https://github.com/lebigot/uncertainties"
    license: BSD-3-Clause
    maturity_tier: "Tier 3 (Mature but Solo-Maintained)"
    primary_use: "Automatic error propagation"
    viability: "5-7 years (simple to fork)"

  - name: PyMC
    version: "5.x"
    repository: "https://github.com/pymc-devs/pymc"
    license: Apache-2.0
    maturity_tier: "Tier 1 (Bayesian Specialist)"
    primary_use: "Bayesian parameter inference ONLY"
    viability: "7-10 years"

  - name: chaospy
    version: "4.x"
    repository: "https://github.com/jonathf/chaospy"
    license: MIT
    maturity_tier: "Tier 4 (HIGH RISK - Declining)"
    primary_use: "Polynomial chaos expansion (AVOID)"
    viability: "2-4 years (abandonment risk)"

  - name: OpenTURNS
    version: "1.22+"
    repository: "https://github.com/openturns/openturns"
    license: LGPL
    maturity_tier: "Tier 2 (Industrial-Grade)"
    primary_use: "Comprehensive UQ (copulas, reliability, Kriging)"
    viability: "10+ years"

generic_use_case_patterns:
  - "Sensitivity Analysis: D input parameters → identify most influential (Sobol indices)"
  - "Confidence Intervals: Stochastic model → statistical bounds (bootstrap, percentile)"
  - "Risk Quantification: N alternatives → probability of success (VaR, CVaR)"
  - "Uncertainty Propagation: Input distributions → output distribution (MC, LHS, PCE)"
  - "Model Calibration: Unknown parameters + data → posterior distribution (Bayesian, MLE)"
  - "Distribution Characterization: Complex system → percentiles, tail behavior"

strategic_insights:
  ecosystem_consolidation:
    trend: "SciPy absorbing specialized functionality (pyDOE→qmc, bootstrap added)"
    prediction: "60% probability SciPy adds sensitivity analysis 2026-2028"
    implication: "Favor SciPy ecosystem for long-term stability"

  institutional_backing_matters:
    observation: "NumFOCUS/corporate-backed libraries survive, academic projects struggle"
    examples: "NumPy/SciPy/PyMC (thriving) vs SALib/chaospy (at-risk)"
    recommendation: "Prioritize governance health over features"

  forward_vs_inverse_clarity:
    confusion: "PyMC marketed as 'probabilistic programming' but designed for parameter inference"
    clarification: "Forward MC (simulation) ≠ Inverse problems (Bayesian calibration)"
    impact: "10-100× performance difference, wrong tool for forward simulation"

  academic_software_lifecycle:
    pattern: "PhD project → initial burst → post-graduation decline → abandonment"
    example: "chaospy shows classic pattern (2015-2020 active, 2020+ declining)"
    mitigation: "Avoid academic projects without institutional succession planning"

research_gaps_identified:
  - "No comprehensive performance benchmarks across all 7 libraries (S2 limitation)"
  - "Limited guidance on sample size planning for MC convergence (all methodologies)"
  - "Unclear surrogate modeling integration patterns (PCE, Kriging, GP)"
  - "No standard workflow for MC + optimization coupling (simheuristics)"

surprising_findings:
  - "SciPy 1.7 consolidated quasi-MC (pyDOE, sobol_seq deprecated) - ecosystem maturation"
  - "PyMC 5.0 unsuitable for forward MC despite probabilistic programming label"
  - "chaospy technical excellence negated by strategic abandonment risk"
  - "SALib has NO NumFOCUS backing despite being sensitivity analysis standard"
  - "OpenTURNS only library with comprehensive copula support (correlation modeling)"

application_specific_analysis:
  location: "/home/ivanadamin/spawn-solutions/applications/elevator-project/monte-carlo-analysis/"
  content: "Elevator-specific parameter values, OR consulting ROI calculations, board presentation requirements"
  note: "Application-specific content moved per 'Hardware Store for Software' philosophy"
