published: false
---
experiment_number: "3.044"
experiment_sequence: 18
experiment_date: "2025-11-06"
experiment_status: complete
discovery_method: mpse_v3.0
migrated_from: null
category: "3.040-049: Data Persistence"
name: "Data Warehouse & Analytics Databases"
started: "2025-11-06"
completed: "2025-11-06"

scope: |
  OLAP (Online Analytical Processing) platforms, columnar storage, and MPP
  (Massively Parallel Processing) analytics databases for business intelligence,
  reporting, and data analysis. Distinct from OLTP databases (3.040) - optimized
  for analytical queries across large datasets rather than transactional operations.

trigger:
  source: "3.007 FP&A Platforms research"
  date: "2025-11-01"
  finding: "Data warehouse integration quality identified as critical FP&A platform selection driver"
  context: "Causal, Runway, and other FP&A tools integrate WITH data warehouses for advanced analytics"

platforms:
  cloud_native:
    - Snowflake
    - Google BigQuery
    - Amazon Redshift
    - Azure Synapse Analytics
    - Databricks Lakehouse
  modern_alternatives:
    - Firebolt
    - ClickHouse Cloud
    - SingleStore
    - Rockset
  open_source:
    - Apache Druid
    - Apache Pinot
    - Apache Kylin
    - Greenplum

key_questions:
  - "When to invest in data warehouse vs stay with OLTP database?"
  - "Cloud warehouse economics: consumption vs reserved pricing?"
  - "Snowflake vs BigQuery vs Redshift - which for what use case?"
  - "Data lakehouse (Databricks) vs data warehouse - when does each make sense?"
  - "Vendor lock-in risks: proprietary vs open formats (Iceberg, Delta Lake)?"
  - "Integration architecture: ELT vs ETL patterns?"
  - "Cost optimization: storage vs compute separation?"

integration_points:
  upstream:
    - "3.040: Relational Databases (OLTP → data warehouse via ETL)"
    - "3.031: Object Storage (data lake raw storage layer)"
  downstream:
    - "3.007: FP&A Platforms (integrate WITH data warehouses)"
    - "3.062: Web Analytics (data warehouse as central repository)"
    - "3.063: Product Analytics (data warehouse as source of truth)"
  adjacent:
    - "3.064: Metadata Management (catalogs sit ON TOP of warehouses)"
    - "3.402: iPaaS (ETL/ELT orchestration tools)"

research_approach: "MPSE v3.0 - S1 (rapid), S2 (comprehensive), S3 (need-driven), S4 (strategic)"

s1_rapid:
  status: "complete"
  goal: "8 platform profiles, quick decision tree"
  platforms: 8
  deliverables:
    - "approach.md"
    - "provider-snowflake.md"
    - "provider-bigquery.md"
    - "provider-redshift.md"
    - "provider-synapse.md"
    - "provider-databricks.md"
    - "provider-clickhouse.md"
    - "provider-druid.md"
    - "provider-firebolt.md"
    - "recommendations.md"

s2_comprehensive:
  status: "complete"
  goal: "Feature matrix, pricing TCO, performance benchmarks"
  deliverables:
    - "approach.md"
    - "feature-matrix.md"
    - "pricing-tco.md"
    - "performance-benchmarks.md"
    - "integration-complexity.md"
    - "data-formats.md"
    - "synthesis.md"

s3_need_driven:
  status: "complete"
  goal: "6 business scenarios with recommendations"
  scenarios: 6
  deliverables:
    - "approach.md"
    - "startup-analytics.md"
    - "saas-product-analytics.md"
    - "ecommerce-reporting.md"
    - "financial-consolidation.md"
    - "iot-time-series.md"
    - "ml-feature-store.md"
    - "synthesis.md"

s4_strategic:
  status: "complete"
  goal: "Vendor viability, lock-in mitigation, 5-year outlook"
  deliverables:
    - "approach.md"
    - "vendor-viability.md"
    - "lock-in-mitigation.md"
    - "oltp-vs-olap.md"
    - "lakehouse-evolution.md"
    - "synthesis.md"

business_value:
  market_size: "Mid-market to enterprise companies with analytics needs"
  decision_frequency: "Every 3-5 years"
  annual_spend: "$10K-$500K+ depending on data volume and query frequency"
  consulting_opportunity: "$5K-$20K per data warehouse selection/migration project"

notes: |
  Triggered by 3.007 FP&A research finding. Data warehouses are critical infrastructure
  for modern analytics stacks. Key differentiator: OLAP (analytical) vs OLTP (transactional).
  Modern trend: separation of storage and compute, consumption-based pricing, open table
  formats (Iceberg, Delta Lake, Hudi) reducing lock-in. Growing category: data lakehouses
  (Databricks) combining warehouse and lake capabilities.

completion_summary:
  date: "2025-11-06"
  duration: "1 day"
  output:
    documents: 32
    total_lines: 20444
    total_size: "1.2MB"
  s1_output: "8 provider profiles (Snowflake, BigQuery, Redshift, Synapse, Databricks, ClickHouse, Druid, Firebolt) + recommendations synthesis"
  s2_output: "Feature matrix (91 features × 8 providers = 728 data points), pricing TCO (6 scenarios × 8 providers × 2 timeframes), performance benchmarks, integration complexity, data formats, synthesis"
  s3_output: "6 business scenarios (startup, SaaS, e-commerce, financial, IoT, ML) with architecture patterns, implementation guides, TCO models, and synthesis"
  s4_output: "Vendor viability (5/10-year survival analysis), lock-in mitigation framework, OLTP vs OLAP decision model, lakehouse evolution trajectory, strategic synthesis"

critical_findings:
  - "No universal winner: Platform choice depends on cloud ecosystem, budget, query patterns, and team skills"
  - "Cost variance: 1,200× price difference between cheapest (ClickHouse $55/month for 1TB) and most expensive configurations (Snowflake enterprise)"
  - "BigQuery cost leadership: Cheapest at scale for variable workloads ($50-100/month for 1TB, $800-10K/month for 10-100TB)"
  - "ClickHouse speed champion: Sub-second query latency, 10-20× faster than traditional warehouses for real-time analytics"
  - "Databricks lakehouse advantage: Python+SQL integration, Delta Lake open format, best for ML/AI workloads"
  - "Lock-in mitigation: Apache Iceberg adoption (Snowflake 2024, BigQuery 2025) reduces vendor lock-in by 30-50%"
  - "OLTP threshold: Stay on Postgres read replica until >100GB data, then migrate to warehouse"
  - "Lakehouse convergence: 70% of new deployments predicted to be lakehouse-first by 2027"
  - "Vendor viability: Cloud-backed platforms (BigQuery/Redshift/Synapse) 99% 10-year survival, Databricks/ClickHouse 85%+"
  - "TCO optimization: 35% cost savings possible with reserved capacity, caching, partitioning, and query optimization over 5 years"

platform_recommendations:
  by_use_case:
    startup_analytics: "BigQuery (cost leader at <1TB) or ClickHouse Cloud"
    saas_product_analytics: "ClickHouse (real-time events) or BigQuery (serverless)"
    ecommerce_reporting: "Redshift (AWS-native) or Snowflake (multi-cloud future)"
    financial_consolidation: "Snowflake (enterprise features, data sharing) or Databricks (ML forecasting)"
    iot_time_series: "Druid (real-time dashboards, high concurrency) or ClickHouse (speed)"
    ml_feature_store: "Databricks (lakehouse, Python-first) or Snowflake (SQL-heavy teams)"
  by_cloud:
    aws: "Redshift (native integration) or Snowflake (if multi-cloud future)"
    gcp: "BigQuery (no-brainer, best economics on GCP)"
    azure: "Synapse (Power BI integration) or Snowflake (if flexibility needed)"
    multi_cloud: "Snowflake (works everywhere) or Databricks (open format)"
  by_budget:
    under_500_month: "BigQuery or ClickHouse Cloud"
    500_to_5k_month: "Snowflake, BigQuery, or Redshift"
    5k_to_50k_month: "Any platform (enterprise tier)"
    over_50k_month: "Evaluate self-hosting (ClickHouse, Druid) if 5+ data engineers"
---
