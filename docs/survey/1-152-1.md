---
id: 1-152-1
title: "1.152.1 Cjk Readability"
sidebar_label: "1.152.1 Cjk Readability"
description: "Research on Cjk Readability"
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 1.152.1 Cjk Readability



---

<Tabs>
<TabItem value="s1" label="S1: Rapid Discovery" default>

# S1: Surface Scan - CJK Readability Analysis

## What This Is

CJK readability analysis evaluates Chinese text difficulty based on character frequency and proficiency level standards (HSK for mainland China, TOCFL for Taiwan). It answers: "What proficiency level does a learner need to read this text?"

## The Core Problem

Unlike alphabetic languages where ~26 letters form all words, Chinese uses thousands of characters. A learner with 500 characters can't read text requiring 2,000 characters. Readability analysis maps text to standardized proficiency levels so learners know if material matches their skill.

## Key Standards

### HSK (Hanyu Shuiping Kaoshi)
- **Old system**: 6 levels (HSK 1-6)
- **New system (2026)**: 9 levels, effective July 2026
- Character requirements:
  - HSK 1: ~300 characters
  - HSK 6: ~2,500 characters
  - HSK 9: 3,000+ characters (academic/professional)
- Most common 1,000 characters cover ~90% of everyday written Chinese
- 2,500 characters cover ~98% of common texts

### TOCFL (Test of Chinese as a Foreign Language - Taiwan)
- 8 levels: Novice 1-2, Levels 1-6
- Organized in 4 bands (Novice, A, B, C)
- Band A: 500-1,000 characters (240-720 learning hours)
- Uses TBCL (Taiwan Benchmarks for the Chinese Language): 3,100 characters, 14,425 words
- Focuses on vocabulary words (ci) rather than character counts

## Existing Tools

### Web-Based
- **Chinese Text Analyser** (chinesetextanalyser.com): Fast segmentation/analysis
- **HSK HSK Analyzer** (hskhsk.com/analyse): HSK level breakdown per text
- **Chinese Text Analyzer** (chine-culture.com): Junda frequency list analysis

### Academic/Research
- **CRIE (Chinese Readability Index Explorer)**: 82 multilevel linguistic features
- **CkipTagger** (Sinica-Taiwan): POS tagging and tokenization

### Libraries
- **cntext** (Python): Word frequency, readability, sentiment analysis
- **Jieba**: Word segmentation (used by many tools)
- **chinese-text-analyzer** (GitHub): HSK breakdown with Jieba

## Key Insights

1. **Character vs word**: Some systems use character counts, others word counts (ci)
2. **Frequency lists**: Junda, HSK official lists, TOCFL/TBCL lists
3. **Coverage metrics**: "90% coverage at HSK 3" = learner knows 90% of characters
4. **Segmentation required**: Chinese text has no spaces; must tokenize before analysis

## Sources
- [The Newly Revised HSK | What You Need to Know in 2026](https://studycli.org/hsk/the-new-hsk/)
- [Everything You Need to Know About the 2026 HSK Overhaul](https://www.hanyuace.com/blog/everything-about-2026-hsk-overhaul)
- [HSK character list](http://hanzidb.org/character-list/hsk)
- [Hanyu Shuiping Kaoshi - Wikipedia](https://en.wikipedia.org/wiki/Hanyu_Shuiping_Kaoshi)
- [Test of Chinese as a Foreign Language - Wikipedia](https://en.wikipedia.org/wiki/Test_of_Chinese_as_a_Foreign_Language)
- [Understanding TOCFL: The Test of Chinese as a Foreign Language](https://cmn-hant.overseas.ncnu.edu.tw/en/further-study-area/summary-of-indonesia/understanding-tocfl-the-test-of-chinese-as-a-foreign-language/)
- [Chinese Text Analyser](https://www.chinesetextanalyser.com/)
- [CRIE: An automated analyzer for Chinese texts](https://link.springer.com/article/10.3758/s13428-015-0649-1)
- [Analyse Your 汉字 Vocabulary/Text](https://hskhsk.com/analyse)
- [cntext · PyPI](https://pypi.org/project/cntext/)

</TabItem><TabItem value="s2" label="S2: Comprehensive">

# S2: Structure - How CJK Readability Analysis Works

## Core Algorithm Pipeline

```
Raw Chinese Text
    ↓
1. Text Segmentation (word boundary detection)
    ↓
2. Character/Word Frequency Analysis
    ↓
3. Linguistic Feature Extraction
    ↓
4. Readability Classification (HSK/TOCFL level)
```

## 1. Text Segmentation (Jieba Algorithm)

### The Problem
Chinese text has no spaces - "我爱你" could be "我/爱/你" (I/love/you) or "我爱/你" (my love/you). Must determine word boundaries before analysis.

### How Jieba Works
1. **Prefix dictionary structure**: Fast word graph scanning
2. **DAG construction**: Builds directed acyclic graph of all possible word combinations
3. **Dynamic programming**: Identifies most probable combination based on word frequency
4. **HMM for unknowns**: Uses Hidden Markov Model (Viterbi algorithm) for new words not in dictionary
5. **Character-based tagging**: Recognizes new words through statistical character patterns

### Alternatives
- **BERT-based segmentation**: Deep learning approach for specialized domains (geoscience, legal, etc.)
- **CkipTagger** (Sinica-Taiwan): POS tagging + tokenization
- **HanLP**: More sophisticated NLP pipeline

## 2. Character/Word Frequency Analysis

### Frequency Datasets

**SUBTLEX-CH**
- 46.8 million characters from film/TV subtitles
- 33.5 million words
- Psychologically/cognitively relevant (reflects real usage)

**Jun Da Corpus**
- 9,933 characters
- Most common character (的) appears 7,922,684 times
- 1,000 most common = 89% coverage

**FineFreq**
- Web-scale multilingual dataset
- Covers Mandarin + other high-resource languages

### Key Metrics
- **Coverage**: % of text a learner can read at their level
- **Shannon entropy**: Chinese "alphabet" = 9.56 bits/character (much higher than alphabetic languages)
- **Zipf distribution**: Frequency follows power law (few characters = most usage)

## 3. Linguistic Feature Extraction

### Traditional Features (Easy to Count)
- Character count
- Word count
- Average sentence length
- Vocabulary difficulty (based on HSK/TOCFL lists)
- Vocabulary frequency (from frequency corpora)

### Advanced Features (CRIE: 82 total)

**Character Level**
- Total characters
- Unique characters
- Character frequency distribution

**Word Level**
- Word length
- Word frequency
- Vocabulary diversity (type-token ratio)

**Sentence Level**
- Sentence length
- Clause complexity
- Dependency tree depth

**Discourse Level**
- Cohesion metrics
- Semantic relations
- Topic consistency

### CTAP (196 Features)
4 levels: character, word, sentence, discourse
- More comprehensive than CRIE
- Includes syntactic complexity, lexical sophistication

## 4. Readability Classification

### Simple Formula Approach
```
Readability Score = f(characters, words, avg_sentence_length)
```
- Linear regression on 3 variables
- Fast but less accurate
- Good for quick estimates

### Machine Learning Approach (CRIE)

**Training Data**
- Taiwanese primary/secondary school textbooks
- Pre-labeled by grade level (1-9)

**Model: Support Vector Machine (SVM)**
- Learns nonlinear relationships between 70-82 features
- Maps data to high-dimensionality space
- More accurate than linear formulas
- Can provide diagnostic information (which features make text hard?)

**Output**
- Grade level classification (1-9)
- Diagnostic report (which linguistic features contribute to difficulty)

### HSK/TOCFL Level Mapping

**Character Coverage Method**
```python
def get_hsk_level(text, char_freq_dict):
    chars_in_text = set(segment_characters(text))

    for level in [1, 2, 3, 4, 5, 6]:
        known_chars = get_hsk_chars(level)
        coverage = len(chars_in_text & known_chars) / len(chars_in_text)

        if coverage >= 0.95:  # 95% coverage threshold
            return level

    return "above HSK 6"
```

**Vocabulary Coverage Method**
- Same approach but uses words (ci) instead of characters
- More accurate for TOCFL (word-focused)
- Requires segmentation first

## Technical Challenges

1. **Segmentation ambiguity**: "研究生" = "research student" or "research born"?
2. **New words**: Internet slang, neologisms not in dictionaries
3. **Domain-specific vocabulary**: Medical/legal text needs specialized dictionaries
4. **Simplified vs Traditional**: Two character sets with different frequency patterns
5. **Context dependence**: Character difficulty varies by context (的 vs 辩证法)

## Performance Considerations

- **Jieba segmentation**: ~200K chars/second (fast enough for most use cases)
- **Feature extraction**: Depends on depth (CRIE 82 features slower than simple 3-feature formula)
- **SVM prediction**: Fast once trained (~milliseconds per text)
- **Bottleneck**: Usually segmentation + NLP parsing for syntactic features

## Sources
- [Chinese Word Segmentation - The challenges of splitting Chinese](https://medium.com/@ching.achterwinter/chinese-word-segmentation-2e28feee87fe)
- [Chinese Word Segmentation — ENC2045 Computational Linguistics](https://alvinntnu.github.io/NTNU_ENC2045_LECTURES/nlp/chinese-word-seg.html)
- [jieba · PyPI](https://pypi.org/project/jieba/)
- [Chinese Text Readability Assessment Based on Visualized POS Information](https://www.mdpi.com/1999-4893/18/12/777)
- [SUBTLEX-CH: Chinese Word and Character Frequencies](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0010729)
- [CRIE: An automated analyzer for Chinese texts](https://link.springer.com/article/10.3758/s13428-015-0649-1)
- [CTAP for Chinese: A Linguistic Complexity Feature Analysis](https://aclanthology.org/2022.lrec-1.592.pdf)
- [Chinese character frequency and entropy](https://www.johndcook.com/blog/2019/10/18/chinese-character-entropy/)

</TabItem><TabItem value="s3" label="S3: Need-Driven">

# S3: Solutions - Available Tools and Libraries

## Open Source Python Libraries

### 1. HSK Character Profiler
- **Repository**: https://github.com/Ancastal/HSK-Character-Profiler
- **Focus**: HSK-based character proficiency analysis
- **Features**:
  - Identifies HSK level per character in text
  - Generates reports of character counts by HSK level
  - Calculates average HSK level of text
  - Customizable settings
- **Origin**: Master's thesis in Computational Linguistics
- **Best for**: Quick HSK level assessment

### 2. Language-Analyzer
- **Repository**: https://github.com/Ancastal/Language-Analyzer
- **Focus**: Multi-language text analysis
- **Features**:
  - HSK profiling for Chinese
  - Readability analysis (English + Chinese)
  - Advanced text analysis tools
- **Best for**: Projects needing both Chinese and English analysis

### 3. AlphaReadabilityChinese (ARC Chinese)
- **Repository**: https://github.com/leileibama/AlphaReadabilityChinese
- **Developers**: Lei Lei (雷蕾) & Tingyu Zhang (张婷玉), Shanghai International Studies University
- **Features**:
  - Lexical level indices
  - Syntactic level indices
  - Semantic level indices
- **Best for**: Academic research requiring multi-level analysis

### 4. python-readability-cn
- **Repository**: https://github.com/chenryn/python-readability-cn
- **Focus**: Chinese text readability calculation
- **Features**:
  - Word segmentation
  - Part-of-speech analysis
  - Syntactic dependency analysis
  - Multiple NLP provider support (LTP, Jieba, PKU)
  - Scoring metrics named after research authors
- **Best for**: Flexible NLP backend requirements

### 5. Hanzipy
- **Repository**: https://github.com/Synkied/hanzipy
- **Focus**: Chinese character NLP framework
- **Features**:
  - Character processing
  - NLP pipeline for Chinese
  - Learning framework for Chinese language students
- **Best for**: Educational applications, character-level analysis

### 6. CTAP for Chinese
- **Documentation**: https://aclanthology.org/2022.lrec-1.592.pdf
- **Focus**: Linguistic complexity measurement
- **Features**:
  - 196 linguistic complexity measures (most comprehensive)
  - Open-source toolkit
  - 4 levels: character, word, sentence, discourse
- **Best for**: Research requiring comprehensive linguistic features

## Commercial APIs

### 1. LTP-Cloud (Language Technology Platform)
- **Website**: https://www.ltp-cloud.com/intro_en
- **Developer**: Harbin Institute of Technology
- **Features**:
  - Chinese word segmentation
  - POS tagging
  - Dependency parsing
  - Named entity recognition
  - Semantic role labeling
- **Users**: Baidu, Tencent, Huawei, Kingsoft
- **Best for**: Production Chinese NLP at scale
- **Pricing**: Commercial (pay-per-use)

### 2. Google Cloud Natural Language API
- **Website**: https://cloud.google.com/natural-language
- **Features**:
  - Syntactic analysis (Simplified + Traditional Chinese)
  - Sentiment analysis
  - Entity recognition
  - Text annotations
- **Best for**: Multi-language apps (Chinese + other languages)
- **Pricing**: Pay-per-request
  - 0-5K units/month: Free
  - 5K-1M units: $1.00 per 1K units
  - 1M-5M units: $0.50 per 1K units
  - (1 unit = 1,000 characters)

### 3. Tencent Cloud NLP (Hunyuan)
- **Website**: https://www.tencentcloud.com/techpedia/109099
- **Features**:
  - Text generation
  - Sentiment analysis
  - Machine translation
  - Large language model (Hunyuan)
- **Best for**: Chinese market applications, integration with Tencent ecosystem
- **Pricing**: Commercial (contact for pricing)

### 4. NLP Cloud
- **Website**: https://nlpcloud.com/
- **Features**:
  - 200+ language support (including Chinese)
  - Custom model training
  - Pre-trained AI engines
- **Best for**: Multi-language NLP with custom models
- **Pricing**: Starts at $29/month (limited requests)

## Academic Tools

### CRIE (Chinese Readability Index Explorer)
- **Website**: http://www.chinesereadability.net/CRIE/publish.html
- **Paper**: https://link.springer.com/article/10.3758/s13428-015-0649-1
- **Features**:
  - 82 multilevel linguistic features
  - Support Vector Machine (SVM) prediction
  - Grade level classification (1-9)
  - Simplified + Traditional Chinese support
  - Diagnostic readability reports
- **Training data**: Taiwanese primary/secondary school textbooks
- **Status**: Research tool (availability varies)
- **Best for**: Academic research, educational text assessment

## Web-Based Tools (Free)

### 1. Chinese Text Analyser
- **Website**: https://www.chinesetextanalyser.com/
- **Features**:
  - Fast segmentation/analysis (~200-300K characters)
  - Web-based (no installation)
  - Character frequency analysis
- **Best for**: Quick one-off analysis, students

### 2. HSK HSK Analyzer
- **Website**: https://hskhsk.com/analyse
- **Features**:
  - Word and character statistics
  - HSK level breakdown
  - Suggests high-frequency words to learn
- **Best for**: Language learners checking text difficulty

### 3. Chinese Text Analyzer (Chine-culture)
- **Website**: https://new.chine-culture.com/en/chinese-language/resources/chinese-text-analyzer
- **Features**:
  - Junda frequency list analysis
  - Character threshold evaluation
  - Based on Joël Belassen's work
- **Best for**: Frequency-based analysis

## Supporting NLP Tools

### CkipTagger (Sinica-Taiwan)
- **Developer**: Academia Sinica, Taiwan
- **Features**:
  - Chinese word segmentation
  - POS tagging
  - Named entity recognition
- **Best for**: Traditional Chinese, Taiwan-focused applications

### Jieba
- **Repository**: https://github.com/fxsjy/jieba
- **PyPI**: https://pypi.org/project/jieba/
- **Features**:
  - Fast word segmentation (~200K chars/sec)
  - Prefix dictionary + DAG + HMM
  - Customizable dictionary
- **Best for**: Foundation for building custom tools
- **Most widely used**: Nearly all Chinese NLP tools use Jieba or build on it

## Data Resources

### HSK 3.0 Lists (2026)
- **Repository**: https://github.com/krmanik/HSK-3.0
- **Content**:
  - HSK 1-9 characters
  - Handwritten characters
  - Words and grammar lists
  - Anki deck format
  - Frequency, pinyin, zhuyin, meaning

### TOCFL Lists
- **Repository**: https://github.com/skishore/inkstone/pull/47
- **Content**:
  - 華語文能力測驗 (TOCFL) vocabulary
  - Traditional Chinese focus
  - Differences between Simplified/Traditional

### SUBTLEX-CH
- **Paper**: https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0010729
- **Content**:
  - 46.8 million characters from film/TV subtitles
  - 33.5 million words
  - Psychologically/cognitively relevant frequency data

## Comparison Matrix

| Tool | Type | Features | HSK | TOCFL | Traditional | Best For |
|------|------|----------|-----|-------|------------|----------|
| HSK Character Profiler | OSS Python | Character profiling | ✓ | ✗ | ? | Quick HSK assessment |
| AlphaReadabilityChinese | OSS Python | Multi-level indices | ? | ? | ✓ | Academic research |
| python-readability-cn | OSS Python | Multiple backends | ? | ? | ✓ | Flexible NLP needs |
| CTAP | OSS Python | 196 features | ✗ | ✗ | ✓ | Comprehensive analysis |
| CRIE | Academic | 82 features + SVM | ✗ | ✗ | ✓ | Grade level prediction |
| LTP-Cloud | Commercial API | Full NLP pipeline | ✗ | ✗ | ✓ | Production scale |
| Google Cloud NLP | Commercial API | Multi-language | ✗ | ✗ | ✓ | Enterprise apps |
| HSK HSK Analyzer | Web | HSK breakdown | ✓ | ✗ | ? | Students/learners |

## Decision Tree

**For learners checking text difficulty:**
→ Use **HSK HSK Analyzer** (web, free)

**For developers building language learning apps:**
→ Use **HSK Character Profiler** or **Language-Analyzer** (OSS Python)

**For academic research:**
→ Use **CTAP** (most features) or **AlphaReadabilityChinese** (multi-level)

**For production apps at scale:**
→ Use **LTP-Cloud** (Chinese-focused) or **Google Cloud NLP** (multi-language)

**For custom requirements:**
→ Build on **Jieba** + **HSK 3.0 lists** + frequency data

## Sources
- [HSK Character Profiler - GitHub](https://github.com/Ancastal/HSK-Character-Profiler)
- [Language-Analyzer - GitHub](https://github.com/Ancastal/Language-Analyzer)
- [AlphaReadabilityChinese - GitHub](https://github.com/leileibama/AlphaReadabilityChinese)
- [python-readability-cn - GitHub](https://github.com/chenryn/python-readability-cn)
- [Hanzipy - GitHub](https://github.com/Synkied/hanzipy)
- [CTAP for Chinese](https://aclanthology.org/2022.lrec-1.592.pdf)
- [LTP-Cloud](https://www.ltp-cloud.com/intro_en)
- [Google Cloud Natural Language](https://cloud.google.com/natural-language)
- [Tencent Cloud NLP](https://www.tencentcloud.com/techpedia/109099)
- [NLP Cloud](https://nlpcloud.com/)
- [CRIE: An automated analyzer for Chinese texts](https://link.springer.com/article/10.3758/s13428-015-0649-1)
- [Chinese Text Analyser](https://www.chinesetextanalyser.com/)
- [HSK HSK Analyzer](https://hskhsk.com/analyse)
- [HSK 3.0 Lists - GitHub](https://github.com/krmanik/HSK-3.0)
- [TOCFL Lists - Inkstone PR](https://github.com/skishore/inkstone/pull/47)

</TabItem><TabItem value="s4" label="S4: Strategic">

# S4: Synthesis - Strategic Insights and Recommendations

## The Core Value Proposition

CJK readability analysis solves a fundamental problem in Chinese language learning: **knowing whether you can read something before you start**. Unlike English where a learner can attempt any text and struggle through unknown words, Chinese text with too many unknown characters is literally unreadable—you can't even sound words out phonetically.

## When This Technology Matters

### High-Value Use Cases

1. **Educational Content Curation**
   - Language learning platforms (Duolingo, HelloChinese, etc.)
   - Digital libraries for learners (graded readers)
   - Textbook publishers (automatic leveling)

2. **Content Accessibility**
   - News sites with "Easy Chinese" versions
   - Government services (simplified language requirements)
   - Healthcare information (patient education materials)

3. **Language Learning Apps**
   - Automatic text difficulty assessment
   - Personalized content recommendations
   - Progress tracking (reading level advancement)

4. **Content Creation Tools**
   - Writing assistants that flag difficult characters
   - Automatic simplification suggestions
   - Target-level validation for authors

### Low-Value Use Cases

- General-purpose NLP (sentiment analysis, classification) - readability features add noise
- Native speaker applications - they already know all the characters
- Machine translation - different problem space entirely

## Architecture Decision Framework

### Choice 1: Character vs Word-Based Analysis

**Character-based (HSK approach):**
- ✅ Simpler algorithm (just count unique characters)
- ✅ Aligns with how learners actually learn (character lists)
- ✅ Works without perfect segmentation
- ❌ Misses vocabulary complexity (knowing 研 + 究 ≠ knowing 研究 "research")

**Word-based (TOCFL approach):**
- ✅ More accurate for actual reading comprehension
- ✅ Captures vocabulary knowledge, not just characters
- ❌ Requires segmentation (Jieba, adds complexity/errors)
- ❌ Harder to align with learning materials (HSK lists are character-focused)

**Recommendation**: Start character-based for MVP (simpler, faster). Add word-based analysis if you need higher accuracy for advanced learners (HSK 4+).

### Choice 2: Simple vs ML-Based Classification

**Simple coverage formula (character/word coverage at HSK level):**
```python
coverage = known_chars / total_chars_in_text
if coverage >= 0.95: return current_level
```
- ✅ Fast (~milliseconds per text)
- ✅ Easy to debug and explain to users
- ✅ Good enough for most use cases (learner apps, content filters)
- ❌ Ignores linguistic complexity (sentence structure, discourse)
- ❌ Fixed threshold (95% might not be right for everyone)

**ML-based (CRIE-style SVM with 82 features):**
- ✅ More accurate grade level prediction
- ✅ Can provide diagnostic feedback ("too many complex sentences")
- ✅ Learns from real educational materials
- ❌ Slower (requires full NLP pipeline: segmentation, POS, parsing)
- ❌ Black box (harder to explain to users why text is level X)
- ❌ Requires training data (textbooks, labeled corpus)

**Recommendation**:
- **B2C apps** (language learners): Simple coverage formula + Jieba. Users want "HSK 3" or "HSK 4", not detailed diagnostics.
- **B2B tools** (publishers, educators): ML-based if you can afford the complexity. They need fine-grained assessment and diagnostic reports.

### Choice 3: Build vs Buy vs Use Free Tools

**Build your own (Jieba + HSK lists + coverage formula):**
- ✅ Full control over algorithm
- ✅ No API costs (self-hosted)
- ✅ Can customize for your domain (medical, legal, etc.)
- ❌ Maintenance burden (keep HSK lists updated, new 2026 standards)
- ❌ Need NLP expertise (if going beyond simple coverage)
- **Effort**: 1-2 weeks for MVP, ongoing maintenance

**Use free OSS library (HSK Character Profiler, etc.):**
- ✅ Fast time-to-market (days, not weeks)
- ✅ Community-maintained (bug fixes, updates)
- ❌ Less control (tied to library's roadmap)
- ❌ May not match your exact requirements
- **Effort**: 1-3 days integration

**Commercial API (Google Cloud NLP, LTP-Cloud):**
- ✅ Fully managed (no infrastructure)
- ✅ Production-grade (high availability, scaling)
- ❌ Recurring costs (pay-per-request)
- ❌ Lock-in (hard to switch later)
- ❌ Chinese-specific features limited (Google doesn't do HSK levels)
- **Effort**: 1-2 days integration
- **Cost**: Google ~$1/million characters; LTP-Cloud pricing varies

**Free web tools (HSK HSK Analyzer, etc.):**
- ✅ Zero cost, zero effort
- ❌ Not for production use (rate limits, no SLA)
- ❌ Can't integrate into your app
- **Best for**: Manual testing, one-off analysis

**Recommendation**:
- **MVP/prototype**: Free OSS library (HSK Character Profiler) or build simple coverage formula (1 day)
- **Production app (< 1M texts/month)**: Build your own (Jieba + HSK lists)
- **Production app (> 1M texts/month)**: Commercial API if you need multi-language NLP; otherwise still self-host for cost savings
- **Enterprise/publishers**: CRIE-style ML system (hire NLP consultants or build in-house)

### Choice 4: HSK vs TOCFL vs Both

**HSK 3.0 (2026 standard, 9 levels):**
- ✅ Larger user base (mainland China market)
- ✅ More resources (apps, textbooks, word lists)
- ✅ New 2026 standard more comprehensive
- ❌ Simplified Chinese focus

**TOCFL (Taiwan, 8 levels):**
- ✅ Traditional Chinese focus
- ✅ Word-based (better for comprehension)
- ❌ Smaller ecosystem (fewer learning resources)
- ❌ Less data available (character/word lists harder to find)

**Both:**
- ✅ Cover entire Chinese-speaking market
- ❌ More complexity (maintain two systems)
- ❌ User confusion (which standard to show?)

**Recommendation**:
- **Mainland China market**: HSK only
- **Taiwan/Hong Kong market**: TOCFL preferred, HSK as fallback
- **Global market**: HSK primary, add TOCFL if you have Traditional Chinese users (> 20% of base)

## Hidden Complexity and Gotchas

### 1. Segmentation Errors Cascade
Jieba accuracy: ~95% for general text. But errors in segmentation cause errors in readability analysis:
- "研究生" segmented as "研究" + "生" instead of "研究生" → wrong HSK level
- Domain-specific terms (medical, legal) often mis-segmented
- **Mitigation**: Use domain-specific dictionaries (Jieba supports custom dicts)

### 2. HSK 3.0 Migration (2026)
New standard effective July 2026. 9 levels instead of 6. Character/word requirements changed.
- Old HSK 6 ≠ new HSK 6 (different word counts)
- Need to update word lists, retrain models
- **Mitigation**: Maintain both HSK 2.0 and HSK 3.0 mappings during transition (2026-2027)

### 3. Context-Dependent Difficulty
Character frequency ≠ character difficulty in context:
- 的 (de, particle): most common character, learned in HSK 1
- 辩证法 (dialectics): rare but each character individually might be HSK 3-4
- Idioms (成语): 4 characters that must be learned as unit, not individually
- **Mitigation**: Use word-based analysis for HSK 4+; flag idioms separately

### 4. Traditional vs Simplified Mapping
Not 1:1 correspondence:
- 台 (simplified) → 臺/台 (traditional) - same character, different meanings
- 后 (simplified) → 後/后 (traditional) - two different words merged
- **Mitigation**: Use proper conversion libraries (OpenCC), maintain separate frequency lists

### 5. Coverage Threshold is Arbitrary
95% coverage = readable? Depends on:
- Text type (narrative easier than academic)
- Learner background (heritage speakers vs beginners)
- Glossary availability (can look up 5% unknown words?)
- **Mitigation**: Make threshold configurable (90-98%), A/B test optimal value for your users

## Cost Modeling

### DIY Approach (Jieba + HSK lists)
**Setup**: 1-2 weeks dev time (~$5K-$10K if outsourced)
**Hosting**: ~$20-50/month (1M texts/month on modest server)
**Maintenance**: 4-8 hours/quarter (update word lists, bug fixes)
**Total Year 1**: ~$7K-$12K (mostly upfront dev)

### Commercial API (Google Cloud NLP)
**Setup**: 1-2 days integration (~$1K)
**Usage**: $1 per 1M characters analyzed (after 5M free tier)
**Maintenance**: ~0 (fully managed)
**Total Year 1 at 10M texts (~50M characters)**: ~$1K setup + $45 usage = $46K

**Break-even**: ~5M texts/year (or ~420K texts/month) - beyond this, DIY is cheaper

### OSS Library (HSK Character Profiler)
**Setup**: 1-3 days integration (~$500-$1.5K)
**Hosting**: $0 (runs in your app)
**Maintenance**: ~2 hours/quarter (library updates)
**Total Year 1**: ~$1K-$2K

**ROI sweet spot**: 100K-1M texts/month. Below that, use web tools. Above that, consider custom build for more control.

## Implementation Roadmap

### Phase 1: MVP (Week 1)
- Integrate HSK Character Profiler or build simple coverage formula
- Use HSK 3.0 character lists (GitHub: krmanik/HSK-3.0)
- Simple API: `POST /analyze` with `{text: "...", standard: "hsk"}` → `{level: 3, coverage: 0.94}`
- Test with sample texts at known levels

### Phase 2: Production (Weeks 2-4)
- Add Jieba for word segmentation (if word-based analysis needed)
- Implement caching (Redis) for frequently analyzed texts
- Add metrics (latency, accuracy vs human labels)
- Deploy with proper error handling

### Phase 3: Enhancement (Months 2-3)
- Custom dictionaries for your domain
- Support Traditional Chinese + TOCFL
- Diagnostic reports (which characters/words are too hard?)
- A/B test coverage thresholds

### Phase 4: ML (Months 4-6, optional)
- Collect labeled training data (texts + human-assessed levels)
- Train SVM with CTAP features or simpler model
- Compare accuracy vs coverage formula
- Deploy if significant improvement (> 10% accuracy gain)

## Key Success Metrics

1. **Accuracy**: % agreement with human assessors on text level
   - Target: 80-90% exact match, 95%+ within ±1 level
2. **Coverage**: % of texts that get a confident level prediction
   - Target: > 95% (few "unknown level" results)
3. **Latency**: Time to analyze typical text
   - Target: < 100ms for 1000 characters (simple), < 500ms (ML-based)
4. **User satisfaction**: Do learners find texts at recommended level readable?
   - Target: > 80% report "just right" difficulty (not too easy/hard)

## The Bigger Picture

### Market Trends
- Chinese learner population growing (300M+ worldwide)
- Digital learning platforms expanding (COVID-19 accelerated shift)
- HSK 3.0 (2026) creating demand for updated tools
- AI/LLM integration opportunity (auto-generate level-appropriate content)

### Adjacent Technologies
- **Content generation**: LLMs that write at target HSK level
- **Personalization**: Adaptive learning paths based on reading level
- **Translation**: Simplify-for-learners translation (not just English-Chinese)
- **Speech**: Readability analysis for spoken content (podcast transcripts)

### Future Research Directions
- **Multimodal**: Images + text (children's books, comics)
- **Dialogue**: Conversational difficulty vs written text
- **Cultural load**: Idioms, cultural references independent of language level
- **Error prediction**: Which characters will THIS learner struggle with? (personalized beyond HSK)

## Bottom Line Recommendations

**If you're building a language learning app:**
→ Start with **HSK Character Profiler** (OSS, free, 1-day integration)
→ Upgrade to **custom Jieba + HSK 3.0 lists** when you hit 100K texts/month
→ Stick with simple coverage formula unless you need fine-grained diagnostics

**If you're a publisher/educator:**
→ Invest in **CRIE-style ML system** (hire consultants, 3-6 months)
→ Use **CTAP features** for comprehensive analysis
→ Build internal tools for authors (real-time difficulty feedback as they write)

**If you're a researcher:**
→ Use **CTAP** (196 features, most comprehensive)
→ Compare ML models (SVM vs neural networks vs LLM-based)
→ Publish open datasets (labeled texts + human assessments)

**If you're just exploring:**
→ Use **HSK HSK Analyzer** (web, free) for one-off analysis
→ Read **CRIE paper** for methodology deep-dive
→ Experiment with **Jieba** to understand segmentation challenges

The technology is mature, tools exist, and the use cases are clear. The main decision is build-vs-buy and simple-vs-ML, which depends entirely on your scale and accuracy requirements.

</TabItem><TabItem value="explainer" label="Explainer">

# CJK Readability Analysis

## What This Solves

Imagine giving someone a book in a language they're learning. In alphabetic languages like English or Spanish, they can at least attempt every word—sound it out, guess from context, look it up. In Chinese, if they don't know a character, they're completely stuck. They can't sound it out phonetically. They can't even look it up easily without knowing how to write it or the pronunciation.

CJK readability analysis solves this fundamental problem: **determining whether a Chinese learner can actually read a piece of text before they waste time trying**. It takes any Chinese text and answers: "What proficiency level (HSK 1-6, TOCFL levels, etc.) does someone need to understand this?"

This matters to three groups:

1. **Language learning platforms** need to match content to learner levels automatically (you can't have humans reading every article)
2. **Content creators** need to know if they're writing at the right difficulty (textbook authors, simplified news sites)
3. **Learners themselves** want to find materials they can actually read (not too easy, not impossibly hard)

Without automated analysis, these groups resort to manual assessment (expensive, slow) or guess-and-check (frustrating for learners).

## Accessible Analogies

Think of Chinese characters like a massive LEGO collection with 3,000+ unique pieces. Learning Chinese means gradually acquiring these pieces:

- **HSK 1** learner: 300 pieces (can build simple structures)
- **HSK 6** learner: 2,500 pieces (can build complex models)

Now imagine you want to give someone assembly instructions. Before handing them over, you scan the instruction manual: "This design requires 847 different LEGO pieces. Do you have them all?"

That's readability analysis. It looks at the text (the instruction manual), counts which unique characters (LEGO pieces) are needed, and compares against standardized learner levels.

The challenge: Unlike LEGO where you can see which pieces you need, Chinese text doesn't have spaces between words. It's like a bag of attached LEGO pieces you need to separate first. This separation step (called "segmentation") is why Chinese readability analysis is more complex than counting words in English.

**Another angle**: Character frequency works like cooking skills. Common characters (的, 是, 我) are like salt and pepper—used in almost every dish, learned first. Rare characters (辩证法 "dialectics") are like saffron—specialized, learned later. Readability analysis counts how much "saffron" vs "salt" is in a text to determine if a beginner cook can handle the recipe.

## When You Need This

**You definitely need this if:**

- You run a language learning app and want to recommend content automatically ("here are 10 articles at your level")
- You're building a digital library with graded readers and need to categorize thousands of texts
- You create educational materials and want real-time feedback on whether you're writing at the target level
- You manage a news site offering "Easy Chinese" versions and need to validate simplifications

**You probably need this if:**

- You're designing accessibility features for Chinese content (simplified government documents, healthcare info)
- You're researching second-language acquisition and need to control for text difficulty
- You're building translation tools that should simplify for learners, not just translate accurately

**You DON'T need this if:**

- Your users are native speakers (they already know all common characters)
- You're doing general NLP (sentiment analysis, classification) where readability is irrelevant
- You're working with non-Chinese languages (completely different problem—this research doesn't transfer)

**The decision hinges on**: Are you matching content difficulty to learner proficiency at scale? If yes, automate. If it's a one-time task, use free web tools.

## Trade-offs

### Simple vs Sophisticated

**Coverage formula approach** (count characters known at HSK level X):
- ✅ Fast (milliseconds per text)
- ✅ Easy to explain to users ("You know 94% of characters = HSK 3")
- ✅ Works well for learner apps (good enough accuracy)
- ❌ Ignores sentence complexity, discourse structure
- ❌ Assumes all HSK 3 characters are equally difficult (not true)

**Machine learning approach** (82+ linguistic features):
- ✅ More accurate (accounts for sentence structure, vocabulary patterns)
- ✅ Can provide diagnostics ("too many compound sentences for this level")
- ❌ Slower (requires full NLP pipeline: segmentation, parsing, POS tagging)
- ❌ Harder to explain ("the SVM says it's level 5" doesn't help users understand why)
- ❌ Requires training data (labeled textbooks, expert assessments)

Most language learning apps use the simple approach. Publishers and educators use ML when they need fine-grained assessment and can afford the complexity.

### Character-Based vs Word-Based

**Character-based** (HSK lists are characters):
- ✅ Aligns with how learners study (character lists, flashcards)
- ✅ Simpler implementation (no word segmentation needed)
- ❌ Misses vocabulary nuance (knowing 研 + 究 individually doesn't mean you know 研究 "research" as a word)

**Word-based** (TOCFL focuses on vocabulary):
- ✅ Better reflects actual reading comprehension
- ✅ More accurate for intermediate/advanced learners
- ❌ Requires accurate word segmentation (adds complexity, potential errors)
- ❌ Harder to align with learning materials (most resources teach characters, not word lists)

The trend is starting with characters (MVP) and adding word-based analysis for advanced learners.

### Build vs Buy

**Self-hosted** (use open-source libraries, HSK word lists):
- ✅ No recurring costs (just server hosting)
- ✅ Full control over algorithm, customization
- ❌ Initial development time (1-2 weeks for basic version)
- ❌ Maintenance burden (keep HSK lists updated, handle edge cases)

**Commercial API** (Google Cloud NLP, LTP-Cloud):
- ✅ Fast integration (1-2 days)
- ✅ Fully managed (no infrastructure worries)
- ❌ Recurring costs (~$1 per million characters analyzed)
- ❌ Less control (can't customize for your domain)
- ❌ APIs don't specifically support HSK levels (you'd still build that layer)

Break-even point: If you're analyzing more than ~5 million texts per year, self-hosting becomes cheaper.

## Cost Considerations

**Free tier** (web tools like HSK Analyzer):
- Good for manual testing, one-off analysis
- Not for production use (rate limits, no API)

**DIY approach**:
- Development: ~$5K-$10K (1-2 weeks)
- Hosting: $20-50/month for 1M texts/month
- Year 1 total: ~$7K-$12K

**Commercial APIs**:
- Google Cloud NLP: $1 per 1M characters after 5M free tier
- At 50M characters/year: ~$45/year in API costs
- But APIs don't give you HSK levels—you still build that logic yourself
- Better suited if you need multi-language NLP beyond just Chinese readability

**Open-source libraries** (HSK Character Profiler, etc.):
- Integration: $500-$1.5K (1-3 days)
- Hosting: $0 (runs in your app)
- Year 1 total: ~$1K-$2K
- Sweet spot for most language learning apps

**Enterprise/Academic** (CRIE-style ML system):
- Development: $50K-$100K (3-6 months, requires NLP expertise)
- Only makes sense if you need research-grade accuracy and diagnostic features
- For publishers, large educational institutions

The pattern: Start cheap with open-source libraries. Upgrade to custom build if you hit scale or need specific features. Only go commercial API if you're already using those platforms for other NLP tasks.

## Implementation Reality

### First 30 Days

Week 1: Integrate an open-source library (HSK Character Profiler) or build a simple coverage formula. You'll have a working prototype that can say "this text is HSK 3" with ~80% accuracy.

Weeks 2-4: Add caching (texts get analyzed repeatedly), error handling, and tests against sample texts at known levels. Deploy with basic API endpoint.

### What Actually Takes Time

1. **Segmentation edge cases**: Medical terms, internet slang, names—Jieba will mess these up. You'll need custom dictionaries.
2. **HSK 3.0 migration**: New standard takes effect July 2026. You'll maintain two versions during transition (2026-2027).
3. **Threshold tuning**: Is 95% character coverage "readable"? Depends on your users. Expect A/B testing to find the right balance.
4. **Traditional vs Simplified**: Not a 1:1 character mapping. Need separate frequency lists and proper conversion libraries.

### Common Pitfalls

- **Assuming perfect segmentation**: Jieba is ~95% accurate. That 5% error rate cascades into readability errors.
- **Treating all HSK 3 characters as equally difficult**: Frequency and context matter. 的 (most common character) vs 辩证法 (rare academic term).
- **Ignoring idioms**: 成语 (4-character idioms) must be learned as units, not as individual characters.
- **Over-engineering for MVP**: Start with character coverage. Don't build the ML system until you know you need it.

### Team Skills Required

- **Basic version**: One Python developer familiar with pip install and REST APIs (junior level is fine)
- **Production version**: Mid-level developer who can handle caching, error handling, deployment
- **ML version**: NLP engineer or data scientist with experience in text classification, training ML models

Most teams can ship a working readability analyzer in 1-2 weeks without NLP expertise. The sophisticated stuff (CRIE-level) is a multi-month project requiring specialists.

### Realistic Expectations

You'll get 80-90% agreement with human assessors on exact level match, 95%+ within ±1 level. That's good enough for learner apps. If you need research-grade precision, budget for the ML approach and several months of development.

The technology is mature. The tools exist. The main challenge is deciding how much accuracy you need versus how much complexity you can handle.

</TabItem>
</Tabs>
