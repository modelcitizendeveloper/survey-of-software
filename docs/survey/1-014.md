---
id: 1-014
title: "1.014 Network Flow"
sidebar_label: "1.014 Network Flow"
description: "Research on Network Flow"
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 1.014 Network Flow



---

<Tabs>
<TabItem value="s1" label="S1: Rapid Discovery" default>

# S1 Rapid Discovery: Network Flow Libraries

## Discovery Approach

Ecosystem-driven survey of network flow libraries across Python, C++, and specialized optimization frameworks.

**Focus areas:**
- Maximum flow algorithms (Ford-Fulkerson, Edmonds-Karp, Push-Relabel)
- Minimum cost flow algorithms
- Library maturity and maintenance status
- Performance characteristics for production use
- Integration complexity

**Time investment:** 10-15 minutes per library
**Sources:** GitHub stats, PyPI downloads, Stack Overflow sentiment, official documentation


---

# graph-tool (Python)

**GitLab:** Not disclosed | **Ecosystem:** Python (C++ core) | **License:** LGPL-3.0

## Positioning

High-performance graph analysis library built on C++ and Boost Graph Library. Designed for researchers needing maximum speed with large-scale networks (millions of nodes). Steepest learning curve, highest performance.

## Key Metrics

- **Performance:** C++ template metaprogramming (fastest Python graph library)
- **Download stats:** Smaller user base (conda-forge primary distribution)
- **Maintenance:** Active development since 2014, 3,730 commits, 150 tags
- **Python versions:** Supports current Python versions
- **Author:** Tiago de Paula Peixoto (network science researcher)

## Algorithms Included

### Maximum Flow
- `edmonds_karp_max_flow()` - O(VE²) or O(VEU) for integer capacities
- `push_relabel_max_flow()` - O(V³) complexity (recommended)
- `boykov_kolmogorov_max_flow()` - specialized variant

All algorithms leverage Boost Graph Library's optimized C++ implementations.

## Community Signals

**Stack Overflow sentiment:**
- "graph-tool when you need absolute maximum performance in Python"
- "Installation can be painful, but worth it for large graphs"
- "Best for academic work with millions of nodes"

**Common use cases:**
- Large-scale network science research (millions of nodes)
- Biological networks (protein interactions, gene regulatory networks)
- Social network analysis at web scale
- Computational neuroscience (brain connectivity graphs)
- Statistical inference on networks (Bayesian models)

## Trade-offs

**Strengths:**
- Fastest graph library for Python (C++ template metaprogramming)
- Scales to millions of nodes/edges
- Comprehensive statistical inference tools (unique among graph libraries)
- LGPL license (more permissive than GPL)
- Advanced algorithms for community detection, graph drawing
- 15+ years of cutting-edge network science development

**Limitations:**
- **Difficult installation** (conda-forge recommended, pip can be problematic)
- Steep learning curve (C++ concepts leak into Python API)
- Smaller community than NetworkX/igraph
- Less documentation and fewer examples
- Requires understanding of Boost Graph Library concepts
- Not suitable for casual graph exploration
- Breaking changes more common than NetworkX

## Decision Context

**Choose graph-tool when:**
- Working with graphs `&gt;1`M nodes
- Performance is critical (research deadlines, production scale)
- Need statistical inference on network structure (Stochastic Block Models)
- Comfortable with C++ concepts and Boost documentation
- Willing to invest in learning curve for long-term performance

**Skip if:**
- Graph `&lt;100`K nodes (NetworkX is easier)
- Prototyping or teaching (complexity not justified)
- Installation/deployment simplicity required
- Team lacks C++/Boost background
- Need operations research features (use OR-Tools instead)


---

# igraph (Python/R/C)

**GitHub:** ~1.4K stars (python-igraph) | **Ecosystem:** Python, R, C | **License:** GPL-2.0

## Positioning

Fast C-based graph library with Python and R bindings. Middle ground between NetworkX's ease of use and graph-tool's extreme performance. Popular in academic network science.

## Key Metrics

- **Performance:** C core with Python bindings (5-20x faster than pure Python)
- **Download stats:** `&gt;50`M total downloads (50x less than NetworkX as of 2024)
- **Maintenance:** Active development, v1.0.0 released Oct 2025 (C core)
- **Python versions:** 3.9-3.13 supported, PyPy compatible (3x slower than CPython)
- **Contributors:** 72+ contributors, 3,276 commits

## Algorithms Included

### Maximum Flow
- `Graph.maxflow()` - computes max flow with edge capacities
- Returns `Flow` object with:
  - Flow values on each edge
  - Minimal cut information
  - Source/sink partition data

### Implementation
Based on Boost Graph Library algorithms, compiled C code for performance.

## Community Signals

**Stack Overflow sentiment:**
- "igraph when you need C speed but want Python/R convenience"
- "R users: igraph is the go-to for network analysis"
- "More networkx-like API than graph-tool, but faster"

**Common use cases:**
- Social network analysis in R
- Community detection workflows
- Moderate-scale graph analysis (10K-1M nodes)
- Cross-language research (Python prototyping, R visualization)
- Academic publications requiring reproducible results

## Trade-offs

**Strengths:**
- Better performance than NetworkX (C core)
- Mature codebase (15+ years)
- R integration (large user base in statistics)
- Comprehensive graph algorithms beyond flow
- Pre-compiled wheels for easy installation
- Dual Python/R API (learn once, use in both languages)

**Limitations:**
- GPL license (more restrictive than BSD/Apache)
- Smaller Python community than NetworkX
- Documentation less extensive than NetworkX
- Slower than graph-tool for very large graphs
- Limited constraint programming features compared to OR-Tools
- Installation requires C/C++/Fortran compilers for source builds

## Decision Context

**Choose igraph when:**
- Need better performance than NetworkX but simpler than graph-tool
- Working in R ecosystem (statistics, bioinformatics)
- Graph size: 100K-1M nodes
- Want C-level speed without learning graph-tool's complexity
- Need cross-platform reproducibility (Python + R)

**Skip if:**
- Pure Python simplicity preferred (use NetworkX)
- Extreme performance required (use graph-tool or OR-Tools)
- GPL license incompatible with project
- Need operations research features (use OR-Tools)
- Graph `&lt;10`K nodes (NetworkX is good enough)


---

# NetworkX (Python)

**GitHub:** ~16K stars | **Ecosystem:** Python | **License:** BSD-3-Clause

## Positioning

Pure Python graph library with comprehensive network flow algorithms. De facto standard for graph analysis in Python data science and research workflows.

## Key Metrics

- **Performance:** Pure Python implementation (slower than C++ bindings for large-scale problems)
- **Download stats:** ~15M downloads/week on PyPI (Jan 2026)
- **Maintenance:** Active development since 2002, stable 3.x release line
- **Python versions:** 3.9+ supported (3.6.1 current as of Jan 2026)

## Algorithms Included

### Maximum Flow
- Ford-Fulkerson (via Edmonds-Karp)
- Preflow-push (default, fastest)
- Shortest augmenting path
- Dinitz's algorithm

### Minimum Cost Flow
- `min_cost_flow()` - satisfies all node demands
- `max_flow_min_cost()` - max flow with minimum cost
- `capacity_scaling()` - successive shortest path algorithm

## Community Signals

**Stack Overflow sentiment:**
- "NetworkX is the standard for graph problems in Python - start here unless you need extreme performance"
- "For research and prototyping, NetworkX is unbeatable for API clarity"
- "Production systems with `&gt;100`K nodes should consider igraph or graph-tool"

**Common use cases:**
- Academic research in network science
- Data science workflows (Jupyter notebooks)
- Supply chain optimization (moderate scale)
- Social network analysis
- Transportation routing (small to medium graphs)

## Trade-offs

**Strengths:**
- Excellent documentation and tutorials
- Clean, Pythonic API - easy to learn
- Rich ecosystem integration (NumPy, SciPy, Pandas)
- Comprehensive algorithm coverage beyond flow (centrality, clustering, etc.)
- Easy visualization with matplotlib integration

**Limitations:**
- Pure Python performance penalty (10-100x slower than C++ implementations)
- Not suitable for graphs with `&gt;1`M edges in production
- Floating-point weights can cause numerical issues in flow algorithms
- Higher memory overhead compared to C++-backed libraries

## Decision Context

**Choose NetworkX when:**
- Prototyping network algorithms rapidly
- Working in Jupyter/academic environment
- Graph size `&lt;100`K nodes
- API clarity and documentation matter more than raw speed
- Need broad algorithm coverage beyond just flow

**Skip if:**
- Processing `&gt;1`M edge graphs regularly
- Flow computations are in critical performance path
- Need sub-second latency for routing queries
- Building production logistics/supply chain systems (use OR-Tools instead)


---

# OR-Tools (Multi-language)

**GitHub:** ~13K stars | **Ecosystem:** C++, Python, Java, C# | **License:** Apache 2.0

## Positioning

Google's production-grade combinatorial optimization suite with specialized, highly optimized network flow solvers. Industry standard for logistics, supply chain, and operations research.

## Key Metrics

- **Performance:** C++ core with optimized algorithms (10-100x faster than pure Python)
- **Download stats:** Enterprise usage (exact PyPI stats not public)
- **Maintenance:** Active Google development, v9.15 released Jan 2026
- **Language support:** First-class APIs for C++, Python, Java, C#
- **Contributors:** 151 people, 15,808 commits

## Algorithms Included

### Maximum Flow
- `SimpleMaxFlow` solver - optimized for basic max flow problems

### Minimum Cost Flow
- `SimpleMinCostFlow` solver - standard min cost flow
- `SolveMaxFlowWithMinCost()` - max flow with min cost variant
- Methods: `AddArcWithCapacityAndUnitCost`, `SetNodeSupply`

## Community Signals

**Stack Overflow sentiment:**
- "OR-Tools for production logistics - battle-tested at Google scale"
- "If you're building a real supply chain system, skip everything else and use OR-Tools"
- "Steeper learning curve than NetworkX, but worth it for performance"

**Common use cases:**
- Supply chain optimization (flow of goods through warehouses)
- Transportation routing with capacity constraints
- Task assignment with resource limits
- Network capacity planning
- Production systems requiring sub-second latency

## Trade-offs

**Strengths:**
- Production-grade performance and reliability (Google's internal tooling)
- Comprehensive documentation with multi-language examples
- Constraint programming (CP-SAT) integration for complex problems
- Specialized solvers tuned for specific problem types
- Cross-platform wheels (Python installation via pip)
- Winning gold medals in MiniZinc Challenge (solver competitions)

**Limitations:**
- Heavier dependency (larger binary size due to C++ core)
- Steeper learning curve than pure Python libraries
- API verbosity compared to NetworkX
- Requires understanding of operations research concepts
- Less suitable for ad-hoc graph exploration

## Decision Context

**Choose OR-Tools when:**
- Building production systems with hard performance requirements
- Graphs have `&gt;100`K nodes or time-critical routing
- Need constraint programming beyond basic flow
- Working on logistics, supply chain, or scheduling problems
- Require multi-language deployment (Python backend, Java frontend)

**Skip if:**
- Prototyping or research (NetworkX is easier)
- Graph algorithms beyond optimization (centrality, clustering)
- Team lacks OR/optimization background
- Simple problems solvable in `&lt;1` second with pure Python


---

# S1 Recommendation: Network Flow Libraries

## Quick Decision Matrix

| Library | Best For | Performance Tier | Ease of Use | License |
|---------|----------|------------------|-------------|---------|
| **NetworkX** | Prototyping, research, `&lt;100`K nodes | ⭐ Slowest | ⭐⭐⭐ Easiest | BSD (permissive) |
| **igraph** | R users, mid-scale (100K-1M nodes) | ⭐⭐ Fast | ⭐⭐ Moderate | GPL-2.0 |
| **OR-Tools** | Production logistics, optimization | ⭐⭐⭐ Very Fast | ⭐ Complex | Apache 2.0 |
| **graph-tool** | Research, `&gt;1`M nodes, max performance | ⭐⭐⭐⭐ Fastest | ⭐ Difficult | LGPL-3.0 |

## Primary Recommendation by Use Case

### "I need to prototype a supply chain model for a presentation next week"
→ **NetworkX**
Clean API, excellent docs, fast development velocity. Performance won't matter for demo data.

### "I'm building a production routing system for a logistics company"
→ **OR-Tools**
Battle-tested at Google scale. Worth the learning curve for performance and reliability.

### "I'm analyzing Twitter follower graphs with 10M users"
→ **graph-tool**
Only library that will handle this scale without choking. Be prepared to debug installation.

### "I'm a statistician who primarily works in R"
→ **igraph**
Dual Python/R API means you learn once, use everywhere. Strong academic community.

## The Performance-Complexity Trade-off

```
Ease of Use  ←→  Raw Performance
NetworkX ← igraph ← OR-Tools ← graph-tool
```

**Key insight:** Most projects start with NetworkX, then migrate to OR-Tools (if building products) or graph-tool (if doing research) when performance becomes critical. igraph sits in the middle for R users or those wanting better-than-NetworkX speed without extreme complexity.

## Red Flags

**Don't use NetworkX if:**
- Processing `&gt;100`K nodes repeatedly in production
- Flow computations must complete in `&lt;100`ms
- Building commercial logistics software

**Don't use OR-Tools if:**
- Just exploring graph properties (centrality, clustering, visualization)
- Team has no operations research background
- Problem is simple enough for NetworkX

**Don't use graph-tool if:**
- Graph size `&lt;100`K nodes (overkill)
- Installation/deployment complexity is a blocker
- Need operations research features (assignment, scheduling)

**Don't use igraph if:**
- Pure Python preferred (NetworkX is cleaner)
- Already invested in NetworkX ecosystem
- GPL license problematic for your project

## Strategic Guidance

1. **Start with NetworkX** for prototyping (always)
2. **Benchmark with real data** before committing to migration
3. **Consider OR-Tools** if building products (Apache license, Google support)
4. **Consider graph-tool** if doing research (LGPL license, academic focus)
5. **Consider igraph** if R is part of your workflow

**The 90% rule:** NetworkX solves 90% of network flow problems people actually encounter. Only move to specialized tools when you've proven NetworkX won't work.

</TabItem><TabItem value="s2" label="S2: Comprehensive">

# S2 Comprehensive Analysis: Network Flow Libraries

## Analysis Framework

Deep technical comparison across algorithm implementations, API design, performance characteristics, and architectural patterns.

**Evaluation dimensions:**
- Algorithm implementations (Ford-Fulkerson, Edmonds-Karp, Push-Relabel, variants)
- API ergonomics and developer experience
- Performance benchmarks (small/medium/large graphs)
- Memory efficiency and scalability limits
- Integration patterns with numerical computing stacks

**Methodology:**
- Official documentation analysis
- Algorithm complexity verification
- API pattern extraction via code examples
- Community benchmark aggregation
- Cross-library feature mapping

**Time investment:** 30-45 minutes per library


---

# igraph: Comprehensive Technical Analysis

## Architecture Overview

C library core with idiomatic Python (and R) bindings. Built on Boost Graph Library algorithms but wraps them in more accessible API. Balances performance with usability.

**Core philosophy:** Fast enough for most research, simple enough for rapid development. Academic network science focus.

## Maximum Flow Algorithms

### Primary Implementation
- **Algorithm:** Push-relabel (via Boost Graph Library)
- **Complexity:** O(V²√E) for bipartite graphs, O(V³) general case
- **Implementation:** C core, minimal Python overhead

**Key characteristic:** Single `maxflow()` method handles all cases, automatically selects appropriate variant based on graph structure.

## API Patterns

### Basic Max Flow
```python
import igraph as ig

# Create directed graph
g = ig.Graph(
    6,  # Number of vertices
    [(0, 1), (0, 2), (1, 3), (2, 3), (2, 4), (3, 5), (4, 5)],
    directed=True
)

# Assign edge capacities
g.es["capacity"] = [7, 8, 1, 2, 3, 4, 5]

# Compute max flow
flow = g.maxflow(source=0, target=5, capacity="capacity")

print(f"Max flow value: {flow.value}")  # Total flow
print(f"Edge flows: {flow.flow}")       # Flow on each edge
print(f"Min cut: {flow.cut}")           # Edges in minimum cut
print(f"Partition: {flow.partition}")   # Source-side nodes in cut
```

### Flow Object Structure
```python
# flow is a Flow object with attributes:
flow.value       # float: maximum flow value
flow.flow        # list: flow on each edge (same order as g.es)
flow.cut         # list of edge IDs in minimum cut
flow.partition   # list of 0/1 indicating partition membership
```

### Alternative: Explicit Edge List
```python
# Use edge IDs instead of edge attribute name
capacities = g.es["capacity"]
flow = g.maxflow(0, 5, capacity=capacities)
```

## Performance Characteristics

### Time Complexity Summary
| Graph Size | Runtime (estimate) |
|------------|--------------------|
| 100 nodes, 500 edges | `&lt;5`ms |
| 1K nodes, 5K edges | 20-100ms |
| 10K nodes, 50K edges | 500ms-5s |
| 100K nodes, 1M edges | 1-10 minutes |

**5-20x faster than NetworkX**, **2-5x slower than graph-tool**.

### Memory Overhead
- **Graph storage:** ~100 bytes/edge (C structs + Python wrappers)
- **Flow computation:** O(E) for residual network
- **Rule of thumb:** 1M edges ≈ 100MB memory

### Numerical Handling
- **Floating-point capacities supported** (unlike OR-Tools SimpleMinCostFlow)
- **Precision:** Double-precision floats (IEEE 754)
- **No overflow protection:** Large integer capacities may lose precision

## API Design Philosophy

### Strengths
- **Single method interface:** `maxflow()` does everything
- **Rich return object:** Value, flow, cut, partition all in one result
- **Pythonic containers:** Edge/vertex sequences with attribute access
- **Flexible node IDs:** Integer-indexed (0 to N-1) but can use names via attributes

### Pain Points
- **Integer vertex IDs required:** No arbitrary hashable types like NetworkX
- **Graph mutability:** Must recompute flow if graph changes (no incremental updates)
- **Limited min cost flow:** No built-in min cost flow solver (max flow only)
- **R-influenced API:** Some methods named for R conventions, not Python idioms

## Integration Patterns

### With NumPy
```python
import numpy as np

# Create graph from adjacency matrix
adj_matrix = np.array([[0, 7, 8, 0, 0, 0],
                        [0, 0, 0, 1, 0, 0],
                        [0, 0, 0, 2, 3, 0],
                        [0, 0, 0, 0, 0, 4],
                        [0, 0, 0, 0, 0, 5],
                        [0, 0, 0, 0, 0, 0]])

g = ig.Graph.Weighted_Adjacency(adj_matrix.tolist(), mode="directed", attr="capacity")
```

### With NetworkX (Migration Pattern)
```python
import networkx as nx

# Prototype in NetworkX
G_nx = nx.DiGraph()
# ... build graph ...

# Convert to igraph for better performance
G_ig = ig.Graph.from_networkx(G_nx)

# Run flow computation
flow = G_ig.maxflow(source_name, target_name, capacity="capacity")
```

### With R (Cross-Language Workflow)
```r
# R code using same igraph library
library(igraph)
g <- graph_from_edgelist(edges, directed=TRUE)
E(g)$capacity <- capacities
flow <- max_flow(g, source=1, target=6)
```

## Specialized Use Cases

### Bipartite Matching
```python
# Create bipartite graph
g = ig.Graph.Bipartite([0,0,0,1,1,1],  # Type indicators
                        [(0,3), (0,4), (1,3), (1,5), (2,4), (2,5)])

# Max matching via max flow
matching = g.maximum_bipartite_matching()
# Returns Matching object with matched pairs
```

### Min Cut Visualization
```python
import matplotlib.pyplot as plt

flow = g.maxflow(source, target, capacity="capacity")

# Color edges in min cut
edge_colors = ["red" if e in flow.cut else "black"
               for e in range(g.ecount())]

ig.plot(g, edge_color=edge_colors,
        vertex_label=range(g.vcount()),
        layout=g.layout_circle())
plt.show()
```

## When igraph Implementation Shines

1. **R users who occasionally need Python:** Single library across both languages
2. **Medium-scale graphs:** 10K-100K nodes, need better than NetworkX speed
3. **Community detection workflows:** Flow + clustering + centrality in one library
4. **Academic publications:** Mature, well-cited library (15+ years)
5. **Cross-platform reproducibility:** Identical results across Windows/Mac/Linux

## When to Use Alternatives

1. **Min cost flow required:** igraph lacks this, use NetworkX or OR-Tools
2. **Pure Python preferred:** NetworkX has simpler installation
3. **Extreme performance needed:** graph-tool is 2-5x faster
4. **Operations research problems:** OR-Tools has constraint programming integration
5. **GPL license incompatible:** Use NetworkX (BSD) or OR-Tools (Apache)

## Debugging and Validation

### Verify Flow Conservation
```python
flow = g.maxflow(source, target, capacity="capacity")

for v in range(g.vcount()):
    if v in [source, target]:
        continue
    inflow = sum(flow.flow[e] for e in g.incident(v, mode="in"))
    outflow = sum(flow.flow[e] for e in g.incident(v, mode="out"))
    assert abs(inflow - outflow) < 1e-9, f"Flow not conserved at node {v}"
```

### Visualize Min Cut
```python
# Partition vertices into source/sink sides
partition = flow.partition
source_side = [i for i in range(g.vcount()) if partition[i] == 0]
sink_side = [i for i in range(g.vcount()) if partition[i] == 1]

print(f"Source side: {source_side}")
print(f"Sink side: {sink_side}")
print(f"Cut edges: {flow.cut}")
```

## Comparative Positioning

igraph is the **balanced implementation** for network flow. Think of it as the "SQLite of graph libraries" - fast enough for most uses, simple enough to deploy anywhere, works the same in Python and R. Not the fastest (that's graph-tool), not the simplest (that's NetworkX), but the best middle ground for multi-language research workflows.


---

# NetworkX: Comprehensive Technical Analysis

## Architecture Overview

Pure Python implementation built on standard library data structures (dicts, sets) with optional NumPy/SciPy integration. Graph representation uses nested dictionaries for maximum flexibility at the cost of memory efficiency.

**Core philosophy:** Readability and extensibility over raw performance. Designed for algorithm exploration and teaching.

## Maximum Flow Algorithms

### Preflow-Push (Default)
- **Complexity:** O(V³) worst case, often faster in practice
- **Implementation:** Python adaptation of Goldberg-Tarjan algorithm
- **Best for:** General-purpose max flow, works well on most graph types

### Edmonds-Karp
- **Complexity:** O(VE²) or O(VEU) for integer capacities
- **Implementation:** BFS-based Ford-Fulkerson variant
- **Best for:** Graphs with small capacity values, pedagogical use

### Shortest Augmenting Path
- **Complexity:** O(V²E) for unit capacities
- **Implementation:** Modified BFS with distance labeling
- **Best for:** Unit capacity networks

### Dinitz Algorithm
- **Complexity:** O(V²E) general, O(E√V) for unit capacities
- **Implementation:** Level graph construction with blocking flows
- **Best for:** Bipartite matching, unit capacity networks

## API Patterns

### Basic Max Flow
```python
import networkx as nx

G = nx.DiGraph()
G.add_edge("s", "a", capacity=3.0)
G.add_edge("s", "b", capacity=1.0)
G.add_edge("a", "t", capacity=3.0)
G.add_edge("b", "t", capacity=1.0)

flow_value, flow_dict = nx.maximum_flow(G, "s", "t")
# flow_value: 4.0
# flow_dict: nested dict with flow on each edge
```

### Minimum Cost Flow
```python
# Nodes with demands (negative = supply, positive = demand)
G.add_node("s", demand=-5)
G.add_node("t", demand=5)
G.add_edge("s", "a", capacity=4, weight=2)  # weight = cost per unit
G.add_edge("a", "t", capacity=4, weight=3)

flowDict = nx.min_cost_flow(G)
# Returns flow satisfying all demands with minimum total cost
```

### Custom Algorithm Selection
```python
# Use Edmonds-Karp instead of default preflow-push
flow_value, flow_dict = nx.maximum_flow(
    G, "s", "t",
    flow_func=nx.algorithms.flow.edmonds_karp
)
```

## Performance Characteristics

### Time Complexity Summary
| Graph Size | Algorithm | Runtime (estimate) |
|------------|-----------|-------------------|
| 100 nodes, 500 edges | Preflow-push | `&lt;10`ms |
| 1K nodes, 5K edges | Preflow-push | 100-500ms |
| 10K nodes, 50K edges | Preflow-push | 10-60s |
| 100K nodes, 500K edges | Any | Not practical |

### Memory Overhead
- **Graph storage:** ~200 bytes/edge (nested dicts + Python object overhead)
- **Flow computation:** O(V+E) additional for residual network
- **Rule of thumb:** 1M edges ≈ 200MB+ memory

### Numerical Stability
**Critical limitation:** Integer-only capacities recommended for min cost flow. Floating-point can cause:
- Infinite loops in capacity scaling algorithm
- Incorrect optimal solutions due to rounding errors
- Workaround: Multiply capacities by large constant, convert to integers

## API Design Philosophy

### Strengths
- **Intuitive graph construction:** Add nodes/edges incrementally
- **Flexible node IDs:** Any hashable type (strings, tuples, integers)
- **Attribute-based configuration:** Edge capacities/costs as attributes
- **Returns both value and flow dict:** Useful for debugging and visualization

### Pain Points
- **Mutable graphs during computation:** Must copy graph if original needed
- **No sparse matrix optimization:** Pure Python dicts don't leverage NumPy/SciPy speed
- **Inconsistent return types:** Some functions return objects, others return tuples

## Integration Patterns

### With NumPy/SciPy
```python
# Convert graph to scipy sparse matrix for external algorithms
adjacency_matrix = nx.to_scipy_sparse_array(G, weight='capacity')

# Convert adjacency matrix back to NetworkX graph
G = nx.from_scipy_sparse_array(adjacency_matrix, create_using=nx.DiGraph)
```

### With Pandas
```python
# Build graph from DataFrame of edges
import pandas as pd
edges_df = pd.DataFrame({
    'source': ['s', 's', 'a'],
    'target': ['a', 'b', 't'],
    'capacity': [3, 1, 3]
})
G = nx.from_pandas_edgelist(edges_df, 'source', 'target',
                             edge_attr='capacity',
                             create_using=nx.DiGraph)
```

## When NetworkX Implementation Shines

1. **Rapid prototyping:** Write/test flow algorithm in `&lt;30` minutes
2. **Teaching/learning:** Code readability matches textbook pseudocode
3. **Visualization:** Built-in matplotlib integration for flow diagrams
4. **Heterogeneous workflows:** Easy to combine flow with centrality, clustering, etc.
5. **Irregular graphs:** Flexible node IDs handle non-sequential node names

## When to Migrate Away

1. **Graphs `&gt;50`K nodes:** Pure Python becomes prohibitively slow
2. **Real-time requirements:** Even small graphs take milliseconds, not microseconds
3. **Repeated computations:** No graph structure caching, recomputes from scratch
4. **Production systems:** No thread safety, no C-level optimization

## Debugging and Introspection

### View Residual Network
```python
R = nx.algorithms.flow.build_residual_network(G, 'capacity')
# Inspect residual capacities after flow computation
```

### Verify Flow Conservation
```python
flow_value, flow_dict = nx.maximum_flow(G, 's', 't')
for node in G.nodes():
    if node not in ['s', 't']:
        inflow = sum(flow_dict[u][node] for u in G.predecessors(node))
        outflow = sum(flow_dict[node][v] for v in G.successors(node))
        assert abs(inflow - outflow) < 1e-6  # Flow conservation
```

## Comparative Positioning

NetworkX is the **reference implementation** for understanding network flow algorithms. Think of it as the "CPython of graph libraries" - not the fastest, but the most readable and widely understood. For production or large-scale research, you'll migrate to OR-Tools (if building products) or graph-tool (if maximizing performance), but you'll prototype in NetworkX first.


---

# OR-Tools: Comprehensive Technical Analysis

## Architecture Overview

Multi-layered C++ optimization suite with thin language bindings (Python, Java, C#). Network flow solvers are specialized components within broader constraint programming and linear optimization framework.

**Core philosophy:** Production-grade performance and correctness. Designed for real-world operations research problems at Google scale.

## Maximum Flow Algorithms

### SimpleMaxFlow
- **Implementation:** C++ optimized preflow-push variant
- **Complexity:** O(V²E) worst case, sub-quadratic in practice
- **Best for:** Standard max flow problems without additional constraints

**Key characteristic:** Solves only max flow, not integrated with other OR features. Use for straightforward capacity planning.

## Minimum Cost Flow Algorithms

### SimpleMinCostFlow
- **Implementation:** Network simplex algorithm with C++ optimization
- **Complexity:** Polynomial but depends on problem structure
- **Best for:** Supply/demand satisfaction with cost minimization

### Cost Scaling Algorithm
- **Implementation:** Successive approximation with cost scaling
- **Complexity:** O(E log(V) · (E + V log V))
- **Best for:** Large-scale problems with integer costs

**Distinguishing feature:** Handles supply/demand constraints natively, unlike pure max flow solvers.

## API Patterns

### Basic Min Cost Flow (Python)
```python
from ortools.graph.python import min_cost_flow
import numpy as np

# Instantiate solver
smcf = min_cost_flow.SimpleMinCostFlow()

# Define network as parallel arrays (efficient bulk insertion)
start_nodes = np.array([0, 0, 1, 1, 2])
end_nodes = np.array([1, 2, 2, 3, 3])
capacities = np.array([15, 8, 20, 4, 15])
unit_costs = np.array([4, 4, 2, 2, 1])

# Add all arcs at once (C++ level optimization)
all_arcs = smcf.add_arcs_with_capacity_and_unit_cost(
    start_nodes, end_nodes, capacities, unit_costs
)

# Set supplies (negative = source, positive = sink, 0 = transshipment)
supplies = [20, 0, 0, -20]  # Node 0 supplies 20, Node 3 demands 20
smcf.set_nodes_supplies(np.arange(len(supplies)), supplies)

# Solve
status = smcf.solve()
if status == smcf.OPTIMAL:
    print(f"Min cost: {smcf.optimal_cost()}")
    flows = smcf.flows(all_arcs)  # Flow values on each arc
```

### Max Flow with Min Cost (Python)
```python
# Solve max flow, break ties by minimum cost
status = smcf.solve_max_flow_with_min_cost()
```

### Accessing Solution Details
```python
# Iterate through solution
for arc in all_arcs:
    if smcf.flow(arc) > 0:
        print(f"{smcf.tail(arc)} -> {smcf.head(arc)}: "
              f"flow={smcf.flow(arc)}/{smcf.capacity(arc)}, "
              f"cost={smcf.unit_cost(arc)}")
```

## Performance Characteristics

### Time Complexity Summary
| Graph Size | Algorithm | Runtime (estimate) |
|------------|-----------|-------------------|
| 100 nodes, 500 edges | SimpleMinCostFlow | `&lt;1`ms |
| 1K nodes, 5K edges | SimpleMinCostFlow | 5-20ms |
| 10K nodes, 50K edges | SimpleMinCostFlow | 50-200ms |
| 100K nodes, 1M edges | SimpleMinCostFlow | 1-10s |

**10-100x faster than NetworkX** due to C++ optimization and specialized algorithms.

### Memory Overhead
- **Graph storage:** ~50-100 bytes/edge (C++ structs, not Python dicts)
- **Solver state:** O(V+E) for residual network + solver-specific structures
- **Rule of thumb:** 1M edges ≈ 50-100MB memory

### Numerical Handling
- **Integer costs required** for SimpleMinCostFlow
- **Floating-point costs** supported in advanced solvers (with caveats)
- **Overflow protection:** Uses 64-bit integers, checks for overflow

## API Design Philosophy

### Strengths
- **Bulk operations:** Add arcs via NumPy arrays (minimize Python/C++ boundary crossings)
- **Clear status codes:** OPTIMAL, INFEASIBLE, UNBALANCED, etc.
- **Efficient queries:** Direct arc access via integer IDs, not dictionary lookups
- **Multi-language consistency:** Same API patterns across Python, Java, C#

### Pain Points
- **Verbosity:** More boilerplate than NetworkX (explicit node/arc management)
- **Node IDs must be integers:** 0 to N-1, no arbitrary hashable types
- **Graph is immutable during solve:** Cannot modify arcs after solver instantiation
- **Debugging difficulty:** C++ errors surface as cryptic Python exceptions

## Integration Patterns

### With NumPy (Recommended)
```python
# Efficiently load large graphs from matrices
adjacency = np.array([...])  # Adjacency matrix with costs
sources, targets = np.where(adjacency > 0)
costs = adjacency[sources, targets]
capacities = np.ones_like(costs) * 1000  # Assume high capacity

smcf.add_arcs_with_capacity_and_unit_cost(sources, targets, capacities, costs)
```

### With NetworkX (Migration Pattern)
```python
import networkx as nx

# Prototype in NetworkX
G = nx.DiGraph()
# ... build graph ...

# Convert to OR-Tools for production
smcf = min_cost_flow.SimpleMinCostFlow()
node_map = {n: i for i, n in enumerate(G.nodes())}  # Map names to integers

for u, v, data in G.edges(data=True):
    smcf.add_arc_with_capacity_and_unit_cost(
        node_map[u], node_map[v],
        data.get('capacity', 1000),
        int(data.get('weight', 1))
    )
```

## Advanced Features

### Assignment Problems
OR-Tools specializes in assignment problems (matching workers to tasks):
```python
# Each worker can do each task, minimize total cost
# Automatically formulated as min cost flow internally
from ortools.graph.python import linear_sum_assignment

assignment = linear_sum_assignment.SimpleLinearSumAssignment()
assignment.add_arc_with_cost(worker=0, task=0, cost=90)
# ... add all worker-task pairs ...
assignment.solve()
```

### Constraint Programming Integration
Combine flow with other constraints (CP-SAT solver):
```python
from ortools.sat.python import cp_model

model = cp_model.CpModel()
# Define flow variables with additional constraints
# (e.g., "flow on arc A must equal flow on arc B")
```

## When OR-Tools Implementation Shines

1. **Production logistics:** Warehouse networks, supply chains, transportation
2. **Assignment problems:** Task allocation, resource scheduling
3. **Large-scale graphs:** `&gt;10`K nodes, need sub-second latency
4. **Multi-language deployment:** Python backend, Java microservices, C# desktop
5. **Constraint programming:** Flow + additional business rules

## When to Use Alternatives

1. **Pure research:** NetworkX has better documentation for learning
2. **Ad-hoc exploration:** Flexible node IDs, easier visualization
3. **Small graphs:** `&lt;1`K nodes, OR-Tools setup overhead not worth it
4. **Non-optimization focus:** Need centrality, clustering, graph properties

## Debugging and Validation

### Check Solution Status
```python
if status == smcf.OPTIMAL:
    print("Optimal solution found")
elif status == smcf.INFEASIBLE:
    print("No feasible flow (supply/demand mismatch)")
elif status == smcf.UNBALANCED:
    print("Total supply != total demand")
```

### Verify Supply/Demand Balance
```python
total_supply = sum(s for s in supplies if s < 0)
total_demand = sum(s for s in supplies if s > 0)
assert abs(total_supply + total_demand) < 1e-6
```

## Comparative Positioning

OR-Tools is the **production implementation** for network flow. Think of it as the "Postgres of graph optimization" - engineered for reliability, performance, and scale. You pay the API complexity tax upfront, but gain 10-100x performance and Google-scale battle-testing. Prototype in NetworkX, deploy with OR-Tools.

</TabItem>
</Tabs>
