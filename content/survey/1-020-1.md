---
title: "1.020.1 Linear Programming"
weight: 1020001
description: "Research on Linear Programming"
related:
- '1.021'
- '1.022'
- '1.023'
- '1.024'
- '1.025'
---

# 1.020.1 Linear Programming



---

<details>
<summary>Explainer</summary>

# Linear Programming: A Decision Guide for Developers

## What This Solves

**The Problem**: You need to make optimal decisions under constraints.

Every day, organizations face resource allocation problems:
- Which products to manufacture on limited machines?
- How to route deliveries with limited trucks and time?
- How to invest capital across assets with risk limits?
- How to schedule employees across shifts with labor rules?

These problems share a pattern: **maximize or minimize something (profit, cost, time) while respecting limits (capacity, budget, rules)**.

Linear programming (LP) is the mathematical framework for solving these problems algorithmically, guaranteeing the best possible answer.

**Who Encounters This**: Software engineers building optimization features, data scientists modeling business decisions, operations teams replacing spreadsheet-based planning.

**Why It Matters**: The difference between a good guess and an optimal solution can be millions in cost savings, 20% faster delivery, or 95% vs 80% service levels. Optimization turns "pretty good" into "mathematically best."

## Accessible Analogies

### The Shopping Optimizer

Imagine you're shopping with a fixed budget. You want to maximize happiness while staying within budget constraints.

**Manual approach**: Grab items, check total, put some back if over budget. Repeat until "good enough."

**LP approach**: List all items with happiness scores and prices. LP finds the exact combination that maximizes happiness without exceeding budget.

**Extension**: Now add constraints:
- Must buy at least 2 vegetables (health rule)
- Can't exceed 10 items (bag space)
- Some items must be bought together (meal recipes)

Still solvable! LP handles dozens of constraints, finding the optimal basket in milliseconds.

### The Factory Scheduler

A factory makes products on machines. Each product requires certain machine time and materials. You want to maximize profit.

**Without LP**: Planner uses spreadsheets, guesses production quantities, checks constraints manually, adjusts until "seems okay." Takes hours, misses opportunities.

**With LP**: Define objective (maximize profit), constraints (machine hours, materials), decision variables (how much to produce). LP solver finds optimal production plan in seconds.

**Universal Pattern**: "Maximize X subject to Y" problems appear everywhere:
- Shipping: Minimize cost subject to delivery deadlines
- Finance: Maximize return subject to risk tolerance
- Scheduling: Minimize labor cost subject to coverage requirements

LP is the universal tool for this pattern.

### The Navigation Analogy

Think of LP like GPS navigation:

**Simple route**: A to B, minimize time → Find shortest path (one dimension)

**With constraints**: Avoid tolls, stay under speed limit, stop for gas → Multi-dimensional optimization

**LP variables are intersections**, constraints are road rules, objective is minimizing time. The solver finds the optimal route through the network.

**Key insight**: Just as GPS handles millions of roads instantly, LP solvers handle thousands of variables and constraints efficiently. You declare the problem; the solver finds the answer.

## When You Need This

### Clear Decision Criteria

**You NEED LP when**:
- Problem has clear objective (maximize profit, minimize cost)
- Constraints are linear relationships (X + Y ≤ 10, not X × Y ≤ 10)
- Variables are continuous quantities OR discrete yes/no decisions
- Solution quality matters (not "good enough" but "provably best")
- Problem too complex for manual optimization (`>10` variables, `>5` constraints)

**Examples that fit**:
- "Allocate $1M across 50 assets to maximize return with `<20`% volatility"
- "Schedule 100 employees across 200 shifts minimizing cost while meeting coverage"
- "Route 30 trucks across 500 deliveries minimizing distance with time windows"

### When You DON'T Need This

**Skip LP if**:
- Objective is vague ("make it better") → Need human judgment
- Relationships are nonlinear (X²) → Need nonlinear optimization or approximation
- Data quality is poor → Garbage in, garbage out
- Problem is tiny (2-3 variables) → Enumerate by hand
- "Close enough" is fine and heuristics work → Don't over-engineer

**Examples where LP is overkill**:
- "Find a decent employee schedule" (heuristics may suffice)
- "Suggest some investment ideas" (not optimization, just filtering)
- "Route 2 trucks with 5 stops each" (try all combinations manually)

## Trade-offs

### Complexity vs Capability

**Spectrum**:
```
Simple            Moderate          Complex
|                 |                 |
Spreadsheets → LP Libraries → Commercial Solvers
```

**Spreadsheets (Excel Solver)**:
- **Pro**: Familiar UI, visual, easy to share
- **Con**: `<1000` variables, slow, brittle formulas
- **Use when**: Small problems, non-programmers

**LP Libraries (scipy, PuLP)**:
- **Pro**: Scalable (10K-100K variables), reproducible, free
- **Con**: Requires programming, steeper learning curve
- **Use when**: Production systems, large problems, technical team

**Commercial Solvers (Gurobi, CPLEX)**:
- **Pro**: Fastest, largest problems (millions of variables), support
- **Con**: $10K-100K/year, vendor lock-in risk
- **Use when**: Performance critical, ROI justifies cost

### Build vs Buy vs Open-Source

**Build Your Own Solver**:
- **When**: Never (unless PhD research or Google-scale unique problems)
- **Why avoid**: 20+ years of algorithm R&D already done

**Use Open-Source Library**:
- **When**: Most cases (scipy, PuLP, CVXPY, OR-Tools)
- **Why**: Free, proven, community-supported, good-enough performance
- **Trade-off**: Slower than commercial, but 10x cheaper

**Buy Commercial Solver**:
- **When**: Performance matters, millions in cost savings at stake
- **Why**: 2-10x faster than free solvers, enterprise support
- **Trade-off**: $10K-50K/year, but typically pays for itself

**Hybrid Strategy**: Start with free solvers (PuLP + CBC), upgrade to Gurobi when scaling justifies cost. Many libraries let you swap solvers without code changes.

### Self-Hosted vs Cloud Services

**Self-Hosted (Libraries)**:
- **Pro**: Full control, no API costs, data privacy
- **Con**: Manage infrastructure, updates, scaling
- **Use when**: Sensitive data, batch processing, existing infrastructure

**Cloud / Optimization-as-a-Service**:
- **Pro**: No ops, scale on demand, pay-per-use
- **Con**: API costs, vendor dependency, latency
- **Use when**: Spiky workloads, microservices, rapid prototyping

**Note**: Most LP libraries run anywhere (local, Docker, cloud VMs), so not a strict dichotomy.

## Cost Considerations

### Pricing Models

**Free Open-Source Solvers**:
- scipy, PuLP + CBC, CVXPY + ECOS: **$0**
- Good for `<100`K variables, most use cases
- **Hidden cost**: Developer time learning, potential slower solve times

**Commercial Solver Licenses**:
- **Gurobi**: $5K-10K/named user, $50K-150K/site license
- **CPLEX**: Similar to Gurobi, enterprise pricing
- **Academic**: Free or heavily discounted for universities
- **Break-even**: If optimization saves `>$50K/year`, license pays off

### Break-Even Analysis

**Example: Supply chain optimization**
- Problem: Route 500 deliveries daily, current cost $100K/month
- LP solution: Saves 10% = $10K/month = $120K/year
- Gurobi license: $20K/year
- Net savings: $100K/year

**ROI**: 5x return, breaks even in ~2 months

**Hidden Costs**:
- Developer time: 1-3 months to build, test, integrate (one-time)
- Maintenance: 10-20% of build time annually
- Data quality: Clean data is prerequisite (often underestimated)

### When Cost is Negligible

**Skip pricing considerations when**:
- Academic projects (free licenses available)
- Small-scale (`<10`K variables, free solvers sufficient)
- Internal tools (developer time dominates, license cost is rounding error)

**Focus on cost when**:
- Large-scale (`>100`K variables, commercial solvers worth it)
- High-frequency optimization (API/cloud costs matter)
- Multiple teams (per-seat licensing adds up)

## Implementation Reality

### Timeline Expectations

**First 90 Days (Typical Project)**:

**Month 1**: Problem formulation and prototyping
- Week 1-2: Understand requirements, clean data, set up environment
- Week 3-4: Build initial model (PuLP or CVXPY), validate constraints
- Milestone: Feasible solution (may not be optimal yet)

**Month 2**: Refinement and optimization
- Week 1-2: Add forgotten constraints, fix edge cases
- Week 3-4: Tune solver parameters, benchmark solvers
- Milestone: Optimal solutions, `<1` minute solve time

**Month 3**: Integration and deployment
- Week 1-2: Integrate with databases/APIs, build UI
- Week 3-4: Testing, documentation, monitoring
- Milestone: Production-ready, automated

**Reality Check**: Month 1 is often longer than expected (problem formulation is hard). Month 3 depends on integration complexity (database access, approval workflows).

### Team Skill Requirements

**Minimum Team**:
- **One developer** with Python experience (3-6 months to learn)
- **One domain expert** (understands business constraints)
- **Nice to have**: Someone with OR background (but not required)

**Skill Levels**:
- **Beginner** (no optimization background): Start with PuLP, 2-3 weeks to basic proficiency
- **Intermediate** (some math background): CVXPY or OR-Tools, 1-2 weeks
- **Expert** (OR degree): Can use any library immediately

**Learning Resources**:
- PuLP: Easiest (intuitive syntax, great docs)
- scipy: Easy (if already use NumPy)
- CVXPY: Moderate (need convex optimization basics)
- OR-Tools: Steep (comprehensive but more complex)

### Common Pitfalls and Misconceptions

**Pitfall 1: "Optimization will solve everything"**
- **Reality**: LP finds best answer to YOUR problem formulation. Wrong constraints = wrong answer (garbage in, garbage out).
- **Fix**: Spend time validating problem formulation with domain experts.

**Pitfall 2: "I'll model reality exactly"**
- **Reality**: Real world has nonlinear relationships, LP requires linear approximations.
- **Fix**: Start simple, add complexity only if needed. 80% accuracy with LP beats 100% manual guessing.

**Pitfall 3: "Commercial solvers are always worth it"**
- **Reality**: Free solvers are excellent for most problems. Commercial shines at scale (`>100`K variables) or hard MIP.
- **Fix**: Start free, measure, upgrade only if bottleneck proven.

**Pitfall 4: "LP solves in milliseconds (like in textbooks)"**
- **Reality**: Textbook examples have 3 variables. Real problems with 10K variables take seconds to minutes.
- **Fix**: Set realistic expectations (seconds to minutes is good, not milliseconds).

**Pitfall 5: "One-time optimization"**
- **Reality**: Requirements change, data quality issues appear, edge cases emerge.
- **Fix**: Plan for iteration. Build maintainable models, version control, testing.

### First 90 Days: What to Expect

**Early Wins** (Week 1-4):
- ✅ Feasible solutions (better than manual)
- ✅ Quick what-if analysis (change constraints, re-solve)
- ✅ Team excitement (see "optimal" in action)

**Frustrations** (Week 4-8):
- ⚠️ Infeasibility errors (forgot a constraint, over-constrained)
- ⚠️ Slow solve times (need to simplify or upgrade solver)
- ⚠️ Unrealistic solutions (modeled constraints wrong)

**Maturity** (Week 8-12):
- ✅ Robust models (handle edge cases)
- ✅ Integrated pipelines (data in, decisions out)
- ✅ Monitoring and validation (trust the solver)

**Key to Success**: Iterate fast, validate often, involve domain experts early.

## Conclusion

Linear programming is **mature, proven technology** for making optimal decisions under constraints. It's not magic—it's math—but it turns complex resource allocation problems into solvable equations.

**Use LP when**: Objective is clear, constraints are linear, solution quality matters, problem too big for manual optimization.

**Start with**: Open-source libraries (PuLP for beginners, CVXPY for versatility, OR-Tools for performance). Upgrade to commercial solvers only when scale justifies cost.

**Expect**: 1-3 months to first production system, ongoing iteration, 10-30% improvement over manual methods (often more).

**Remember**: The hardest part isn't the solver—it's correctly formulating your problem. Invest time understanding constraints, validating models, and iterating with domain experts.

</details>

<details>
<summary>S1: Rapid Discovery</summary>

# S1-Rapid Approach: Linear Programming Libraries

## Objective
Quick survey of Python linear programming libraries to understand their capabilities, maturity, and suitability for optimization problems.

## Scope
- **Libraries**: scipy.optimize.linprog, PuLP, CVXPY, OR-Tools
- **Focus**: Linear programming (LP) specifically, not general optimization
- **Time**: 30-60 minutes per library
- **Depth**: Documentation review, feature overview, ecosystem integration

## Evaluation Criteria
1. **Ease of Use**: API simplicity, problem formulation clarity
2. **Solver Support**: Which underlying solvers are supported (CBC, GLPK, CPLEX, Gurobi, etc.)
3. **Performance**: Speed claims, problem size limits
4. **Ecosystem**: Integration with NumPy/pandas, community support
5. **Maturity**: GitHub stars, maintenance status, stability

## Method
- Review official documentation
- Check GitHub metrics (stars, recent commits, issues)
- Identify solver backends and performance characteristics
- Note licensing and commercial solver support

## Constraints
- No hands-on benchmarking in S1
- Relying on documentation and community consensus
- Not evaluating specific problem types (defer to S2/S3)


---

# CVXPY

## Overview
Domain-specific language for convex optimization. Handles LP as a subset of convex programs. Automatic problem classification and solver dispatch.

## Key Features
- **Convex optimization framework**: LP, QP, SOCP, SDP support
- **Disciplined Convex Programming (DCP)**: Automatic convexity verification
- **Rich expression system**: Matrix operations, norms, complex constraints
- **Solver ecosystem**: Integrates with 10+ solvers

## Solvers Supported
- ECOS (default, open-source)
- OSQP (for QP)
- SCS (for conic programs)
- CBC, GLPK (for MIP)
- CPLEX, Gurobi, Mosek (commercial)
- CVXOPT, GLPK_MI

## Maturity
- **Stars**: 5.4K GitHub stars
- **Maintenance**: Very active, Stanford research project
- **Community**: Strong academic user base
- **Stability**: Mature (v1.0+), used in research and industry

## Licensing
- Apache 2.0 (permissive)
- Solver licenses vary

## Strengths
- Elegant API: write mathematical notation directly
- Automatic problem classification (LP, QP, etc.)
- Powerful for complex convex constraints
- Academic rigor: DCP ensures correctness
- Excellent for research and prototyping

## Limitations
- Learning curve: DCP rules require understanding
- Overhead for simple LP (designed for broader convex class)
- Some performance cost from abstraction layer
- May be overkill if you only need LP

## Best For
- Mixed problem types (LP, QP, SOCP in one project)
- Research requiring mathematical correctness proofs
- Teams familiar with convex optimization theory
- Projects needing constraint flexibility


---

# OR-Tools (Google Optimization Tools)

## Overview
Google's fast optimization toolkit. Industrial-strength solver suite covering LP, MIP, CP, routing, and more. Extensive feature set.

## Key Features
- **Built-in solvers**: GLOP (LP), CP-SAT (constraint programming)
- **External solver support**: CPLEX, Gurobi, Xpress, SCIP
- **Multiple APIs**: Python, C++, Java, C#
- **Problem types**: LP, MIP, CP, vehicle routing, assignment, flows

## Solvers
- GLOP: Google's linear optimizer (fast, open-source)
- CP-SAT: Constraint programming with MIP capabilities
- SCIP (bundled)
- CPLEX, Gurobi (if installed)

## Maturity
- **Stars**: 11K GitHub stars
- **Maintenance**: Active Google project
- **Community**: Large, production-focused
- **Stability**: Heavily tested at Google scale

## Licensing
- Apache 2.0 (permissive)

## Strengths
- **Performance**: GLOP competitive with commercial solvers for LP
- **Comprehensive**: Routing, scheduling, assignment problems included
- **Google-scale testing**: Used in production at Google
- **No external dependencies** for basic LP/MIP
- **Excellent documentation** and examples

## Limitations
- Larger dependency (C++ core, larger install size)
- More complex API than PuLP for simple problems
- Some features require deeper optimization knowledge
- C++ errors can be cryptic from Python

## Best For
- Production systems needing performance
- Complex problems (routing, scheduling, assignment)
- Teams comfortable with lower-level APIs
- Projects requiring Google-scale reliability
- MIP problems with combinatorial structure


---

# PuLP

## Overview
Python modeling API for optimization. High-level problem formulation with automatic solver dispatch. Most popular LP modeling library in Python.

## Key Features
- **Modeling language**: Declare variables, objectives, constraints in natural syntax
- **Solver agnostic**: Supports CBC, GLPK, CPLEX, Gurobi, Mosek, and more
- **MIP support**: Handles integer and mixed-integer programs
- **Free solver included**: Ships with CBC (COIN-OR Branch and Cut)

## Solvers Supported
- CBC (default, open-source)
- GLPK (open-source)
- CPLEX (commercial)
- Gurobi (commercial)
- Mosek (commercial)
- SCIP, HiGHS, XPRESS

## Maturity
- **Stars**: 2.3K GitHub stars
- **Maintenance**: Active development, regular releases
- **Community**: Large user base, extensive examples
- **Stability**: Mature (v2+), widely deployed

## Licensing
- MIT License (permissive)
- Note: Solver licenses vary (CBC is EPL, CPLEX/Gurobi are commercial)

## Strengths
- Intuitive modeling API: `x + y <= 10` syntax
- Battle-tested in industry and academia
- Excellent documentation and tutorials
- Easy solver switching (test with CBC, deploy with Gurobi)
- Handles both LP and MIP

## Limitations
- Slower than native solver APIs for very large problems
- Modeling overhead (translate Python to solver format)
- No automatic differentiation or convex detection

## Best For
- Production LP/MIP applications
- Teams wanting readable optimization code
- Projects needing solver flexibility
- MIP problems (not just LP)


---

# S1 Recommendation: Linear Programming Library Selection

## Quick Decision Tree

**For quick prototyping / learning:**
→ **scipy.optimize.linprog** - Zero setup, NumPy integration

**For production LP/MIP with readable code:**
→ **PuLP** - Intuitive modeling, solver flexibility, battle-tested

**For convex problems beyond LP (QP, SOCP):**
→ **CVXPY** - Mathematical elegance, automatic problem classification

**For performance-critical / complex combinatorial:**
→ **OR-Tools** - Google-scale reliability, comprehensive features

## Ecosystem Maturity Comparison

| Library | Stars | Maintenance | Community | Best Known For |
|---------|-------|-------------|-----------|----------------|
| scipy | 30K+ | SciPy core | Massive | Scientific computing |
| PuLP | 2.3K | Active | Large | Readable LP/MIP modeling |
| CVXPY | 5.4K | Very active | Academic | Convex optimization |
| OR-Tools | 11K | Google | Production | Google-scale performance |

## Solver Backend Summary

- **No external solver needed**: scipy (HiGHS), OR-Tools (GLOP)
- **Free solver included**: PuLP (CBC), CVXPY (ECOS)
- **Commercial solver support**: All four support CPLEX/Gurobi
- **Most flexible**: PuLP (7+ solvers), CVXPY (10+ solvers)

## Feature Comparison

| Feature | scipy | PuLP | CVXPY | OR-Tools |
|---------|-------|------|-------|----------|
| LP | ✅ | ✅ | ✅ | ✅ |
| MIP | ❌ | ✅ | ✅ | ✅ |
| QP | ❌ | ❌ | ✅ | ❌ |
| Modeling API | ❌ | ✅ | ✅ | ⚠️ |
| NumPy-first | ✅ | ❌ | ✅ | ❌ |
| Routing/Scheduling | ❌ | ❌ | ❌ | ✅ |

⚠️ OR-Tools has modeling API but more verbose than PuLP/CVXPY

## Common Patterns

**Start simple, upgrade path:**
1. Prototype with scipy.linprog
2. Move to PuLP when constraints get complex
3. Switch to Gurobi/CPLEX backend when performance matters
4. OR-Tools for routing/scheduling problems

**Research → Production:**
1. CVXPY for research (verify convexity, experiment)
2. PuLP or OR-Tools for deployment (performance, reliability)

## Anti-Recommendations

- ❌ Don't use scipy for MIP (it doesn't support integer variables)
- ❌ Don't use CVXPY if you only need LP (overhead)
- ❌ Don't use OR-Tools for first LP project (learning curve)
- ❌ Don't write raw solver APIs unless benchmarking proves necessary

## Next Steps (S2-S4)

- **S2**: Deep-dive into API patterns, benchmarking problem sizes
- **S3**: Map to use cases (supply chain, finance, ML, etc.)
- **S4**: Evaluate long-term ecosystem trends, community health


---

# scipy.optimize.linprog

## Overview
Part of SciPy's optimization module. Solves linear programming problems using built-in algorithms. No external solver dependencies required.

## Key Features
- **Built-in algorithms**: Interior-point, simplex, revised simplex, HiGHS
- **NumPy integration**: Direct array input/output
- **No dependencies**: Ships with SciPy, no external solvers needed
- **Standard form**: Minimization problems in canonical LP form

## Solvers
- `highs` (default): State-of-art open-source solver
- `highs-ds`: Dual simplex variant
- `highs-ipm`: Interior-point method
- `interior-point`: Legacy SciPy IPM
- `revised simplex`: Legacy SciPy simplex
- `simplex`: Basic simplex (deprecated)

## Maturity
- **Stars**: Part of SciPy (30K+ stars)
- **Maintenance**: Active, part of core SciPy
- **Community**: Extensive scientific Python community
- **Stability**: Production-ready, well-tested

## Licensing
- BSD-3-Clause (permissive, commercial-friendly)

## Strengths
- Zero setup: installed with SciPy
- Fast for small-medium problems via HiGHS
- Well-documented, stable API
- Good for prototyping and educational use

## Limitations
- Array-based API (not modeling language)
- Less expressive than PuLP/CVXPY for complex constraints
- Limited to LP (no MIP, no quadratic)
- No direct CPLEX/Gurobi support

## Best For
- Quick prototyping
- Small to medium LP problems
- Projects already using SciPy/NumPy
- No external solver setup allowed

</details>

<details>
<summary>S2: Comprehensive</summary>

# S2-Comprehensive Approach: Linear Programming Libraries

## Objective
Technical deep-dive into architecture, algorithms, and performance characteristics of linear programming libraries.

## Scope
- **Libraries**: scipy.optimize.linprog, PuLP, CVXPY, OR-Tools
- **Focus**: API patterns, solver algorithms, performance benchmarks
- **Time**: 2-3 hours per library
- **Depth**: Code examples, architecture understanding, performance profiles

## Analysis Dimensions

### 1. API Architecture
- Problem formulation patterns
- Constraint specification methods
- Objective function definition
- Variable declaration approaches

### 2. Algorithm Details
- Which algorithms are implemented
- Simplex vs interior-point trade-offs
- Presolving and scaling techniques
- Numerical stability considerations

### 3. Performance Characteristics
- Problem size limits (rows, columns, non-zeros)
- Memory usage patterns
- Solver speed comparisons
- Warm-start support

### 4. Integration Patterns
- NumPy/pandas integration
- Serialization and problem export
- Result interpretation and dual variables
- Sensitivity analysis capabilities

## Method
- Read implementation documentation
- Review solver backend papers
- Analyze API examples for patterns
- Compare benchmark results (existing literature)
- Minimal code samples for API illustration

## Constraints
- Code samples are minimal API examples only
- No installation tutorials
- Focusing on understanding, not usage guides
- Deferring use-case mapping to S3


---

# CVXPY - Technical Analysis

## Architecture

### Disciplined Convex Programming (DCP)
Three-stage pipeline:
1. **Expression tree**: Build problem with `Variable`, `Objective`, `Constraint` objects
2. **DCP analysis**: Verify problem is convex via curvature and sign analysis
3. **Canonicalization**: Transform to cone program
4. **Solver dispatch**: Convert to solver-specific format (ECOS, OSQP, etc.)

### Problem Classification
Automatically detects: LP, QP, SOCP, SDP based on expression structure.

## Algorithm Deep-Dive

### ECOS (Default for LP)
- Embedded Conic Solver
- Interior-point method for conic programs
- Fast for small-medium problems (`<10`K variables)
- Implements primal-dual predictor-corrector
- Self-dual embedding for infeasibility detection

### Solver Comparison (for LP)
| Solver | Speed | Robustness | Best For |
|--------|-------|------------|----------|
| ECOS | Fast | Good | Small-medium LP/SOCP |
| SCS | Moderate | Excellent | Large-scale, ill-conditioned |
| OSQP | Fast | Good | QP (not LP-specific) |
| CPLEX | Excellent | Excellent | Production LP/MIP |

## Performance Profile

| Problem Type | Size | ECOS Time | CPLEX Time |
|--------------|------|-----------|------------|
| LP (sparse) | 10K vars | ~2s | `<1`s |
| LP (dense) | 5K vars | ~5s | ~1s |
| SOCP | 5K vars | ~10s | ~2s |

DCP verification adds negligible overhead (`<100`ms).

## API Pattern

Minimal example:
```python
x = cp.Variable()
y = cp.Variable()
objective = cp.Minimize(x + 2*y)
constraints = [x + y <= 5, x >= 0, y >= 0]
prob = cp.Problem(objective, constraints)
prob.solve()
# x.value, y.value contain solution
```

Mathematical notation directly in code.

## Integration Capabilities

- **Input**: NumPy arrays, pandas Series, scalars
- **Output**: Variable objects with `.value`, problem has `.value` (optimal objective)
- **Warm start**: Limited support (solver-dependent)
- **Sensitivity**: Dual variables via `constraint.dual_value`
- **Export**: No direct MPS export (must use solver API)
- **Parameters**: `cp.Parameter` for parameterized problems (efficient re-solve)

## Advanced Features

### DCP Verification
```python
prob.is_dcp()  # Returns True if convex
prob.is_dgp()  # Returns True if log-log convex
```

### Disciplined Parameterized Programming (DPP)
```python
a = cp.Parameter()
x = cp.Variable()
prob = cp.Problem(cp.Minimize(x), [x >= a])
a.value = 5
prob.solve()  # Fast re-solve with new parameter
```

### GPU Acceleration
SCS solver supports GPU via CUDA (cuSPARSE, cuSOLVER).

## Numerical Considerations

- Automatic problem transformation can introduce scaling issues
- ECOS has tight default tolerances (1e-8)
- SCS more robust for ill-conditioned problems
- Can specify solver tolerances: `prob.solve(eps_abs=1e-10)`

## Limitations

- DCP rules require learning (e.g., can't multiply two variables)
- Overhead for simple LP (designed for broader convex class)
- Some convex problems not DCP-compliant (must reformulate)
- Commercial solver integration less mature than PuLP

## When to Use

- Mixed problem types (LP + QP + SOCP in one project)
- Need mathematical correctness guarantees
- Prototyping convex optimization research
- Parameterized problems with frequent re-solves


---

# S2 Feature Comparison: Technical Characteristics

## Performance Benchmarks (LP, 10K variables, sparse)

| Library | Solver | Time | Memory | Scalability |
|---------|--------|------|--------|-------------|
| scipy | HiGHS | ~2s | Low | Good (to 100K) |
| PuLP | CBC | ~5s | Medium | Moderate |
| PuLP | CPLEX | `<1`s | Medium | Excellent |
| CVXPY | ECOS | ~2s | Medium | Good (to 50K) |
| CVXPY | CPLEX | `<1`s | Medium | Excellent |
| OR-Tools | GLOP | ~10s | High | Excellent (to 500K) |

**Note**: Times are approximate, vary by problem structure.

## API Complexity vs Expressiveness

```
Low Complexity                        High Complexity
Simple API                            Powerful Features
|                                     |
scipy -------- PuLP -------- CVXPY -------- OR-Tools
         |                |
         |                └─ Best mathematical notation
         └─ Best readability
```

## Architecture Comparison

| Aspect | scipy | PuLP | CVXPY | OR-Tools |
|--------|-------|------|-------|----------|
| Modeling Layer | None | Yes | Yes (DCP) | Yes |
| Serialization | None | MPS/LP | Cone | Internal |
| Solver API | Direct | CLI/API | Direct | Direct |
| Language | Python | Python | Python | C++/Python |
| Overhead | Minimal | High | Medium | Low |

## Numerical Robustness

| Library | Presolve | Scaling | Tolerances | Ill-Conditioned |
|---------|----------|---------|------------|-----------------|
| scipy | HiGHS auto | HiGHS auto | Configurable | Good |
| PuLP | Solver-dependent | Solver-dependent | Solver-dependent | CBC: Moderate |
| CVXPY | ECOS auto | ECOS auto | Tight default | SCS: Excellent |
| OR-Tools | GLOP auto | GLOP auto | Configurable | Good |

## Memory Footprint

| Library | Base Install | With Solvers | Runtime (10K vars) |
|---------|--------------|--------------|---------------------|
| scipy | 50 MB | N/A (built-in) | ~100 MB |
| PuLP | 5 MB | +50 MB (CBC) | ~200 MB |
| CVXPY | 10 MB | +20 MB (ECOS) | ~300 MB |
| OR-Tools | 100 MB | Included | ~400 MB |

## Warm Start Support

| Library | LP Warm Start | MIP Warm Start | Incremental |
|---------|---------------|----------------|-------------|
| scipy | ❌ | N/A | ❌ |
| PuLP | ⚠️ (solver-dep) | ✅ (CPLEX/Gurobi) | ❌ |
| CVXPY | ⚠️ (limited) | ⚠️ (solver-dep) | ✅ (Parameters) |
| OR-Tools | ✅ | ✅ | ✅ |

## Sensitivity Analysis

| Library | Dual Variables | Reduced Costs | Shadow Prices | Ranges |
|---------|----------------|---------------|---------------|--------|
| scipy | ✅ | ✅ | ✅ | ❌ |
| PuLP | ✅ | ✅ | ✅ | ⚠️ |
| CVXPY | ✅ | ⚠️ | ✅ | ❌ |
| OR-Tools | ✅ | ✅ | ✅ | ⚠️ |

⚠️ = Available but requires extra steps or solver support

## Parallel Solving

| Library | Parallel Presolve | Parallel Simplex | Parallel IPM | Concurrent Solvers |
|---------|-------------------|------------------|--------------|---------------------|
| scipy | ✅ (HiGHS) | ✅ (HiGHS) | ✅ (HiGHS) | ❌ |
| PuLP | Solver-dependent | Solver-dependent | Solver-dependent | ❌ |
| CVXPY | Solver-dependent | Solver-dependent | ✅ (SCS GPU) | ❌ |
| OR-Tools | ✅ (GLOP) | Partial | ❌ | ✅ |

## Problem Size Recommendations

| Library | Small (`<1`K) | Medium (1K-10K) | Large (10K-100K) | Very Large (`>100`K) |
|---------|-------------|-----------------|------------------|--------------------|
| scipy | ✅ | ✅ | ⚠️ | ❌ |
| PuLP | ✅ | ✅ | ⚠️ (slow) | ❌ |
| CVXPY | ✅ | ✅ | ⚠️ | ❌ |
| OR-Tools | ✅ | ✅ | ✅ | ✅ |

For very large: upgrade to commercial solvers (CPLEX, Gurobi) regardless of library.

## Developer Experience

| Aspect | scipy | PuLP | CVXPY | OR-Tools |
|--------|-------|------|-------|----------|
| Learning Curve | Easiest | Easy | Moderate | Steep |
| Documentation | Excellent | Good | Excellent | Good |
| Error Messages | Clear | Clear | Good | Cryptic (C++) |
| Debugging | Easy | Easy | Moderate | Hard |
| IDE Support | Excellent | Excellent | Excellent | Good |

## Production Readiness

| Library | Stability | Backward Compat | Versioning | Enterprise Use |
|---------|-----------|-----------------|------------|----------------|
| scipy | Excellent | Excellent | Semantic | ✅ |
| PuLP | Good | Good | Version numbers | ✅ |
| CVXPY | Good | Good | Semantic | ✅ (research) |
| OR-Tools | Excellent | Good | Google release | ✅ |


---

# OR-Tools - Technical Analysis

## Architecture

### Multi-Paradigm Design
Supports three problem modeling approaches:
1. **Linear Solver (GLOP)**: For LP problems
2. **CP-SAT**: For constraint programming and MIP
3. **Routing**: Specialized for vehicle routing problems

Each has its own API and solver backend.

### Problem Representation
C++ core with Python bindings. Direct API calls (no serialization layer like PuLP).

## Algorithm Deep-Dive

### GLOP (Google Linear Optimizer)
- Revised dual simplex implementation
- Written from scratch at Google (2014+)
- Optimized for Google-scale problems
- Performance competitive with CPLEX/Gurobi on many benchmarks
- Parallel presolve and crash procedures

### CP-SAT (for MIP)
- Constraint programming with SAT-based search
- Lazy clause generation
- Advanced branching heuristics
- Excellent for scheduling and assignment problems
- Can handle 10^6 binary variables for structured problems

### Algorithm Selection
```python
# For LP: use GLOP
solver = pywraplp.Solver('example', pywraplp.Solver.GLOP_LINEAR_PROGRAMMING)

# For MIP: use CP-SAT or SCIP
solver = pywraplp.Solver('example', pywraplp.Solver.SCIP_MIXED_INTEGER_PROGRAMMING)
```

## Performance Profile

| Problem Type | Size | GLOP Time | CPLEX Time |
|--------------|------|-----------|------------|
| LP (sparse) | 100K vars | ~10s | ~5s |
| LP (dense) | 20K vars | ~30s | ~10s |
| MIP (CP-SAT) | 10K binary | Seconds-minutes | Seconds-minutes |

GLOP particularly strong on: network flow, assignment, transportation problems.

## API Pattern

Minimal example:
```python
solver = pywraplp.Solver('example', pywraplp.Solver.GLOP_LINEAR_PROGRAMMING)
x = solver.NumVar(0, solver.infinity(), 'x')
y = solver.NumVar(0, solver.infinity(), 'y')
solver.Minimize(x + 2*y)
solver.Add(x + y <= 5)
status = solver.Solve()
# x.solution_value(), y.solution_value()
```

More verbose than PuLP but direct access to solver internals.

## Integration Capabilities

- **Input**: Direct Python API, can wrap NumPy arrays
- **Output**: Variable objects with `.solution_value()`, `.reduced_cost()`
- **Warm start**: Supported via `.SetHint()`
- **Sensitivity**: Dual values via `.dual_value()` on constraints
- **Export**: `.ExportModelAsLpFormat()`, `.ExportModelAsMpsFormat()`

## Advanced Features

### Incremental Solving
```python
solver.Add(constraint1)
solver.Solve()  # First solve
solver.Add(constraint2)  # Add constraint
solver.Solve()  # Re-solve from warm start
```

### Parameters and Tolerances
```python
solver.SetTimeLimit(60000)  # milliseconds
params = pywraplp.MPSolverParameters()
params.SetDoubleParam(params.RELATIVE_MIP_GAP, 0.01)
solver.Solve(params)
```

### External Solver Integration
Can use CPLEX, Gurobi, XPRESS backends:
```python
solver = pywraplp.Solver('example', pywraplp.Solver.GUROBI_LINEAR_PROGRAMMING)
```

### Routing Library
Specialized for VRP (Vehicle Routing Problem):
- TSP, CVRP, VRPTW variants
- Dimension constraints (capacity, time windows)
- Local search metaheuristics
- Google Maps API integration

## Numerical Considerations

- GLOP uses LU factorization with Markowitz pivoting
- Automatic scaling and presolve
- Harris ratio test for numerical stability
- Can handle moderately ill-conditioned problems
- Tolerances: `solver.set_primal_tolerance(1e-7)`

## Limitations

- More verbose API than PuLP/CVXPY
- Larger install size (C++ library)
- Learning curve for routing/CP-SAT features
- Python error messages less informative (C++ core)

## When to Use

- Performance-critical LP (GLOP competitive with commercial)
- Vehicle routing, scheduling, assignment problems
- Need incremental solving
- Google-scale reliability required
- Projects already using other OR-Tools features


---

# PuLP - Technical Analysis

## Architecture

### Modeling Layer
Two-stage process:
1. Build problem using Python expressions (`LpVariable`, `LpProblem`)
2. Export to solver format (MPS or LP file)
3. Invoke solver
4. Parse results back to Python

### Problem Representation
Object-oriented API with symbolic variables. Constraint expressions build abstract syntax tree.

### Solver Dispatch
`problem.solve(solver)` serializes to solver-specific format:
- CBC: calls command-line binary
- CPLEX/Gurobi: uses Python API if available
- GLPK: calls via command-line or ctypes

## Algorithm Deep-Dive

### CBC (Default Solver)
- Branch-and-Cut for MIP
- Dual simplex for LP relaxations
- Cutting planes: Gomory, knapsack, clique
- Performance: Handles 10^5 variables for LP, 10^4 for MIP

### Solver Comparison
| Solver | LP Speed | MIP Speed | License |
|--------|----------|-----------|---------|
| CBC | Good | Moderate | EPL (open) |
| GLPK | Moderate | Slow | GPL |
| CPLEX | Excellent | Excellent | Commercial |
| Gurobi | Excellent | Excellent | Commercial |

## Performance Profile

| Problem Type | Size | CBC Time | CPLEX Time |
|--------------|------|----------|------------|
| LP (sparse) | 10K vars | ~5s | `<1`s |
| LP (dense) | 5K vars | ~10s | ~2s |
| MIP (easy) | 1K binary | ~10s | `<1`s |
| MIP (hard) | 1K binary | Minutes-hours | Seconds-minutes |

Modeling overhead: ~100ms for problem construction.

## API Pattern

Minimal example:
```python
prob = LpProblem("example", LpMinimize)
x = LpVariable("x", lowBound=0)
y = LpVariable("y", lowBound=0)
prob += x + 2*y  # Objective
prob += x + y <= 5  # Constraint
prob.solve()
# x.varValue, y.varValue contain solution
```

Natural Python expression syntax.

## Integration Capabilities

- **Input**: Python expressions, can wrap pandas DataFrames
- **Output**: Variable objects with `.varValue`, `.dj` (reduced cost)
- **Warm start**: Supported with CPLEX/Gurobi (set `.varValue` before solve)
- **Sensitivity**: Dual variables via `.pi` on constraints, reduced costs via `.dj`
- **Export**: `.writeLP()` creates LP file, `.writeMPS()` creates MPS file

## Advanced Features

### Parameter Passing
```python
solver = PULP_CBC_CMD(timeLimit=60, fracGap=0.01)
prob.solve(solver)
```

### Solution Pool (MIP)
Some solvers return multiple feasible solutions. PuLP exposes first solution only by default.

### Incumbent Callbacks
Not directly supported (solver-specific feature).

## Limitations

- Serialization overhead for very large problems
- No automatic differentiation or convexity checking
- Must manually handle nonlinear terms (not supported)
- Some advanced solver features inaccessible

## When to Use

- Need readable optimization code
- Want to prototype with CBC, deploy with Gurobi
- MIP problems (not just LP)
- Team unfamiliar with matrix formulation


---

# S2 Recommendation: Technical Implementation Guidance

## Performance-Driven Selection

### For Maximum Speed (LP only)
1. **scipy with HiGHS**: Zero overhead, excellent for 10K-100K variables
2. **OR-Tools GLOP**: Best for `>100`K variables or network flow problems
3. **Commercial solvers**: CPLEX/Gurobi via any library for `>500`K variables

### For MIP Performance
1. **OR-Tools CP-SAT**: Excellent for combinatorial problems (scheduling, assignment)
2. **Commercial via PuLP**: CPLEX/Gurobi for general MIP
3. **CBC via PuLP**: Good enough for `<10`K binary variables

## Architecture-Driven Selection

### For Prototyping → Production Path
```
Stage 1: CVXPY with ECOS (verify convexity, explore)
Stage 2: PuLP with CBC (readable code, free solver)
Stage 3: PuLP with Gurobi (performance, same code)
```

### For Pure Performance
```
Direct: scipy HiGHS (LP) or OR-Tools GLOP (large LP)
Skip modeling layer overhead, accept less readable code
```

### For Mixed Problems (LP + QP + SOCP)
```
CVXPY (automatic problem classification)
Single library for multiple problem types
```

## API Pattern Trade-offs

### Matrix Formulation (scipy)
**Pros**:
- Zero overhead
- NumPy integration
- Explicit problem structure

**Cons**:
- Not readable for complex constraints
- Error-prone for large models
- No symbolic debugging

**Best for**: Well-structured problems with clear matrix form (e.g., from optimization textbook).

### Modeling Language (PuLP, CVXPY)
**Pros**:
- Human-readable constraints
- Symbolic debugging
- Easier maintenance

**Cons**:
- Serialization overhead
- Some performance loss
- Abstraction complexity

**Best for**: Complex constraint logic, team collaboration, production systems.

### Low-Level API (OR-Tools)
**Pros**:
- Direct solver control
- Incremental updates
- Best performance

**Cons**:
- More verbose
- Steeper learning curve
- Less Pythonic

**Best for**: Performance-critical systems, advanced solver features needed.

## Numerical Stability Guidance

### Well-Conditioned Problems
Any library works. Choose based on API preference.

### Ill-Conditioned Problems
1. **CVXPY with SCS**: Best robustness
2. **scipy HiGHS**: Good presolve and scaling
3. **Avoid**: Basic CBC (less robust preconditioning)

### Very Large Sparse Problems
1. **OR-Tools GLOP**: Optimized for network structure
2. **scipy HiGHS**: Good sparse LA
3. **Commercial solvers**: For ultimate scalability

## Integration Pattern Recommendations

### Data Science Workflow (pandas/NumPy)
**Option A**: scipy (direct NumPy arrays)
```python
# DataFrame → NumPy → scipy → solution → DataFrame
```

**Option B**: CVXPY (native NumPy support)
```python
# Constraints on NumPy arrays/pandas Series
```

### Production API
**Pattern**: PuLP or OR-Tools with database integration
```python
# Query database → build model → solve → write results
```

Prefer PuLP for readability, OR-Tools for performance.

### Research Pipeline
**Pattern**: CVXPY for experimentation
```python
# cp.Parameter for parameterized families
# Fast re-solve with different data
```

## Solver Upgrade Path

### Free → Commercial Transition
All four libraries support commercial solvers:

```
Development: CBC/ECOS/HiGHS (free)
Staging: Gurobi academic license
Production: Gurobi/CPLEX commercial
```

**Easiest transition**: PuLP (same code, change one line)
**Most performance gain**: Switch from ECOS to CPLEX in CVXPY

## Anti-Patterns

### ❌ Don't: Use CVXPY for simple LP
If constraints are just `Ax <= b`, scipy is 10x simpler.

### ❌ Don't: Use scipy for MIP
No integer variable support. Use PuLP minimum.

### ❌ Don't: Use PuLP for `>100`K variables without commercial solver
Serialization overhead kills performance. Use OR-Tools or scipy.

### ❌ Don't: Build matrices manually in production
Modeling languages (PuLP/CVXPY) prevent bugs, cost `<10`% performance.

### ❌ Don't: Ignore sparsity
Dense 10K×10K matrix = 400MB. Sparse = `<1MB`. Use scipy.sparse or PuLP with sparse data.

## Team Skill Level Guidance

| Team Profile | Recommended Library | Why |
|--------------|---------------------|-----|
| Data scientists | scipy or CVXPY | NumPy-native, familiar workflow |
| Software engineers | PuLP | Readable, maintainable, OOP |
| Operations research | OR-Tools or PuLP | Full OR toolkit or standard modeling |
| Beginners | PuLP | Lowest learning curve |
| Performance experts | OR-Tools or scipy | Direct control, least overhead |

## Next Steps (S3-S4)

- **S3**: Map libraries to specific use cases (supply chain, portfolio, scheduling)
- **S4**: Evaluate long-term viability, community health, roadmap


---

# scipy.optimize.linprog - Technical Analysis

## Architecture

### Problem Representation
Uses standard form: minimize `c^T x` subject to `A_ub x <= b_ub`, `A_eq x = b_eq`, `bounds on x`.

Direct NumPy array input, no modeling layer.

### Solver Dispatch
`method` parameter selects algorithm:
- `'highs'`: Dispatches to HiGHS C++ solver (default since SciPy 1.6)
- `'highs-ds'`: Dual simplex
- `'highs-ipm'`: Interior-point method
- `'interior-point'`: Legacy SciPy IPM
- `'revised simplex'`: Legacy revised simplex

## Algorithm Deep-Dive

### HiGHS (Default)
- State-of-art open-source LP solver (2020s)
- Implements dual simplex, primal simplex, IPM
- Parallel presolve and scaling
- Competitive with commercial solvers for many problems
- Performance: 10^5 variables feasible, 10^6+ with sparse structure

### Interior-Point Method (Legacy)
- Predictor-corrector IPM
- Good for dense problems
- O(n^3) per iteration but fewer iterations than simplex
- Numerically stable for well-conditioned problems

### Revised Simplex (Legacy)
- Classical simplex with sparse linear algebra
- Better than basic simplex but slower than HiGHS
- Phase I/Phase II approach

## Performance Profile

| Problem Size | Variables | Constraints | Typical Time (HiGHS) |
|--------------|-----------|-------------|----------------------|
| Small | `<1`K | `<1`K | `<1`s |
| Medium | 1K-10K | 1K-10K | 1-10s |
| Large | 10K-100K | 10K-50K | 10s-minutes |
| Very Large | `>100`K | `>50`K | Minutes-hours |

Sparse problems scale better. Dense constraint matrices hit memory limits faster.

## API Pattern

Minimal example (no installation tutorial):
```python
c = [1, 2]  # Objective coefficients
A_ub = [[1, 1]]  # Inequality constraints
b_ub = [5]
result = linprog(c, A_ub=A_ub, b_ub=b_ub, method='highs')
# result.x contains solution, result.fun is optimal value
```

Direct array manipulation, no symbolic variables.

## Integration Capabilities

- **Input**: NumPy arrays (dense or sparse)
- **Output**: OptimizeResult object with solution, dual variables, status
- **Warm start**: Not supported
- **Sensitivity**: Can extract dual variables (`result.ineqlin.marginals`)
- **Export**: No MPS/LP file export

## Numerical Considerations

- Presolve enabled by default in HiGHS
- Automatic scaling
- Tolerances: `options={'presolve': True, 'tol': 1e-9}`
- HiGHS has robust preconditioning for ill-conditioned problems

## Limitations

- No integer variables (LP only)
- Must manually convert to standard form
- Large dense problems exhaust memory
- No incremental updates (must re-solve from scratch)

## When to Use

- Already in NumPy/SciPy workflow
- Problem naturally expressed as matrices
- Don't need MIP
- Want zero external dependencies

</details>

<details>
<summary>S3: Need-Driven</summary>

# S3-Need-Driven Approach: Linear Programming Use Cases

## Objective
Identify WHO needs linear programming and WHY, mapping libraries to specific user personas and problem domains.

## Scope
- **Focus**: Real-world use cases and user needs
- **Format**: Persona-driven (WHO + WHY), not implementation guides
- **Coverage**: 3-5 distinct use cases across industries
- **Depth**: Problem characteristics, requirements, validation criteria

## Use Case Selection Criteria

### 1. Representative Domains
- Supply chain / logistics
- Finance / portfolio optimization
- Operations / scheduling
- Network infrastructure
- Resource allocation

### 2. Problem Characteristics
- Variable scale (small/medium/large)
- Constraint complexity (simple/moderate/high)
- Performance requirements (batch/real-time)
- Data sources (databases, APIs, spreadsheets)

### 3. User Profiles
- Technical background (data scientist, engineer, analyst)
- Organizational context (startup, enterprise, academic)
- Tool ecosystem (Python, Excel, cloud platforms)

## Analysis Framework

### For Each Use Case:
1. **Who Needs This**: Persona, role, organization type
2. **Why This Problem**: Business value, pain points, current solutions
3. **Problem Characteristics**: Size, complexity, frequency, latency
4. **Success Criteria**: What makes a solution "good enough"
5. **Library Fit**: Which tools match these requirements

## Method
- Review industry applications of LP
- Identify common problem patterns
- Map problem characteristics to library strengths
- Validate with real-world examples

## Constraints
- NO implementation tutorials or code walkthroughs
- NO "how to" guides - focus on "why" and "who"
- Each file must start with "## Who Needs This" section


---

# S3 Recommendation: Use Case to Library Mapping

## Decision Matrix: Which Library for Your Use Case?

| Use Case | Problem Type | Scale | Best Library | Alternative | Why |
|----------|--------------|-------|--------------|-------------|-----|
| **Supply Chain** | LP + MIP | Medium-Large | PuLP | OR-Tools | Readable, solver flexibility, MIP |
| **Portfolio** | QP | Small-Medium | CVXPY | scipy.optimize | NumPy integration, QP support |
| **Workforce Scheduling** | MIP | Medium-Large | OR-Tools (CP-SAT) | PuLP | Combinatorial, binary assignment |
| **Network Flow** | LP (special structure) | Large | OR-Tools | scipy | Specialized flow algorithms |
| **Production Planning** | LP + MIP | Medium | PuLP | OR-Tools | Readable for engineers, MIP |

## Problem Type Patterns

### Pure Linear Programming (LP)
**Characteristics**: Continuous variables, linear constraints, linear objective
**Examples**: Network flow, simple portfolio (no variance), blending problems

**Library Choice**:
- **Small (`<1`K vars)**: scipy or PuLP (either works)
- **Medium (1K-10K)**: scipy (HiGHS) or PuLP (CBC)
- **Large (`>10`K)**: OR-Tools (GLOP) or commercial (CPLEX via any library)

### Mixed-Integer Programming (MIP)
**Characteristics**: Binary or integer variables, yes/no decisions
**Examples**: Facility location, production with setups, workforce scheduling

**Library Choice**:
- **General MIP**: PuLP (readable) or OR-Tools (performance)
- **Combinatorial (scheduling, assignment)**: OR-Tools CP-SAT
- **Large-scale**: Commercial solvers (Gurobi via PuLP)

### Quadratic Programming (QP)
**Characteristics**: Quadratic objective (e.g., minimize variance)
**Examples**: Portfolio optimization, regularized regression

**Library Choice**:
- **CVXPY** (first choice for QP + LP mix)
- **scipy.optimize.minimize** (for pure QP, no constraints)

### Network Flow (Special LP Structure)
**Characteristics**: Flow conservation, capacity constraints, graph structure
**Examples**: Transportation, telecommunications, power grid

**Library Choice**:
- **OR-Tools SimpleMinCostFlow** (fastest for pure flow problems)
- **scipy or PuLP** (if additional constraints beyond standard flow)

## User Persona Mapping

### Data Scientists / Analysts
**Background**: NumPy, pandas, Jupyter notebooks
**Preferred**: scipy or CVXPY
**Why**: NumPy-native, minimal syntax, fits data pipeline

**Use Case Fit**:
- Portfolio optimization (CVXPY)
- ML optimization problems (CVXPY)
- Small LP/QP prototypes (scipy)

### Industrial Engineers / Operations Managers
**Background**: Operations research, supply chain, manufacturing
**Preferred**: PuLP
**Why**: Readable constraints, matches OR textbooks, maintainable by business users

**Use Case Fit**:
- Production planning
- Supply chain optimization
- Resource allocation

### Software Engineers / Performance Engineers
**Background**: CS, systems programming, large-scale infrastructure
**Preferred**: OR-Tools
**Why**: Performance, comprehensive toolkit, Google-tested

**Use Case Fit**:
- Network routing
- Large-scale scheduling
- Vehicle routing, job shop scheduling

### Financial Quants / Researchers
**Background**: Math, finance, academic optimization
**Preferred**: CVXPY
**Why**: Mathematical rigor, DCP guarantees, research-grade

**Use Case Fit**:
- Portfolio optimization
- Risk management
- Trading strategy optimization

## Industry-Specific Recommendations

### Manufacturing
**Primary**: PuLP (production planning, scheduling)
**Secondary**: OR-Tools (complex job shop, large-scale)
**Integration**: ERP databases, MES systems

### Finance / Asset Management
**Primary**: CVXPY (portfolio, risk)
**Secondary**: scipy (simple problems)
**Integration**: Bloomberg, market data APIs

### Logistics / Supply Chain
**Primary**: PuLP (general optimization)
**Secondary**: OR-Tools (routing, large networks)
**Integration**: Shipping APIs, WMS, TMS

### Telecommunications / Utilities
**Primary**: OR-Tools (network flow, routing)
**Secondary**: scipy (smaller networks)
**Integration**: Network management systems, SCADA

### Healthcare / Services
**Primary**: OR-Tools CP-SAT (workforce scheduling)
**Secondary**: PuLP (simpler scheduling)
**Integration**: HR systems, EHR (scheduling)

## Organizational Context

### Startups / Small Teams
**Recommended**: PuLP or scipy
**Why**: Low barrier to entry, free solvers, easy to learn, good enough performance

**Upgrade Path**: Start with CBC, move to Gurobi academic → commercial

### Mid-Size Companies
**Recommended**: PuLP with commercial solver (Gurobi)
**Why**: Balance readability and performance, sustainable maintenance

**Investment**: Gurobi license ($10K-50K/year) pays off with 5-15% cost savings

### Enterprises / Large Scale
**Recommended**: OR-Tools or commercial solver APIs
**Why**: Performance critical, Google-scale reliability, integration with infrastructure

**Investment**: CPLEX/Gurobi enterprise licenses, dedicated optimization team

### Research / Academic
**Recommended**: CVXPY or scipy
**Why**: Mathematical correctness, reproducibility, publication-ready

**Flexibility**: Easy to experiment, compare algorithms, share models

## Technical Skill Level

### Beginner (New to Optimization)
1. **PuLP**: Easiest to learn, intuitive syntax
2. **scipy**: If already using NumPy/SciPy stack
3. Avoid: OR-Tools (too complex), CVXPY (DCP rules confusing)

### Intermediate (Some OR Background)
1. **PuLP or CVXPY**: Expressive, good documentation
2. **OR-Tools**: If performance matters
3. Can handle: All four libraries

### Expert (Optimization Specialist)
1. **OR-Tools**: Full control, best performance
2. **CVXPY**: Research problems, theoretical guarantees
3. **PuLP**: Production systems (maintainability > raw speed)
4. **scipy**: Quick prototypes

## Anti-Patterns (What Not to Do)

### ❌ Using scipy for MIP
**Problem**: scipy doesn't support integer variables
**Solution**: Use PuLP or OR-Tools

### ❌ Using PuLP for QP (portfolio optimization)
**Problem**: PuLP doesn't support quadratic objectives naturally
**Solution**: Use CVXPY or scipy.optimize

### ❌ Using CVXPY for large-scale LP
**Problem**: Overhead from DCP analysis and canonicalization
**Solution**: Use scipy (HiGHS) or OR-Tools (GLOP)

### ❌ Using general LP for network flow (`>10`K nodes)
**Problem**: Ignoring special structure, slow
**Solution**: Use OR-Tools SimpleMinCostFlow or specialized algorithms

### ❌ Manual matrix construction in production code
**Problem**: Error-prone, hard to maintain
**Solution**: Use modeling language (PuLP, CVXPY) for anything beyond prototypes

## Next Steps (S4)

- **S4**: Evaluate long-term ecosystem health
  - Community activity and maintenance
  - Solver ecosystem trends (HiGHS, OSQP, commercial)
  - Integration with modern stack (cloud, containers, APIs)
  - Future roadmap and sustainability


---

# Use Case: Network Flow and Allocation

## Who Needs This

**Persona**: Network engineers, infrastructure planners, and operations researchers at organizations managing flow-based systems.

**Background**:
- Often computer science, electrical engineering, or operations research background
- Design and optimize networks (telecommunications, power grids, water systems, transportation)
- Need to route flows efficiently under capacity constraints
- Work with graph structures, optimization tools, simulation software

**Organization Type**:
- Telecommunications providers (ISPs, CDNs)
- Utilities (electricity, water, gas distribution)
- Transportation agencies (traffic management, transit routing)
- Cloud infrastructure (data center networking)
- Supply chain (mentioned separately, but shares network structure)

## Why This Problem

**Business Need**:
Route flows through a network to minimize cost, maximize throughput, or balance load, subject to:
- **Capacity constraints**: Each edge/link has maximum flow
- **Conservation of flow**: What goes in must come out (except sources/sinks)
- **Demand satisfaction**: Deliver required amounts to destinations
- **Cost minimization**: Route via cheapest paths

**Pain Points Without Optimization**:
- Manual routing: Suboptimal, misses opportunities
- Greedy algorithms: Local optima, poor global allocation
- Load imbalance: Some links saturated, others idle
- Congestion: Network slowdowns from inefficient routing
- Cost: Paying for excess capacity or expensive routes

**Current Alternatives**:
- Shortest path algorithms (Dijkstra): Single-path, ignores capacity
- Load balancing heuristics (ECMP): Equal splitting, not optimal
- Simulation-based: Trial-and-error, slow
- Commercial network planners: Expensive, proprietary

## Problem Characteristics

**Scale**:
- Small: 10-100 nodes, 50-500 edges → 100-1K flow variables
- Medium: 100-1K nodes, 500-10K edges → 1K-20K variables
- Large: 1K-10K nodes, 10K-100K edges → 20K-500K variables
- Very large: Internet-scale routing → Millions of variables (special algorithms)

**Constraints**:
- **Flow conservation**: Inflow = outflow at intermediate nodes
- **Capacity**: Flow on edge ≤ edge capacity
- **Demand**: Flow from source to sink ≥ demand
- **Multicommodity**: Multiple source-destination pairs, shared capacity
- **Integer flows**: Some systems require discrete units (trucks, packets)

**Problem Types**:
- **Minimum cost flow**: Minimize routing cost while satisfying demands
- **Maximum flow**: Maximize throughput from source to sink
- **Multicommodity flow**: Multiple concurrent flows sharing infrastructure
- **Network design**: Choose which links to build (MIP with binary decisions)

**Update Frequency**:
- Strategic: Annual or quarterly (infrastructure planning)
- Tactical: Monthly or weekly (routing policy updates)
- Operational: Real-time (dynamic traffic routing)

**Data Sources**:
- Network topology (graph databases, configuration files)
- Capacity data (link speeds, power ratings)
- Demand matrices (traffic measurements, forecasts)
- Cost data (transit costs, energy prices)

## Success Criteria

**Good Enough Solution**:
- Cost reduction: 15-30% vs naive routing
- Solve time: `<5` minutes for tactical planning, `<1` second for operational
- Throughput: 95%+ of theoretical maximum (given capacities)
- Load balance: No link `>80`% utilized while others `<20`%
- Scalability: Handle 10K+ nodes for strategic planning

**Nice to Have**:
- Sensitivity analysis: Impact of link failures
- Scenario planning: Compare routing policies
- Real-time adaptation: Re-route on failures or congestion
- Visualization: Flow maps, bottleneck identification

## Library Fit

### Recommended: OR-Tools
**Why**:
- Network flow is a **classic LP problem** with special structure
- OR-Tools has optimized network flow algorithms (not just general LP)
  - `SimpleMinCostFlow`: Specialized for min-cost flow (very fast)
  - `SimpleMaxFlow`: For maximum flow problems
  - GLOP: General LP for complex variants
- Scales to 100K+ nodes efficiently
- C++ core provides performance for real-time use

**Typical Pattern**:
```
Load graph → Define flows → Solve min-cost flow → Route traffic
```

### Alternative: scipy
**When**:
- Pure min-cost flow (no additional constraints)
- NumPy graph representation
- Smaller networks (`<10`K nodes)

**Trade-off**: General LP solver, not specialized for network structure.

### Alternative: PuLP
**When**:
- Need readable code for multicommodity flow
- Additional constraints beyond standard flow problems
- Team prefers modeling language over graph API

**Trade-off**: Slower than specialized network flow solvers.

### Not Recommended: CVXPY
**Why**: Network flow is LP (not QP/SOCP), CVXPY overhead unnecessary.

### Special Case: NetworkX
**Python library**: Has basic network flow algorithms (not optimization library)
- **Good for**: Small graphs, quick prototypes, single-source flow
- **Not good for**: Multicommodity, large-scale, cost minimization with complex constraints

## Validation Checklist

- [ ] Handles flow conservation constraints naturally?
- [ ] Scales to 10K+ nodes for strategic planning?
- [ ] Solves min-cost flow in `<1` minute for tactical use?
- [ ] Supports multicommodity flow (multiple commodities sharing edges)?
- [ ] Integrates with graph databases or NetworkX?
- [ ] Provides dual variables (shadow prices on capacity)?


---

# Use Case: Portfolio Optimization

## Who Needs This

**Persona**: Quantitative analysts (quants) and portfolio managers at investment firms, robo-advisors, or asset management teams.

**Background**:
- Often have finance, math, or physics PhD
- Work with time-series data (prices, returns, volatility)
- Build models in Python/R, use NumPy/pandas heavily
- Optimize asset allocation under risk/return constraints

**Organization Type**:
- Hedge funds and asset managers
- Robo-advisory platforms (Betterment, Wealthfront)
- Pension funds and endowments
- Prop trading desks

## Why This Problem

**Business Need**:
Allocate capital across assets to maximize return for given risk tolerance, subject to constraints:
- No short selling (long-only)
- Sector exposure limits (e.g., ≤20% in tech)
- Minimum/maximum position sizes
- Transaction cost minimization (rebalancing)

**Pain Points Without Optimization**:
- Manual allocation: Ignores correlations, suboptimal
- Equal weighting: Naive, doesn't consider risk
- Rules-of-thumb (60/40 stocks/bonds): Inflexible
- Excel-based: Doesn't scale to 100s of assets

**Current Alternatives**:
- Mean-variance optimization (Markowitz): Quadratic programming
- Risk parity: Specialized algorithm
- Commercial platforms (Bloomberg PORT, FactSet): Expensive, black box

## Problem Characteristics

**Scale**:
- Small: 10-50 assets (ETF portfolio) → `<100` variables
- Medium: 100-500 stocks (sector rotation) → 100-1K variables
- Large: 1000+ securities (institutional) → 1K-10K variables

**Constraints**:
- Budget: Sum of weights = 1 (or allocated capital)
- Long-only: All weights ≥ 0 (or allow shorting with bounds)
- Sector limits: Sum of tech stocks ≤ 20%
- Position limits: Each asset ≤ 10% of portfolio
- Turnover: Limit changes from previous allocation (rebalancing cost)

**Update Frequency**:
- Strategic: Quarterly rebalancing (batch)
- Tactical: Monthly or weekly (batch)
- High-frequency: Daily or intraday (low latency)

**Data Sources**:
- Price feeds (Bloomberg, Yahoo Finance, APIs)
- Risk models (covariance matrices)
- Fundamental data (earnings, valuation)
- Transaction cost models

## Success Criteria

**Good Enough Solution**:
- Risk-adjusted return: Outperform benchmark by 50-200 bps
- Solve time: `<1` minute for daily rebalancing
- Numerical stability: Handles near-singular covariance matrices
- Explainability: Understand why allocation changed
- Backtesting: Easy to run historical simulations

**Nice to Have**:
- Robust optimization: Hedge against model uncertainty
- Scenario analysis: Stress test allocations
- Multi-period: Optimize over time horizon
- Transaction cost integration

## Library Fit

### Recommended: CVXPY
**Why**:
- Portfolio optimization is often **quadratic programming** (QP), not pure LP
  - Minimize variance (quadratic) while constraining expected return (linear)
- CVXPY handles QP naturally (OSQP solver)
- NumPy integration: covariance matrices are NumPy arrays
- DCP ensures mathematical correctness
- Parameters for efficient re-optimization (new data, same structure)

**Typical Pattern**:
```
Load returns → Compute covariance → Formulate QP → Solve → Backtest
```

### Alternative: scipy (cvxopt backend)
**When**:
- Pure mean-variance (quadratic objective)
- Small problems (`<100` assets)
- Want minimal dependencies

**Trade-off**: Less expressive than CVXPY, limited to basic QP.

### Not Recommended: PuLP
**Why**: Designed for LP/MIP, not QP. Can do piecewise-linear approximations but clunky.

### Not Recommended: OR-Tools
**Why**: Not focused on portfolio optimization, lacks QP support.

### Special Case: Pure LP Portfolio
If objective is **linear** (e.g., maximize expected return, ignore variance):
- **scipy** or **PuLP** work fine
- Example: Index tracking (minimize absolute deviation from index weights)

## Validation Checklist

- [ ] Handles quadratic objectives (variance minimization)?
- [ ] NumPy/pandas integration for covariance matrices?
- [ ] Solves 100-500 asset problem in `<10` seconds?
- [ ] Supports parameters for fast re-optimization?
- [ ] Provides dual variables (shadow prices of constraints)?
- [ ] Numerically stable for near-singular covariances?


---

# Use Case: Production Planning and Resource Allocation

## Who Needs This

**Persona**: Production planners, industrial engineers, and operations managers at manufacturing companies.

**Background**:
- Often industrial engineering, business, or supply chain background
- Manage production lines, machines, raw materials
- Balance production capacity, inventory costs, and customer demand
- Use ERP systems (SAP, Oracle), Excel, or specialized MRP software

**Organization Type**:
- Discrete manufacturers (automotive, electronics, consumer goods)
- Process industries (chemicals, pharmaceuticals, food & beverage)
- Job shops and contract manufacturers
- Fabrication and assembly plants

## Why This Problem

**Business Need**:
Decide what to produce, when, and on which machines to:
- Minimize total cost (production + inventory + overtime + shortages)
- Maximize profit (revenue - costs)
- Meet customer orders and forecasted demand
- Respect production capacity, material availability, labor constraints

**Pain Points Without Optimization**:
- Manual planning: Time-consuming, reactive to crises
- Excel-based MRP: Brittle formulas, no global optimization
- Excess inventory: Tying up 20-40% of working capital
- Stockouts: Lost sales, rush orders, premium freight
- Inefficient changeovers: Wasted machine time, high setup costs

**Current Alternatives**:
- MRP systems: Rule-based (not optimization), myopic
- Spreadsheets: Limited scale, no scenario analysis
- External consultants: One-off studies, not integrated
- "Tribal knowledge": Experienced planners, but inconsistent and not scalable

## Problem Characteristics

**Scale**:
- Small: Single line, 10-50 products, monthly plan → 500-5K variables
- Medium: 5-10 lines, 100-500 products, weekly plan → 10K-100K variables
- Large: Multiple plants, 1000+ SKUs, daily plan → 100K-1M variables

**Constraints**:
- **Capacity**: Machine hours, labor hours, storage space
- **Material**: Bill of materials (BOM), raw material availability
- **Demand**: Customer orders (firm), forecasts (uncertain)
- **Inventory**: Safety stock levels, max storage capacity
- **Setup/Changeover**: Time and cost to switch between products
- **Lead times**: Production delays, material procurement delays

**Decision Variables**:
- **Continuous**: Production quantities (how much to make)
- **Binary**: Setup decisions (produce product X in period T: yes/no)
- **Integer**: Batch sizes (number of batches to run)

**Update Frequency**:
- Strategic: Annual or quarterly (capacity expansion, product mix)
- Tactical: Monthly (aggregate production plan)
- Operational: Weekly or daily (detailed schedule)
- Real-time: Shift-level adjustments (machine breakdowns, rush orders)

**Data Sources**:
- ERP systems (orders, inventory, BOM)
- MES (Manufacturing Execution System): Machine status, yield rates
- Demand forecasts (sales, marketing)
- Cost data (materials, labor, overhead)

## Success Criteria

**Good Enough Solution**:
- Cost reduction: 5-15% total production + inventory cost
- Inventory reduction: 20-30% while maintaining service levels
- Fill rate: 95%+ of orders delivered on time
- Solve time: `<1` hour for monthly plan, `<15` minutes for weekly
- Scenario analysis: Evaluate multiple demand/capacity scenarios
- Explainability: Planners understand why decisions changed

**Nice to Have**:
- Robust optimization: Hedge against demand uncertainty
- Multi-period: Optimize over rolling horizon (12 weeks)
- Integration: Sync with ERP (read orders, write production plan)
- What-if analysis: "What if we add one more machine?"

## Library Fit

### Recommended: PuLP
**Why**:
- Production planning is **mixed-integer programming** (MIP)
  - Binary decisions: Setup yes/no, run product or not
  - Continuous: Production quantities
- PuLP's modeling syntax matches production planning concepts
  - Easy to express capacity, BOM, inventory balance constraints
- Can start with CBC (free), upgrade to Gurobi for large-scale
- Readable code: Industrial engineers can maintain models

**Typical Pattern**:
```
Load orders/BOM/capacity → Build MIP → Solve → Export production plan to ERP
```

### Alternative: OR-Tools (CP-SAT)
**When**:
- Complex sequencing (job shop scheduling)
- Very large-scale (`>100`K binary variables)
- Need special constraints (disjunctive, cumulative)

**Trade-off**: Steeper learning curve, less readable for planners.

### Not Recommended: scipy
**Why**: No MIP support (can't handle setup decisions, batch sizes).

### Not Recommended: CVXPY
**Why**: Production planning has binary variables; CVXPY's MIP is less mature.

### Special Case: Continuous Production (no setups)
If production is continuous (e.g., refining, flow processes) with no setup costs:
- **scipy** or **PuLP** with LP solvers (no integrality needed)

## Validation Checklist

- [ ] Handles binary setup decisions and continuous production quantities?
- [ ] Expresses multi-period inventory balance constraints?
- [ ] Solves weekly planning problem (`<500` products) in `<15` minutes?
- [ ] Integrates with ERP databases (read BOM, orders; write plan)?
- [ ] Supports scenario analysis (multiple demand forecasts)?
- [ ] Can model setup costs and changeover times?


---

# Use Case: Supply Chain Optimization

## Who Needs This

**Persona**: Supply chain analysts and operations managers at manufacturing companies or logistics firms.

**Background**:
- Often have business analytics or industrial engineering background
- Work with ERP systems, inventory databases, shipping APIs
- Need to optimize flows (materials, goods, shipments) under constraints
- Report to operations executives who care about cost and service levels

**Organization Type**:
- Mid-size manufacturers (100-1000 employees)
- 3PL (third-party logistics) providers
- E-commerce fulfillment operations

## Why This Problem

**Business Need**:
Minimize transportation and inventory costs while meeting demand and capacity constraints. Typical questions:
- Which warehouses should supply which customers?
- How much inventory to hold at each location?
- Which shipping routes minimize cost under delivery time constraints?

**Pain Points Without Optimization**:
- Manual planning: slow, error-prone, suboptimal
- Spreadsheet-based: doesn't scale beyond 100s of variables
- Rules-of-thumb: leaves 10-30% cost savings on table
- Ad-hoc decisions: inconsistent, hard to audit

**Current Alternatives**:
- Excel Solver (limited scale, fragile)
- Commercial supply chain software (expensive, inflexible)
- Consultant-built models (one-off, not maintained)

## Problem Characteristics

**Scale**:
- Small: Single facility, `<500` SKUs, `<50` customers → 1K-10K variables
- Medium: Regional network, 5-10 facilities, 1000s SKUs → 10K-100K variables
- Large: National network, `>50` facilities, omnichannel → 100K-1M variables

**Constraints**:
- Supply: Production capacity, inventory levels
- Demand: Customer orders, forecast accuracy
- Logistics: Shipping capacity, lead times, service levels
- Business rules: Minimum order quantities, preferred suppliers

**Update Frequency**:
- Strategic planning: Monthly or quarterly (batch)
- Tactical planning: Weekly (batch)
- Operational: Daily or real-time (low latency)

**Data Sources**:
- ERP databases (SAP, Oracle)
- Demand forecasts (Excel, BI tools)
- Shipping APIs (FedEx, UPS, freight carriers)
- Cost tables (accounting systems)

## Success Criteria

**Good Enough Solution**:
- Cost reduction: 10-20% vs manual planning
- Solve time: `<1` hour for strategic, `<15` minutes for tactical, `<1` minute for operational
- Explainability: Business users can understand recommendations
- Robustness: Handles demand variability, infeasibility cases
- Integration: Works with existing ERP/BI stack

**Nice to Have**:
- Sensitivity analysis: "What if warehouse X goes offline?"
- Multiple scenarios: Compare optimistic/pessimistic demand
- Visualization: Maps of shipping flows

## Library Fit

### Recommended: PuLP
**Why**:
- Readable constraint syntax (easy for analysts to maintain)
- Scales to 10K-100K variables with CBC
- Can upgrade to Gurobi when growth demands it
- Good for MIP (discrete shipment sizes, yes/no facility decisions)
- Export to LP files for audit trail

**Typical Pattern**:
```
Build model from database → Solve weekly → Write results back
```

### Alternative: OR-Tools
**When**:
- Very large networks (`>100`K variables)
- Need routing optimization (VRP component)
- Performance critical (real-time operational decisions)

**Trade-off**: Steeper learning curve, harder for analysts to maintain.

### Not Recommended: scipy
**Why**: No MIP support (can't handle discrete decisions like "open facility or not").

### Not Recommended: CVXPY
**Why**: Designed for convex optimization, less mature MIP support than PuLP.

## Validation Checklist

- [ ] Can express supply, demand, capacity constraints naturally?
- [ ] Handles MIP (discrete facility/route decisions)?
- [ ] Solves weekly planning problem in `<15` minutes?
- [ ] Integrates with SQL databases or pandas DataFrames?
- [ ] Business users can read the constraint code?
- [ ] Can switch solvers as problem grows?


---

# Use Case: Workforce Scheduling

## Who Needs This

**Persona**: Operations managers and workforce planners at service businesses with shift-based workers.

**Background**:
- Often business operations or HR background, limited programming
- Manage 50-5000 employees across multiple locations
- Balance labor costs, coverage requirements, and employee preferences
- Use scheduling software, spreadsheets, or manual roster building

**Organization Type**:
- Hospitals and healthcare systems
- Call centers and customer service
- Retail chains and restaurants
- Security and facility services
- Transportation (drivers, pilots, crew)

## Why This Problem

**Business Need**:
Assign employees to shifts to meet demand while minimizing labor costs and respecting constraints:
- Coverage: Enough staff for expected customer volume
- Skills: Right mix of capabilities (nurses, cashiers, supervisors)
- Labor rules: Max hours per week, rest periods, overtime limits
- Preferences: Employee availability, shift preferences, seniority

**Pain Points Without Optimization**:
- Manual scheduling: 5-20 hours per week for managers
- Understaffing: Lost sales, poor service quality
- Overstaffing: Wasted labor costs (10-20% excess)
- Burnout: Unfair distribution, disregard for preferences
- Compliance: Violate labor laws, union agreements

**Current Alternatives**:
- Manual spreadsheets: Tedious, error-prone
- Scheduling software: Often heuristic-based, suboptimal
- External consultants: Expensive, not real-time
- Staff just says "this is how we've always done it"

## Problem Characteristics

**Scale**:
- Small: Single location, 20-50 employees, 7-day schedule → 1K-5K variables
- Medium: 5-10 locations, 100-500 employees, 2-4 week schedule → 10K-50K variables
- Large: 50+ locations, 1000+ employees, monthly schedule → 100K-1M variables

**Constraints**:
- **Coverage**: Each shift has min/max staff requirements
- **Availability**: Employees specify when they can work
- **Labor rules**: Max consecutive days, min rest hours, max weekly hours
- **Skills**: Certain shifts require certified staff
- **Fairness**: Equitable weekend/holiday distribution
- **Budget**: Total labor cost ≤ budget

**Decision Variables**:
- Binary: Employee X assigned to shift Y (yes/no)
- Integer: Number of staff on shift Y
- Continuous: Hours worked by employee X

**Update Frequency**:
- Long-term: Monthly or quarterly (strategic staffing levels)
- Medium-term: Weekly or biweekly (shift assignments)
- Short-term: Daily (swap requests, sick calls)

**Data Sources**:
- HR systems (employee data, certifications)
- Demand forecasts (customer traffic, call volume)
- Timekeeping systems (availability, time off requests)
- Labor cost data (wages, overtime rates)

## Success Criteria

**Good Enough Solution**:
- Cost savings: 10-15% labor cost reduction
- Manager time: `<1` hour per week on scheduling (vs 5-20 hours manual)
- Coverage quality: 95%+ shifts meet minimum requirements
- Employee satisfaction: Respect 90%+ of availability preferences
- Solve time: `<30` minutes for weekly schedule
- Compliance: Zero labor law violations

**Nice to Have**:
- Shift swaps: Easy employee-initiated changes
- Scenario analysis: "What if demand spikes 20%?"
- Mobile app: Employees view schedules, request changes
- Auto-adjustments: Re-optimize when employee calls in sick

## Library Fit

### Recommended: OR-Tools (CP-SAT)
**Why**:
- Workforce scheduling is **mixed-integer programming** (MIP) with many binary variables
- CP-SAT excels at combinatorial problems (assignment, scheduling)
- Can handle complex constraints (consecutive shifts, rest periods)
- Scales to 100K+ binary variables
- Fast for structured problems (patterns in shift assignments)

**Typical Pattern**:
```
Load employee/shift data → Build MIP → Solve → Export schedule → Handle swap requests
```

### Alternative: PuLP
**When**:
- Simpler constraints (basic coverage, no complex sequencing)
- Smaller scale (`<10`K variables)
- Team prefers more readable Python code

**Trade-off**: Slower than OR-Tools for large-scale or complex constraints.

### Not Recommended: scipy
**Why**: No MIP support (can't handle binary assignment decisions).

### Not Recommended: CVXPY
**Why**: Less mature MIP capabilities than OR-Tools or PuLP.

### Special Case: Continuous Scheduling
If variables are continuous hours (e.g., part-time with flexible hours):
- **scipy** or **PuLP** with LP solvers (no integrality needed)

## Validation Checklist

- [ ] Handles binary assignment variables (employee → shift)?
- [ ] Expresses complex constraints (consecutive shifts, rest periods)?
- [ ] Solves weekly schedule in `<30` minutes?
- [ ] Integrates with HR databases or CSV files?
- [ ] Supports incremental updates (add/remove employees)?
- [ ] Provides infeasibility diagnosis (why no feasible schedule)?

</details>

<details>
<summary>S4: Strategic</summary>

# S4-Strategic Approach: Long-Term Viability

## Objective
Evaluate the long-term strategic viability of linear programming libraries from ecosystem, community, and architectural perspectives.

## Scope
- **Focus**: 3-5 year outlook, not just current state
- **Dimensions**: Community health, maintenance trajectory, solver ecosystem, integration trends
- **Risk Assessment**: Bus factor, commercial dependencies, breaking changes
- **Investment Advice**: Which libraries are safe bets for new projects?

## Analysis Dimensions

### 1. Community and Maintenance
- Contributor diversity (bus factor)
- Commit frequency and response times
- Issue resolution patterns
- Breaking change history
- Long-term maintainer commitment

### 2. Solver Ecosystem Trends
- Open-source solver maturity (HiGHS, OSQP, SCS)
- Commercial solver integration
- New solvers emerging (Clarabel, cuPDLP)
- GPU/parallel trends

### 3. Integration and Deployment
- Cloud platform support
- Containerization and packaging
- API and microservice patterns
- Modern Python ecosystem (type hints, async)

### 4. Competitive Landscape
- New entrants and threats
- Specialized alternatives
- Commercial platform consolidation
- Academic vs industrial focus

### 5. Technical Debt and Architecture
- Code quality and test coverage
- Backward compatibility commitments
- Migration paths between versions
- API stability

## Method
- GitHub metrics analysis (stars, commits, issues, PRs)
- Release history and versioning patterns
- Community forum activity (Stack Overflow, Discourse)
- Roadmap and governance review
- Comparative trend analysis

## Questions to Answer
- Which libraries are actively maintained vs maintenance mode?
- What is the risk of abandonment or breaking changes?
- How dependent is each library on commercial solvers?
- What are the emerging solver technologies?
- Which libraries align with modern Python best practices?

## Constraints
- Focus on strategic outlook, not immediate features
- Consider organizational risk tolerance
- Balance innovation vs stability


---

# CVXPY - Strategic Viability

## Community and Maintenance (2026)

**Status**: Active development, Stanford-led research project

- **Maintainer Model**: Academic-led, 5-10 core contributors (Stanford, industry)
- **Bus Factor**: Moderate (depends on 3-4 key maintainers, Steven Diamond as BDFL)
- **Commit Frequency**: Weekly commits, quarterly releases
- **Issue Resolution**: 90%+ issues triaged within 1 week (very responsive)
- **Breaking Changes**: Rare post-v1.0 (2018), strong backward compatibility

**Risk Level**: **Low**
- Strong academic backing (Stanford Convex Optimization Group)
- Industry sponsorship (Mosek, Gurobi partnerships)
- Active research → continuous improvement

## Solver Ecosystem

**Current (2026)**:
- **Open-source**: ECOS, OSQP, SCS, GLPK, CBC (10+ solvers)
- **Commercial**: CPLEX, Gurobi, Mosek (well-integrated)
- **Specialized**: Clarabel (Rust-based, emerging), cuPDLP (GPU)

**Trends**:
- **Expanding**: New solvers added regularly (Clarabel 2024, cuPDLP 2025)
- **GPU**: Growing interest in GPU acceleration (SCS CUDA, cuPDLP)
- **Rust**: Clarabel (Rust solver) shows ecosystem modernization

**Strategic Assessment**:
- **Future-focused**: Actively integrating cutting-edge solvers
- **Innovation**: More experimental than PuLP or scipy
- **Risk**: Some new solvers less mature (beta quality)

**Key Advantage**: Automatic solver selection (CVXPY picks best solver for problem type)

## Integration and Modern Python

**Current**:
- **Type hints**: Full support (added v1.3, 2023)
- **Python 3.10+**: Yes, 3.12 support added 2024
- **Async**: Limited (not priority for batch optimization)
- **Packaging**: PyPI, conda-forge

**Modern Features**:
- Protocols and generics for type safety
- Dataclass integration for problem parameters
- NumPy 2.0 ready

**Strategic Assessment**:
- **Modern**: Best Python practices adopted
- **Active**: Keeps pace with Python ecosystem
- **Academic focus**: Less microservice-oriented than OR-Tools

## Competitive Landscape

**Threats**:
- **PuLP**: Simpler API for pure LP/MIP
- **OR-Tools**: Performance, Google backing
- **Specialized tools**: Pyomo (nonlinear), JAX-based optimization

**Strengths**:
- **Mathematical rigor**: DCP guarantees correctness
- **Academic mindshare**: Taught in optimization courses
- **Versatility**: Handles LP, QP, SOCP, SDP in one framework
- **Research**: Bleeding-edge features (GPU, new algorithms)

**Strategic Assessment**:
- **Growing**: Academic → industry adoption trend
- **Differentiated**: DCP and multi-problem-type support unique
- **Niche**: Not replacing PuLP/OR-Tools, but complementing

## Technical Debt and Architecture

**Code Quality**:
- **Test coverage**: `>95`% (excellent)
- **Architecture**: Clean, modular, well-documented
- **C extensions**: Minimal (Python-first, solver interfaces in C)

**API Stability**:
- v1.0 (2018): Major API stabilization
- Post-v1.0: Strong semver discipline
- Deprecation: 2-release warning cycle

**Migration Risk**: **Very Low**
- v0.x → v1.0 was last major break (2018)
- v1.x series stable (2018-2026, no breaks)
- Code from 2018 runs in 2026 unchanged

## Long-Term Investment Advice

### Safe for New Projects? **YES** (especially for research/QP)
**Reasons**:
- Active development, growing adoption
- Strong academic backing (Stanford, MIT, other universities)
- Best-in-class for mixed problem types (LP + QP + SOCP)
- Modern Python practices

**Caveats**:
- Overkill for pure LP (scipy simpler)
- DCP learning curve (requires convex optimization understanding)
- Less industry battle-testing than PuLP (but growing)

**Best For**:
- Portfolio optimization (QP native support)
- Research projects (mathematical correctness)
- Mixed problem types (don't know if you'll need QP later)
- Teams prioritizing modern Python

**Not Ideal For**:
- Pure MIP (PuLP or OR-Tools more mature)
- Very large-scale LP (scipy or OR-Tools faster)
- Teams unfamiliar with convex optimization

### 3-5 Year Outlook

| Dimension | Trend | Impact |
|-----------|-------|--------|
| Maintenance | Growing | ✅ Accelerating development |
| Performance | Improving | ✅ GPU, new solvers (Clarabel, cuPDLP) |
| Features | Expanding | ✅ Differentiable optimization, stochastic |
| Community | Growing | ✅ Industry adoption increasing |
| Breaking Changes | None expected | ✅ v1.x stable, v2.0 not planned |

### Risk Mitigation

**Key Risks**:
- **Academic project risk**: If funding ends, maintenance slows
- **BDFL risk**: Steven Diamond departure would impact direction
- **Solver dependencies**: Relies on external solvers (but diverse set)

**Mitigation**:
- **Industry sponsors**: Mosek, Gurobi have vested interest
- **Growing community**: Less dependent on single person
- **Fallback**: Can use solvers directly if CVXPY abandoned (unlikely)

## Governance and Sustainability

**Governance**: Informal (Steven Diamond as lead, community input)
**Funding**: Academic grants, industry sponsorships (Mosek, Gurobi), donations
**Transparency**: Open development, GitHub, public roadmap

**Sustainability Score**: **8/10**
- Financial: Academic grants + industry partnerships (good, not bulletproof)
- Social: Growing contributor base, active community
- Technical: Excellent code quality, high test coverage

**Strengths**: Strong technical foundation, growing adoption
**Concerns**: Dependent on academic funding cycle

## Recommendation

**Strategic Position**: **Modern, Future-Focused Choice**

CVXPY is the **sophisticated, modern alternative** for optimization. Best for:
- Projects needing QP, SOCP, or SDP (not just LP)
- Teams wanting cutting-edge solvers (GPU, Rust)
- Organizations prioritizing code quality and type safety

**Ideal Timeline**: 5-10 years
**Use When**: Multiple problem types, research, modern Python stack, QP/convex

**Consider Alternatives**:
- **PuLP**: If pure MIP and battle-testing matters
- **scipy**: If pure LP and simplicity preferred
- **OR-Tools**: If performance trumps elegance

### Verdict

**Safe to invest in CVXPY?** **Yes, especially for forward-looking projects**
- Use CVXPY for portfolio optimization (QP)
- Use CVXPY for research (correctness guarantees)
- Use CVXPY for mixed problem types (don't know future needs)

**Trend**: CVXPY is gaining momentum, likely to grow faster than PuLP in next 5 years (academic → industry pipeline).

### The "No-Regrets" Scenario

If you pick CVXPY today:
- **2026**: Modern, well-maintained, good choice
- **2031**: Likely even better (more solvers, GPU, larger community)

If you pick PuLP today:
- **2026**: Stable, proven, good choice
- **2031**: Probably same (slower innovation, risk of stagnation)

**For new projects in 2026**: **Lean toward CVXPY** unless you know you need MIP-only (then PuLP).


---

# OR-Tools - Strategic Viability

## Community and Maintenance (2026)

**Status**: Active development, Google internal + open-source project

- **Maintainer Model**: Google team (10-15 engineers) + external contributors
- **Bus Factor**: High (Google team, institutional commitment)
- **Commit Frequency**: Daily commits, monthly releases
- **Issue Resolution**: 85-90% issues triaged within days (fast)
- **Breaking Changes**: Rare, but API evolved 2015-2023 (C++ → Python parity)

**Risk Level**: **Very Low**
- Google uses OR-Tools internally (production at scale)
- Not a side project - core infrastructure at Google
- Large team, institutional backing

## Solver Ecosystem

**Current (2026)**:
- **Built-in**: GLOP (LP), CP-SAT (MIP/CP), BOP (boolean)
- **Bundled**: SCIP (open-source MIP)
- **External**: CPLEX, Gurobi, Xpress (if installed)
- **Specialized**: Vehicle routing, graph algorithms

**Trends**:
- **GLOP improvements**: Continuous optimization (Google-funded)
- **CP-SAT dominance**: Best-in-class constraint programming solver
- **Routing**: Industry-leading vehicle routing algorithms

**Strategic Assessment**:
- **Self-sufficient**: GLOP and CP-SAT are world-class (no external dependency)
- **Innovation**: Google invests in solver R&D (not relying on external projects)
- **Long-term**: Google committed to maintaining own solvers (strategic asset)

**Key Advantage**: CP-SAT is arguably the best free MIP solver for combinatorial problems (scheduling, assignment).

## Integration and Modern Python

**Current**:
- **Type hints**: Partial (C++ core, Python bindings)
- **Python 3.10+**: Yes
- **Async**: Limited (not primary focus)
- **Packaging**: PyPI, conda, Docker images

**API Evolution**:
- C++-first design (Python is bindings)
- Protobuf-based problem specification (modern, structured)
- Some Python API quirks (C++ influence)

**Strategic Assessment**:
- **Practical**: Works well, but not pure-Python elegance
- **Performance**: C++ core is a feature, not a bug
- **Cloud-native**: Good Docker/Kubernetes support

## Competitive Landscape

**Threats**:
- **None at scale**: No free alternative for Google-scale problems
- **Specialized**: PuLP/CVXPY for simpler/academic problems

**Strengths**:
- **Google brand**: Trust, reliability, battle-testing
- **Performance**: GLOP and CP-SAT competitive with commercial
- **Comprehensive**: Routing, graph, CP, LP, MIP in one toolkit
- **Industry use**: Uber, Lyft, others use OR-Tools for routing

**Strategic Assessment**:
- **Defensible**: Google's internal use ensures longevity
- **Growing**: More companies adopting for routing, scheduling
- **Trend**: Becoming the de facto standard for vehicle routing

## Technical Debt and Architecture

**Code Quality**:
- **Test coverage**: High (Google internal standards)
- **Architecture**: C++ core, clean interfaces, protobuf specs
- **Documentation**: Good, but C++-centric (Python examples exist)

**API Stability**:
- Major API changes rare post-2020
- Deprecation cycle: Warning → 6-12 months → removal
- C++ API more stable than Python (Python evolves faster)

**Migration Risk**: **Low**
- Historical: Some API churn 2015-2020 (stabilization phase)
- Current: Stable, breaking changes rare
- Future: Google's internal use constrains breaking changes

## Long-Term Investment Advice

### Safe for New Projects? **YES** (especially for performance/scale)
**Reasons**:
- Google backing ensures longevity
- Best-in-class performance for LP and combinatorial problems
- Active development, continuous improvement
- Production-tested at scale

**Caveats**:
- Steeper learning curve (C++ influence)
- Overkill for small problems
- API less "Pythonic" than PuLP/CVXPY

**Best For**:
- Large-scale LP (`>100`K variables)
- Combinatorial optimization (scheduling, assignment, routing)
- Production systems needing reliability
- Vehicle routing problems (best-in-class)

**Not Ideal For**:
- Beginners (learning curve)
- QP or convex beyond LP/MIP (use CVXPY)
- Small problems where readability > performance

### 3-5 Year Outlook

| Dimension | Trend | Impact |
|-----------|-------|--------|
| Maintenance | Very active | ✅ Google internal use guarantees support |
| Performance | Improving | ✅ GLOP, CP-SAT continuous optimization |
| Features | Expanding | ✅ New routing features, constraint types |
| Community | Growing | ✅ Industry adoption (Uber, Lyft, etc.) |
| Breaking Changes | Rare | ✅ Stable, internal use constrains changes |

### Risk Mitigation

**Key Risks**:
- **Google abandonment**: Extremely unlikely (internal use)
- **API churn**: Low risk (stabilized)
- **Learning curve**: Mitigated by documentation, examples

**Mitigation**:
- **Monitor**: Google's optimization team blog, releases
- **Fallback**: Solvers are independent (GLOP, CP-SAT can be used without OR-Tools API if needed)
- **Community**: Growing user base reduces dependency on Google alone

## Governance and Sustainability

**Governance**: Google-led, community contributors welcome
**Funding**: Google internal funding (part of infrastructure budget)
**Transparency**: Open-source (Apache 2.0), public GitHub

**Sustainability Score**: **10/10**
- Financial: Google budget (unlimited for practical purposes)
- Social: Large team, growing community
- Technical: Excellent code quality, high test coverage

**No concerns**: This is as sustainable as it gets for open-source projects.

## Recommendation

**Strategic Position**: **Industrial-Strength, Production-Grade**

OR-Tools is the **performance and reliability choice**. Best for:
- Companies needing Google-scale capabilities
- Performance-critical systems
- Vehicle routing, scheduling, assignment problems
- Teams comfortable with lower-level APIs

**Ideal Timeline**: 10+ years
**Use When**: Performance matters, large-scale, production reliability required

**Consider Alternatives**:
- **PuLP**: If readability > performance
- **CVXPY**: If QP or academic focus
- **scipy**: If small-scale and NumPy-native preferred

### Verdict

**Safe to invest in OR-Tools?** **Absolutely, especially for production systems**
- Use OR-Tools for vehicle routing (best-in-class)
- Use OR-Tools for large-scale LP (GLOP is fast)
- Use OR-Tools for combinatorial MIP (CP-SAT is excellent)

**Trend**: OR-Tools is becoming the industry standard for routing and large-scale scheduling.

### The "No-Regrets" Scenario

If you pick OR-Tools today:
- **2026**: Best performance, Google-backed, excellent choice
- **2031**: Almost certainly still best (Google continues investment)
- **2036**: Likely still supported (core to Google infrastructure)

OR-Tools is the **lowest-risk, highest-performance** choice for production systems.

### Special Note: CP-SAT Dominance

CP-SAT (OR-Tools' constraint programming solver) is **uniquely excellent** for:
- Scheduling (job shop, flow shop, resource-constrained)
- Assignment (matching, allocation)
- Routing (with time windows, capacity)

**No free competitor** matches CP-SAT for these problems. This alone makes OR-Tools strategic.

### Investment Recommendation

**High confidence, high reward**:
- **Invest**: Learning curve pays off with performance, reliability
- **Timeframe**: 5-10+ years safe
- **Risk**: Minimal (Google backing)

If you need performance and can handle learning curve: **OR-Tools is your best bet**.


---

# PuLP - Strategic Viability

## Community and Maintenance (2026)

**Status**: Active maintenance, COIN-OR project

- **Maintainer Model**: COIN-OR organization, 3-5 core contributors
- **Bus Factor**: Moderate (depends on 2-3 key maintainers)
- **Commit Frequency**: Monthly releases, major version annually
- **Issue Resolution**: 80-90% issues triaged within 2 weeks
- **Breaking Changes**: Rare, but API evolved 2015-2020 (v2.0 major rewrite)

**Risk Level**: **Low-Moderate**
- COIN-OR provides organizational backing
- Widely used in industry (good retention incentive)
- Some dependence on key maintainers, but community stepping up

## Solver Ecosystem

**Current (2026)**:
- CBC (default, COIN-OR project)
- GLPK, CPLEX, Gurobi, Mosek, SCIP, HiGHS, XPRESS

**Trends**:
- **Growing**: HiGHS integration added (2023+)
- **Stable**: CBC maintained but not aggressively developed
- **Commercial**: Gurobi and CPLEX support actively maintained (high demand)

**Strategic Assessment**:
- **Diverse**: Not locked into one solver
- **Future-proof**: Easy to add new solvers as they emerge
- **Dependency**: CBC quality matters for free users

**CBC Viability**:
- Maintained but slow development
- Good enough for 80% of users
- Risk: If CBC stagnates, PuLP's free offering weakens

## Integration and Modern Python

**Current**:
- Type hints: Partial (added in v2.7, 2022)
- Python 3.10+ support: Yes
- Async: No (not needed for batch optimization)

**Packaging**:
- PyPI (pip install pulp)
- Conda (conda-forge)
- Docker: Not official, but easy (just pip install)

**API Modernization**:
- Legacy API (2010s style) still dominant
- Some modern conveniences added (context managers, pathlib)

**Strategic Assessment**:
- **Adequate**: Keeps up with Python ecosystem
- **Legacy feel**: API shows age (pre-type-hint design)
- **Not blocking**: Doesn't prevent adoption

## Competitive Landscape

**Threats**:
- **CVXPY**: More modern API, academic mindshare
- **OR-Tools**: Google backing, performance
- **Pyomo**: More comprehensive (nonlinear), academic support

**Strengths**:
- **Installed base**: Widely used in industry
- **Simplicity**: Lowest barrier to LP/MIP
- **Inertia**: Switching cost for existing projects

**Strategic Assessment**:
- **Defensible**: Network effects, inertia
- **Niche**: "Readable MIP modeling" - keeps PuLP relevant
- **Pressure**: Must improve solver support, performance to compete

## Technical Debt and Architecture

**Code Quality**:
- Test coverage: ~70% (adequate, not excellent)
- Architecture: Serialization layer (MPS/LP files) is legacy
- Python-only (no C extensions): Easy to maintain, but slower

**API Stability**:
- v2.0 (2020) was last major break
- Now committed to semver (no more v2 → v3 churn)
- Minor versions backward-compatible

**Migration Risk**: **Moderate**
- v1 → v2 required code changes (2020)
- Future: Should be stable (semver commitment)
- Fallback: v1 still works, can stay on old version

## Long-Term Investment Advice

### Safe for New Projects? **YES** (with caveats)
**Reasons**:
- Mature, widely used, good documentation
- Solver flexibility (not locked in)
- COIN-OR backing reduces abandonment risk

**Caveats**:
- Performance not best-in-class (use Gurobi for large-scale)
- API aging (not as modern as CVXPY)
- Smaller community than scipy or OR-Tools

**Best For**:
- LP/MIP with readable code (production systems)
- Teams wanting solver flexibility (CBC → Gurobi path)
- Projects already using PuLP (low switching cost)

**Not Ideal For**:
- QP (use CVXPY)
- Very large-scale (`>100`K variables without commercial solver)
- New projects prioritizing modern Python aesthetics

### 3-5 Year Outlook

| Dimension | Trend | Impact |
|-----------|-------|--------|
| Maintenance | Stable | ✅ Continued updates likely |
| Performance | Incremental | ⚠️ Limited without commercial solver |
| Features | Incremental | ✅ Solver support expanding (HiGHS) |
| Community | Stable | ⚠️ Not growing fast, not shrinking |
| Breaking Changes | Unlikely | ✅ Semver commitment |

### Risk Mitigation

**Key Risks**:
- CBC stagnation → Use Gurobi or HiGHS
- Maintainer turnover → COIN-OR can recruit new maintainers
- CVXPY/OR-Tools cannibalization → PuLP's simplicity keeps niche

**Mitigation**:
- **Don't rely on CBC long-term**: Plan to upgrade to commercial solver
- **Monitor**: COIN-OR project health, maintainer activity
- **Fallback**: Can migrate to Pyomo or OR-Tools (modeling languages portable)

## Governance and Sustainability

**Governance**: COIN-OR (academic/industry consortium)
**Funding**: Mix of volunteer time, corporate contributions (indirect), grants
**Transparency**: Open development, public GitHub

**Sustainability Score**: **7/10**
- Financial: Volunteer-driven, no dedicated funding (risk)
- Social: Moderate contributor base, good user community
- Technical: Clean enough, test coverage adequate

**Concerns**:
- No full-time maintainers (all volunteers)
- Dependent on COIN-OR health (broader project)

## Recommendation

**Strategic Position**: **Workhorse for MIP**

PuLP is the **practical, readable choice** for LP/MIP. Not the fastest, not the fanciest, but gets the job done.

**Ideal Timeline**: 3-5 years
**Use When**: Readability > raw performance, MIP needed, want solver flexibility

**Consider Alternatives**:
- **scipy**: If LP-only and NumPy-native preferred
- **OR-Tools**: If performance critical
- **CVXPY**: If QP or academic correctness needed

### Verdict

**Safe to invest in PuLP?** **Yes, but hedge your bets**
- Use PuLP for production MIP (proven, stable)
- Plan to add Gurobi if scaling up
- Keep eye on CVXPY (may overtake for new projects in 5 years)


---

# S4 Recommendation: Strategic Investment Guidance

## Executive Summary: Which Libraries Will Thrive?

### 2026-2031 Outlook

| Library | 2026 Status | 2031 Projection | Risk Level | Investment Grade |
|---------|-------------|-----------------|------------|------------------|
| **scipy** | Mature, stable | Mature, stable | Very Low | A+ (Foundation) |
| **PuLP** | Mature, stable | Mature, slower growth | Low | B+ (Workhorse) |
| **CVXPY** | Growing, modern | Strong growth | Low | A (Future-focused) |
| **OR-Tools** | Strong, active | Stronger, industry standard | Very Low | A+ (Production) |

### Strategic Positioning

```
              Innovation
                  ↑
                  |
              CVXPY ●
                  |
                  |
     PuLP ●       |       ● OR-Tools
                  |
                  |
              scipy ●
                  |
      ←───────────┼───────────→
      Stability   |   Performance
                  ↓
```

## Investment Matrix by Organizational Context

### Startups / Small Teams (1-10 people)
**Recommended**: PuLP or scipy
**Why**: Low learning curve, free solvers, "good enough" performance
**Upgrade Path**: PuLP → Gurobi when scaling; scipy → CVXPY if QP needed

**Risk**: Low (mature technologies, easy to replace if growing)

### Mid-Size Companies (50-500 people)
**Recommended**: PuLP (with Gurobi) or CVXPY
**Why**: Balance maintainability and performance, team can handle learning curve
**Investment**: Gurobi license ($10K-50K/year) justified by cost savings

**Risk**: Low (both libraries stable, good documentation, hiring pool)

### Large Enterprises (500+ people)
**Recommended**: OR-Tools or commercial solver APIs
**Why**: Performance critical, dedicated optimization team, scale matters
**Investment**: Gurobi/CPLEX enterprise licenses + OR-Tools for routing

**Risk**: Very Low (Google-backed, established commercial relationships)

### Research / Academic
**Recommended**: CVXPY or scipy
**Why**: Reproducibility, mathematical correctness, teaching
**License**: Academic licenses for Gurobi/CPLEX (free or cheap)

**Risk**: Very Low (academic projects have different risk profile)

## Timeline-Based Decision Framework

### Project Horizon: 1-2 Years
**Any library works** - all four are stable enough
**Choose based on**: Developer familiarity, problem type, performance needs

### Project Horizon: 3-5 Years
**Recommended**: CVXPY or OR-Tools
**Avoid**: PuLP (risk of stagnation, though low)
**Safe**: scipy (will be maintained, but feature-static)

**Logic**: CVXPY and OR-Tools are accelerating, PuLP is steady-state

### Project Horizon: 5-10 Years
**Recommended**: OR-Tools (highest confidence)
**Also Safe**: CVXPY, scipy
**Moderate Risk**: PuLP (may fall behind, but not abandoned)

**Logic**: Google backing + internal use is strongest sustainability signal

## Problem Type → Library Strategy

### Pure LP (No MIP, No QP)
- **Small-scale (`<10`K vars)**: scipy (simplest)
- **Large-scale (`>10`K vars)**: OR-Tools GLOP (fastest free)
- **With commercial solver**: Any library + CPLEX/Gurobi

**Strategic Lens**: scipy is "safe and boring" (good), OR-Tools is "overkill but future-proof"

### LP + MIP
- **Readable code priority**: PuLP
- **Performance priority**: OR-Tools
- **Future flexibility**: PuLP (easier to maintain)

**Strategic Lens**: PuLP for startups/mid-size, OR-Tools for enterprises

### LP + QP + SOCP (Mixed Convex)
- **Only choice**: CVXPY
- **Fallback**: Specialized libraries per problem type (scipy for LP, OSQP for QP)

**Strategic Lens**: CVXPY is the only general-purpose option

### Combinatorial (Scheduling, Routing, Assignment)
- **Clear winner**: OR-Tools CP-SAT
- **Alternatives**: PuLP (weaker, but acceptable for simple problems)

**Strategic Lens**: OR-Tools is unmatched for combinatorial

## Technology Trend Analysis

### Solver Ecosystem Trends

**Open-Source Improving**:
- HiGHS (scipy's default): Approaching commercial quality
- CP-SAT (OR-Tools): Best-in-class for combinatorial
- OSQP, SCS (CVXPY): Excellent for QP, conic

**Implication**: Less pressure to buy commercial solvers in next 5 years

**Strategic Bet**: Open-source will close gap, but commercial still faster for very large problems

### GPU and Parallel Trends

**Current (2026)**:
- SCS supports GPU (CVXPY can use it)
- cuPDLP emerging (GPU solver)
- Most solvers still CPU-bound

**Future (2031)**:
- GPU likely mainstream for large problems
- CVXPY best positioned (active integration)
- OR-Tools may add GPU support (Google has resources)

**Strategic Bet**: CVXPY benefits most from GPU trend

### Cloud and Microservices

**Current**:
- All four libraries containerize well
- OR-Tools has best Docker support
- PuLP and CVXPY trivial to deploy

**Future**:
- Optimization-as-a-Service (OaaS) growing
- API wrappers around OR-Tools common
- Cloud-native solvers (Gurobi Cloud, etc.)

**Strategic Bet**: OR-Tools most aligned with cloud/microservice architecture

## Risk Assessment by Library

### scipy: Minimal Risk
**Black Swan Event**: NumFOCUS collapses, SciPy abandoned
**Probability**: `<1`% (institutional backing, wide usage)
**Mitigation**: Fork or migrate to PuLP
**Impact**: Low (mature, replaceable)

### PuLP: Low Risk
**Black Swan Event**: COIN-OR funding dries up, maintainers quit
**Probability**: 5-10% (volunteer-driven, funding uncertain)
**Mitigation**: Migrate to Pyomo or OR-Tools
**Impact**: Moderate (migration cost, but feasible)

### CVXPY: Low Risk
**Black Swan Event**: Stanford team loses funding, project stalls
**Probability**: 5% (industry sponsors provide hedge)
**Mitigation**: Use solvers directly or migrate to specialized libraries
**Impact**: Moderate (unique features hard to replace)

### OR-Tools: Minimal Risk
**Black Swan Event**: Google shuts down project
**Probability**: `<1`% (internal use prevents this)
**Mitigation**: Fork (open-source, could be maintained by community)
**Impact**: Low (solvers are independent, API could be maintained)

## Future-Proofing Strategies

### Hedge Your Bets
**Multi-library strategy** for large organizations:
- **Prototyping**: CVXPY (fast iteration)
- **Production LP**: OR-Tools or scipy (performance)
- **Production MIP**: OR-Tools or PuLP + Gurobi

**Advantage**: Not locked into one ecosystem

### Lock-In Avoidance
**Minimize vendor lock-in**:
- **Avoid**: Proprietary problem formats (use standard MPS/LP files)
- **Prefer**: Libraries with solver flexibility (PuLP, CVXPY)
- **Document**: Problem formulation separately from code (models are reusable)

**Advantage**: Can switch libraries if needed

### Skill Investment
**Which library to teach new hires?**
- **2026-2028**: PuLP (easiest, most readable)
- **2028-2031**: CVXPY (modern, growing, future-focused)
- **Expert track**: OR-Tools (performance-critical roles)

**Advantage**: Team skills align with ecosystem trajectory

## The "No-Regrets" Portfolio

If you must choose ONE library for a new project in 2026:

### For LP-only projects
**Choose**: scipy (zero risk, simple, adequate)
**No regrets**: Will be maintained forever, easy to extend later

### For LP + MIP projects
**Choose**: PuLP (battle-tested, readable)
**Hedge**: Plan to add CVXPY if QP appears, or OR-Tools if scaling

### For LP + QP + SOCP projects
**Choose**: CVXPY (only comprehensive option)
**No regrets**: Growing fast, modern, likely to improve

### For performance-critical projects
**Choose**: OR-Tools (best free performance, Google-backed)
**No regrets**: Will be maintained, likely to improve

## Final Verdict: Strategic Ranking

### For New Projects Starting in 2026

**Tier 1 (Highly Recommended)**:
1. **CVXPY**: Modern, growing, versatile, future-proof
2. **OR-Tools**: Performance, Google-backed, comprehensive

**Tier 2 (Safe, Solid Choices)**:
3. **scipy**: Mature, stable, simple (LP-only)
4. **PuLP**: Battle-tested, readable (LP+MIP)

**Investment Advice**:
- **High-growth startups**: CVXPY (flexible, modern)
- **Established companies**: OR-Tools (performance, reliability)
- **Conservative orgs**: scipy or PuLP (lowest risk)
- **Research**: CVXPY (correctness, innovation)

### The 5-Year Bet

**Most likely to thrive (2026-2031)**:
1. OR-Tools (Google investment)
2. CVXPY (academic → industry pipeline)

**Steady state (will be fine)**:
3. scipy (SciPy ecosystem too big to fail)

**Moderate risk (may fall behind)**:
4. PuLP (volunteer-driven, slower innovation)

**Bottom line**: All four libraries are safe investments for next 3-5 years. Choose based on problem type and organizational context. For long-term bets (5-10 years), lean toward CVXPY or OR-Tools.


---

# scipy.optimize.linprog - Strategic Viability

## Community and Maintenance (2026)

**Status**: Active core development, part of SciPy

- **Maintainer Model**: NumFOCUS-backed, large contributor base
- **Bus Factor**: High (20+ core contributors)
- **Commit Frequency**: Weekly releases, quarterly major versions
- **Issue Resolution**: 95%+ issues triaged within 1 week
- **Breaking Changes**: Rare (last major: scipy 1.0 in 2017), strong backward compatibility

**Risk Level**: **Very Low**
- SciPy is foundational to scientific Python ecosystem
- Institutional backing (NumFOCUS, NASA, academic grants)
- No risk of abandonment in next 5-10 years

## Solver Ecosystem

**Current (2026)**:
- HiGHS as default (since SciPy 1.6, 2021)
- Legacy solvers maintained for compatibility

**Trends**:
- HiGHS actively developed (2023-2026 updates)
- No plans to add new solvers (feature-complete for LP)
- GPU support unlikely (not a priority for SciPy)

**Strategic Assessment**:
- **Conservative**: Sticks with proven, mature solvers
- **Stable**: HiGHS unlikely to be replaced in next 5 years
- **Limitation**: Won't get cutting-edge solver innovations

## Integration and Modern Python

**Current**:
- Type hints added (scipy 1.7+)
- NumPy 2.0 compatibility committed
- No async support (not applicable for solvers)

**Packaging**:
- Conda, pip, system packages (apt, yum)
- Docker images available (jupyter/scipy-notebook)
- Cloud: AWS Lambda layers, Google Colab pre-installed

**Strategic Assessment**:
- **Mature**: Well-integrated into data science stack
- **Cloud-native**: Easy deployment, no dependencies
- **Limitation**: Not designed for microservices (use PuLP or OR-Tools API wrappers)

## Competitive Landscape

**Threats**:
- None (scipy is a foundational library)
- Specialized libraries (PuLP, CVXPY) complement, don't replace

**Opportunities**:
- Growing scientific Python adoption
- Education: Default choice for teaching optimization
- Integration with ML libraries (scikit-learn, statsmodels)

**Strategic Assessment**:
- **Defensible**: Strong network effects, no viable replacements
- **Growth**: Continues to grow with scientific Python ecosystem

## Technical Debt and Architecture

**Code Quality**:
- High test coverage (`>90`%)
- C/Fortran core (BLAS, LAPACK) well-maintained
- Python wrapper clean, documented

**API Stability**:
- Strong commitment to backward compatibility
- Deprecation cycle: Warning → 2 releases → removal
- Keyword-only arguments prevent accidental breaks

**Migration Risk**: **Very Low**
- Code written in 2015 still works in 2026
- HiGHS addition was backward-compatible (new default, old solvers available)

## Long-Term Investment Advice

### Safe for New Projects? **YES**
**Reasons**:
- Mature, stable, won't break
- Institutional support ensures longevity
- Wide adoption = good hiring, support

**Best For**:
- Data science teams (already use NumPy/pandas)
- Academic projects (teaching, research)
- Prototyping before production

**Not Ideal For**:
- MIP (no support)
- Large-scale production (limited control)
- Cutting-edge solver features

### 3-5 Year Outlook

| Dimension | Trend | Impact |
|-----------|-------|--------|
| Maintenance | Stable | ✅ Continued support guaranteed |
| Performance | Incremental | ✅ HiGHS updates benefit scipy |
| Features | Static | ⚠️ Unlikely to add MIP or new solvers |
| Community | Growing | ✅ More users, better documentation |
| Breaking Changes | None expected | ✅ Safe to build on |

### Risk Mitigation

**Minimal risks**, but to mitigate:
- **Monitor**: SciPy release notes for deprecations (rare)
- **Fallback**: If scipy discontinued (extremely unlikely), PuLP can replace
- **Solver lock-in**: HiGHS is open-source, can be used independently

## Governance and Sustainability

**Governance**: NumFOCUS-backed, community-driven
**Funding**: Mix of grants (NASA, NSF), donations, sponsorships (Enthought, Anaconda)
**Transparency**: Public roadmap, open development

**Sustainability Score**: **10/10**
- Financial: Well-funded, diverse sources
- Social: Large contributor base, active community
- Technical: Clean architecture, good test coverage

## Recommendation

**Strategic Position**: **Foundation Layer**

scipy.optimize.linprog is a **safe, boring, excellent choice** for LP problems. It's not exciting, but it's reliable:
- Won't break
- Won't be abandoned
- Won't surprise you

**Ideal Timeline**: 5-10+ years
**Use When**: You want zero risk, mature technology, easy hiring

**Avoid When**: You need MIP, QP, or cutting-edge performance

</details>

